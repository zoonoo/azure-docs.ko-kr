---
title: 매핑 데이터 흐름 성능 및 조정 가이드
description: Azure Data Factory에서 매핑 데이터 흐름의 매핑 성능에 영향을 주는 주요 요소에 대해 알아봅니다.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 07/27/2020
ms.openlocfilehash: 55483b93b770687703b381366d48edbc7d48f26e
ms.sourcegitcommit: 5f7b75e32222fe20ac68a053d141a0adbd16b347
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/31/2020
ms.locfileid: "87475341"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>매핑 데이터 흐름 성능 및 조정 가이드

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Azure Data Factory에서 데이터 흐름을 매핑하면 대규모로 데이터 변환을 디자인 하 고 실행할 수 있는 코드 없는 인터페이스를 제공 합니다. 매핑 데이터 흐름을 잘 모르는 경우 [매핑 데이터 흐름 개요](concepts-data-flow-overview.md)를 참조하세요. 이 문서에서는 성능 벤치 마크를 충족 하도록 데이터 흐름을 조정 하 고 최적화 하는 다양 한 방법을 중점적으로 설명 합니다.

아래 비디오를 시청 하 여 데이터 흐름으로 데이터를 변환 하는 몇 가지 샘플 시간을 확인 하세요.

> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="testing-data-flow-logic"></a>데이터 흐름 논리 테스트

ADF UX에서 데이터 흐름을 디자인 하 고 테스트 하는 경우 디버그 모드에서 라이브 Spark 클러스터에 대해 대화형으로 테스트할 수 있습니다. 이렇게 하면 클러스터가 준비 될 때까지 기다리지 않고 데이터를 미리 보고 데이터 흐름을 실행할 수 있습니다. 자세한 내용은 [디버그 모드](concepts-data-flow-debug-mode.md)를 참조하세요.

## <a name="monitoring-data-flow-performance"></a>데이터 흐름 성능 모니터링

디버그 모드를 사용 하 여 변환 논리를 확인 한 후 파이프라인에서 작업으로 데이터 흐름 종단 간을 실행 합니다. 데이터 흐름은 [데이터 흐름 실행 작업](control-flow-execute-data-flow-activity.md)을 사용 하 여 파이프라인에서 조작 가능한 됩니다. 데이터 흐름 작업에는 변환 논리의 자세한 실행 계획 및 성능 프로필을 표시 하는 다른 Azure Data Factory 작업과 비교할 때 고유한 모니터링 환경이 있습니다. 데이터 흐름에 대 한 자세한 모니터링 정보를 보려면 파이프라인의 활동 실행 출력에서 안경 아이콘을 클릭 합니다. 자세한 내용은 [매핑 데이터 흐름 모니터링](concepts-data-flow-monitoring.md)을 참조하세요.

![데이터 흐름 모니터링](media/data-flow/monitoring-details.png "데이터 흐름 모니터 2")

데이터 흐름 성능을 모니터링할 때 확인할 수 있는 네 가지 병목 현상이 있습니다.

* 클러스터 시작 시간
* 원본에서 읽기
* 변환 시간
* 싱크에 쓰기 

![데이터 흐름 모니터링](media/data-flow/monitoring-performance.png "데이터 흐름 모니터 3")

클러스터 시작 시간은 Apache Spark 클러스터를 실행 하는 데 걸리는 시간입니다. 이 값은 모니터링 화면의 오른쪽 위 모퉁이에 있습니다. 데이터 흐름은 각 작업에서 격리 된 클러스터를 사용 하는 just-in-time 모델에서 실행 됩니다. 이 시작 시간은 일반적으로 3-5 분이 걸립니다. 순차적 작업의 경우 time to live 값을 사용 하 여이를 줄일 수 있습니다. 자세한 내용은 [Azure Integration Runtime 최적화](#ir)를 참조 하세요.

데이터 흐름은 ' 스테이지 '의 비즈니스 논리를 다시 정렬 하 고 실행 하 여 가능한 한 빨리 수행 하는 Spark 최적화 프로그램을 활용 합니다. 데이터 흐름이 기록 하는 각 싱크에 대해 모니터링 출력에는 싱크에 데이터를 쓰는 데 걸리는 시간과 함께 각 변환 단계의 기간이 나열 됩니다. 가장 큰 시간은 데이터 흐름에 병목 상태가 될 수 있습니다. 가장 큰 값을 사용 하는 변환 단계에서 원본을 포함 하는 경우 읽기 시간을 최적화 하는 것을 확인할 수 있습니다. 변환에 오랜 시간이 걸리는 경우 통합 런타임의 크기를 다시 분할 하거나 늘려야 할 수 있습니다. 싱크 처리 시간이 클 경우 데이터베이스를 확장 하거나 단일 파일에 출력 되지 않는지 확인 해야 할 수 있습니다.

데이터 흐름의 병목 상태를 확인 한 후에는 아래 최적화 전략을 사용 하 여 성능을 향상 시킵니다.

## <a name="optimize-tab"></a>최적화 탭

**최적화** 탭에는 Spark 클러스터의 파티션 구성표를 구성 하는 설정이 포함 되어 있습니다. 이 탭은 데이터 흐름의 모든 변환에 존재 하며 변환이 완료 된 **후** 데이터를 다시 분할할 것인지 여부를 지정 합니다. 분할을 조정 하면 전체 데이터 흐름 성능에 긍정적인 영향을 미칠 수 있는 계산 노드 및 데이터 위치 최적화에서 데이터 배포를 제어할 수 있습니다.

![Optimize](media/data-flow/optimize.png "최적화")

기본적으로 현재 *분할 사용* 은 변환의 현재 출력 분할을 유지 Azure Data Factory 지시 하는 선택입니다. 데이터를 다시 분할 하는 데 시간이 걸리므로 대부분의 시나리오에서 *현재 분할을 사용* 하는 것이 좋습니다. 데이터를 다시 분할할 수 있는 시나리오에는 데이터를 상당히 왜곡 하는 집계 및 조인과 SQL DB에서 원본 분할을 사용 하는 경우가 포함 됩니다.

변환에서 분할을 변경 하려면 **최적화** 탭을 선택 하 고 **분할 설정** 라디오 단추를 선택 합니다. 분할에 대 한 일련의 옵션이 제공 됩니다. 분할의 가장 좋은 방법은 데이터 볼륨, 후보 키, null 값 및 카디널리티에 따라 다릅니다. 

> [!IMPORTANT]
> 단일 파티션은 모든 분산 데이터를 단일 파티션으로 결합 합니다. 이 작업은 다운스트림 변환과 쓰기에 상당한 영향을 주는 매우 느립니다. 이 옵션을 사용 하는 것이 명시적인 비즈니스 이유가 없다면이 옵션을 사용 하지 않는 것이 좋습니다 Azure Data Factory.

모든 변환에서 다음 분할 옵션을 사용할 수 있습니다.

### <a name="round-robin"></a>라운드 로빈 

라운드 로빈은 여러 파티션에 데이터를 균등 하 게 분산 합니다. 견고한 스마트 분할 전략을 구현 하는 데 좋은 핵심 후보가 없는 경우 라운드 로빈을 사용 합니다. 물리적 파티션 수를 설정할 수 있습니다.

### <a name="hash"></a>Hash

Azure Data Factory는 유사한 값을 가진 행이 동일한 파티션에 포함 되도록 균일 한 파티션을 생성 하는 열 해시를 생성 합니다. Hash 옵션을 사용 하는 경우 가능한 파티션 오차를 테스트 합니다. 물리적 파티션 수를 설정할 수 있습니다.

### <a name="dynamic-range"></a>동적 범위

동적 범위에는 사용자가 제공 하는 열 또는 식을 기반으로 하는 Spark 동적 범위가 사용 됩니다. 물리적 파티션 수를 설정할 수 있습니다. 

### <a name="fixed-range"></a>고정 범위

분할 된 데이터 열 내에서 값의 고정 범위를 제공 하는 식을 작성 합니다. 파티션 기울이기를 방지 하려면이 옵션을 사용 하기 전에 데이터를 잘 이해 해야 합니다. 식에 대해 입력 하는 값은 파티션 함수의 일부로 사용 됩니다. 물리적 파티션 수를 설정할 수 있습니다.

### <a name="key"></a>키

데이터의 카디널리티에 대해 잘 알고 있다면 키 분할이 좋은 전략이 될 수 있습니다. 키 분할은 열에서 각 고유 값에 대 한 파티션을 만듭니다. 숫자가 데이터의 고유 값을 기반으로 하기 때문에 파티션 수를 설정할 수 없습니다.

> [!TIP]
> 데이터를 reshuffles 하는 파티션 구성표를 수동으로 설정 하 고 Spark 최적화 프로그램의 이점을 오프셋할 수 있습니다. 필요한 경우를 제외 하 고는 수동으로 분할을 설정 하지 않는 것이 가장 좋습니다.

## <a name="optimizing-the-azure-integration-runtime"></a><a name="ir"></a>Azure Integration Runtime 최적화

데이터 흐름은 런타임에 분리 된 Spark 클러스터에서 실행 됩니다. 사용 되는 클러스터에 대 한 구성은 활동의 IR (통합 런타임)에 정의 되어 있습니다. 통합 런타임을 정의할 때 세 가지 성능 고려 사항이 있습니다. 클러스터 유형, 클러스터 크기 및 ttl (time to live)이 있습니다.

Integration Runtime를 만드는 방법에 대한 자세한 내용은 [Azure Data Factory의 Integration Runtime](concepts-integration-runtime.md)을 참조하세요.

### <a name="cluster-type"></a>클러스터 유형

Spark 클러스터 분리의 유형에 사용할 수 있는 세 가지 옵션이 있습니다. 범용, 메모리 최적화 및 계산에 최적화 됨입니다.

**범용** 클러스터는 기본 선택 사항이 며 대부분의 데이터 흐름 워크 로드에 이상적입니다. 이는 성능 및 비용의 균형을 극대화 하는 경향이 있습니다.

데이터 흐름에 많은 조인과 조회가 있는 경우 메모리 액세스에 **최적화** 된 클러스터를 사용 하는 것이 좋습니다. 메모리 액세스에 최적화 된 클러스터는 메모리에 더 많은 데이터를 저장 하 고 발생할 수 있는 메모리 부족 오류를 최소화 합니다. 메모리 액세스에 최적화 됨은 코어 당 가장 높은 가격 지점을 가지 지만 더 성공적인 파이프라인을 생성 하기도 합니다. 데이터 흐름을 실행할 때 메모리 부족 오류가 발생 하면 메모리 액세스에 최적화 된 Azure IR 구성으로 전환 합니다. 

**계산 최적화** 는 ETL 워크플로에 적합 하지 않으며 대부분의 프로덕션 워크 로드에 대 한 Azure Data Factory 팀에서 권장 하지 않습니다. 데이터 필터링 또는 파생 열 추가와 같이 메모리를 많이 사용 하는 데이터를 더 간단 하 게 변형 하기 위해 계산에 최적화 된 클러스터는 코어 당 저렴 한 가격으로 사용할 수 있습니다.

### <a name="cluster-size"></a>클러스터 크기

데이터 흐름은 데이터 처리를 Spark 클러스터의 여러 노드에 분산 하 여 작업을 병렬로 수행 합니다. 더 많은 코어가 있는 Spark 클러스터는 계산 환경에서 노드 수를 늘립니다. 노드가 많을 수록 데이터 흐름의 처리 성능이 향상 됩니다. 클러스터의 크기를 높이면 처리 시간을 단축 하는 경우가 많습니다.

기본 클러스터 크기는 4 개의 드라이버 노드와 4 개의 작업자 노드입니다.  더 많은 데이터를 처리 하는 경우 더 큰 클러스터를 권장 합니다. 가능한 크기 조정 옵션은 다음과 같습니다.

| 작업자 코어 | 드라이버 코어 | 총 코어 | 참고 |
| ------------ | ------------ | ----------- | ----- |
| 4 | 4 | 8 | 계산에 최적화 된 경우 사용할 수 없음 |
| 8 | 8 | 16 | |
| 16 | 16 | 32 | |
| 32 | 16 | 48 | |
| 64 | 16 | 80 | |
| 128 | 16 | 144 | |
| 256 | 16 | 272 | |

데이터 흐름은 vcore 시간별로 가격이 책정 됩니다. 즉, 클러스터 크기와 실행 시간 요인이 모두이에 해당 합니다. 확장 하는 동안 분당 클러스터 비용이 증가 하지만 전체 시간이 단축 됩니다.

> [!TIP]
> 클러스터의 크기가 데이터 흐름의 성능에 영향을 주는 정도에는 제한이 있습니다. 데이터의 크기에 따라 클러스터 크기를 늘릴 경우 성능이 향상 되지 않을 수 있습니다. 예를 들어 데이터 파티션 보다 노드가 더 많은 경우 노드를 더 추가 하면 도움이 되지 않습니다. 모범 사례는 작고 성능 요구에 맞게 확장 하는 것입니다. 

### <a name="time-to-live"></a>TTL(Time to live)

기본적으로 모든 데이터 흐름 작업은 IR 구성에 따라 새 클러스터를 회전 합니다. 클러스터 시작 시간은 몇 분 정도 걸리며, 완료 될 때까지 데이터 처리를 시작할 수 없습니다. 파이프라인이 여러 개의 **순차적** 데이터 흐름을 포함 하는 경우 TTL (time to live) 값을 설정할 수 있습니다. Ttl (time to live) 값을 지정 하면 해당 실행이 완료 된 후 특정 기간 동안 클러스터가 활성 상태로 유지 됩니다. 새 작업이 TTL 시간 동안 IR을 사용 하 여 시작 하는 경우 기존 클러스터를 다시 사용 하 고 시작 시간은 몇 분이 아니라 몇 초 이내입니다. 두 번째 작업이 완료 되 면 클러스터는 다시 TTL 시간 동안 활성 상태로 유지 됩니다.

한 번에 하나의 작업만 단일 클러스터에서 실행할 수 있습니다. 사용 가능한 클러스터가 있지만 두 개의 데이터 흐름이 시작 되 면 하나만 라이브 클러스터를 사용 합니다. 두 번째 작업은 자체 격리 된 클러스터를 실행 합니다.

대부분의 데이터 흐름이 동시에 실행 되는 경우 TTL을 사용 하지 않는 것이 좋습니다. 

> [!NOTE]
> 자동 해결 통합 런타임을 사용 하는 경우 ttl (Time to live)을 사용할 수 없음

## <a name="optimizing-sources"></a>소스 최적화

Azure SQL Database를 제외한 모든 원본에 대해 **현재 분할** 을 선택한 값으로 계속 사용 하는 것이 좋습니다. 다른 모든 원본 시스템에서 데이터를 읽을 때 데이터 흐름은 데이터 크기에 따라 데이터를 균등 하 게 자동으로 분할 합니다. 128 MB의 데이터 마다 새 파티션이 만들어집니다. 데이터 크기가 증가 하면 파티션 수가 증가 합니다.

사용자 지정 분할은 데이터에서 Spark를 읽은 *후에* 발생 하며 데이터 흐름 성능에 부정적인 영향을 줍니다. 읽기에서 데이터를 균등 하 게 분할 하는 것은 권장 되지 않습니다. 

> [!NOTE]
> 읽기 속도는 원본 시스템의 처리량에 따라 제한 될 수 있습니다.

### <a name="azure-sql-database-sources"></a>Azure SQL Database 소스

Azure SQL Database에는 ' 원본 ' 분할 이라는 고유한 분할 옵션이 있습니다. 원본 시스템에서 병렬 연결을 사용 하도록 설정 하 여 원본 분할을 사용 하면 Azure SQL DB에서 읽기 시간을 향상 시킬 수 있습니다. 파티션 수를 지정 하 고 데이터를 분할 하는 방법을 지정 합니다. 카디널리티가 높은 파티션 열을 사용 합니다. 원본 테이블의 파티션 구성표와 일치 하는 쿼리를 입력할 수도 있습니다.

> [!TIP]
> 원본 분할의 경우 SQL Server i/o는 병목 상태입니다. 너무 많은 파티션을 추가 하면 원본 데이터베이스가 포화 상태가 될 수 있습니다. 일반적으로이 옵션을 사용 하는 경우 4 개 또는 5 개의 파티션이 적합 합니다.

![원본 분할](media/data-flow/sourcepart3.png "원본 분할")

#### <a name="isolation-level"></a>격리 수준

Azure SQL 원본 시스템에서 읽기의 격리 수준은 성능에 영향을 줍니다. ' 커밋되지 않은 읽기 '를 선택 하면 가장 빠른 성능을 제공 하 고 데이터베이스 잠금을 방지 합니다. SQL 격리 수준에 대 한 자세한 내용은 [격리 수준 이해](https://docs.microsoft.com/sql/connect/jdbc/understanding-isolation-levels?view=sql-server-ver15)를 참조 하세요.

#### <a name="read-using-query"></a>쿼리를 사용 하 여 읽기

테이블 또는 SQL 쿼리를 사용 하 여 Azure SQL Database에서 읽을 수 있습니다. SQL 쿼리를 실행 하는 경우에는 변환을 시작 하기 전에 쿼리를 완료 해야 합니다. SQL 쿼리는 SELECT, WHERE 및 JOIN 문과 같이 더 빠르게 실행 되 고 SQL Server에서 읽는 데이터 양을 줄일 수 있는 작업을 푸시하는 데 유용할 수 있습니다. 작업을 푸시하는 경우 데이터 흐름에 데이터를 제공 하기 전에 변환의 계보 및 성능을 추적할 수 있는 기능이 손실 됩니다.

### <a name="azure-synapse-analytics-sources"></a>Azure Synapse 분석 소스

Azure Synapse Analytics를 사용 하는 경우 원본 옵션에 **준비 사용** 이라는 설정이 있습니다. 이렇게 [하면 ADF를 사용 하](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide?view=sql-server-ver15)여 Synapse에서 읽기 성능을 크게 향상 시킬 수 있습니다. PolyBase를 사용 하도록 설정 하려면 데이터 흐름 활동 설정에서 Azure Blob Storage 또는 Azure Data Lake Storage gen2 준비 위치를 지정 해야 합니다.

![준비 사용](media/data-flow/enable-staging.png "준비 사용")

### <a name="file-based-sources"></a>파일 기반 원본

데이터 흐름은 다양 한 파일 형식을 지원 하지만 Azure Data Factory은 최적의 읽기 및 쓰기 시간에 Spark-네이티브 Parquet 형식을 사용 하는 것이 좋습니다.

파일 집합에서 동일한 데이터 흐름을 실행 하는 경우 파일 목록에서 읽기 또는 와일드 카드 경로를 사용 하 여 폴더에서 읽는 것이 좋습니다. 단일 데이터 흐름 작업 실행은 모든 파일을 일괄 처리로 처리할 수 있습니다. 이러한 설정을 설정 하는 방법에 대 한 자세한 내용은 [Azure Blob Storage](connector-azure-blob-storage.md#source-transformation)와 같은 커넥터 설명서에서 찾을 수 있습니다.

가능 하면 각 작업을 사용 하 여 파일 집합에 대 한 데이터 흐름을 실행 하지 않도록 합니다. 이렇게 하면 각각에 대 한 각 반복이 자체 Spark 클러스터를 실행 하 게 됩니다 .이는 대개 필요 하지 않으며 비용이 많이 들 수 있습니다. 

## <a name="optimizing-sinks"></a>싱크 최적화

데이터 흐름이 싱크에 기록 될 때 사용자 지정 분할은 쓰기 직전에 발생 합니다. 원본과 마찬가지로 대부분의 경우 **현재 분할** 을 선택한 파티션 옵션으로 계속 사용 하는 것이 좋습니다. 분할 된 데이터는 파티션이 분할 되지 않은 경우에도 분할 되지 않은 데이터 보다 훨씬 더 빠르게 작성 됩니다. 다음은 다양 한 싱크 유형에 대 한 개별 고려 사항입니다. 

### <a name="azure-sql-database-sinks"></a>Azure SQL Database 싱크

Azure SQL Database를 사용 하면 대부분의 경우 기본 분할이 작동 합니다. SQL database에서 처리 하기에 너무 많은 파티션이 싱크에 있을 수 있습니다. 이를 실행 하는 경우 SQL Database 싱크에 의해 출력 되는 파티션 수를 줄입니다.

#### <a name="disabling-indexes-using-a-sql-script"></a>SQL 스크립트를 사용 하 여 인덱스 비활성화

SQL 데이터베이스에 로드 하기 전에 인덱스를 비활성화 하면 테이블에 쓰기 성능이 크게 향상 됩니다. 다음 명령을 실행 하 여 SQL 싱크에 작성 합니다.

`ALTER INDEX ALL ON dbo.[Table Name] DISABLE`

쓰기가 완료 되 면 다음 명령을 사용 하 여 인덱스를 다시 작성 합니다.

`ALTER INDEX ALL ON dbo.[Table Name] REBUILD`

이러한 작업은 모두 데이터 흐름 매핑의 Azure SQL DB 또는 Synapse 싱크 내에서 SQL 사전 및 사후 SQL 스크립트를 사용 하 여 수행할 수 있습니다.

![인덱스 사용 안 함](media/data-flow/disable-indexes-sql.png "인덱스 사용 안 함")

> [!WARNING]
> 인덱스를 사용 하지 않도록 설정 하는 경우 데이터 흐름은 실제로 데이터베이스의 제어를 수행 하 고 쿼리는 성공할 가능성이 거의 없습니다. 결과적으로이 충돌을 방지 하기 위해 많은 ETL 작업이 야간 도중에 트리거됩니다. 자세한 내용은 [인덱스 비활성화의 제약 조건](https://docs.microsoft.com/sql/relational-databases/indexes/disable-indexes-and-constraints?view=sql-server-ver15) 에 대 한 자세한 내용

#### <a name="scaling-up-your-database"></a>데이터베이스 확장

일단 DTU 한도에 도달하면, 파이프라인 실행 전에 원본 크기 조정을 예약하고 Azure SQL DB 및 DW를 싱크하여 처리량을 늘리고 Azure 제한을 최소화합니다. 파이프라인 실행이 완료되면 데이터베이스를 다시 일반 실행 속도로 조정합니다.

### <a name="azure-synapse-analytics-sinks"></a>Azure Synapse Analytics 싱크

Azure Synapse Analytics에 쓸 때 **준비 사용** 이 true로 설정 되어 있는지 확인 합니다. 이렇게 하면 ADF를 사용 하 여 대량의 데이터를 효과적으로 로드 하는 [PolyBase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide) 를 작성할 수 있습니다. PolyBase를 사용 하는 경우 데이터 준비를 위해 Azure Data Lake Storage gen2 또는 Azure Blob Storage 계정을 참조 해야 합니다.

PolyBase 외에도 동일한 모범 사례는 Azure SQL Database으로 Azure Synapse Analytics에 적용 됩니다.

### <a name="file-based-sinks"></a>파일 기반 싱크 

데이터 흐름은 다양 한 파일 형식을 지원 하지만 Azure Data Factory은 최적의 읽기 및 쓰기 시간에 Spark-네이티브 Parquet 형식을 사용 하는 것이 좋습니다.

데이터를 균등 하 게 분산 하는 경우 **현재 분할을 사용** 하는 것이 파일을 쓰기 위한 가장 빠른 분할 옵션입니다.

#### <a name="file-name-options"></a>파일 이름 옵션

파일을 작성할 때 성능에 영향을 주는 이름 지정 옵션을 선택할 수 있습니다.

![싱크 옵션](media/data-flow/file-sink-settings.png "싱크 옵션")

**기본** 옵션을 선택 하면 가장 빠르게 기록 됩니다. 각 파티션은 Spark 기본 이름으로 파일에 해당 합니다. 이는 데이터 폴더에서 읽기만 하는 경우에 유용 합니다.

명명 **패턴** 을 설정 하면 각 파티션 파일의 이름이 사용자에 게 친숙 한 이름으로 바뀝니다. 이 작업은 쓰기 후에 수행 되며 기본값을 선택 하는 것 보다 약간 느립니다. 파티션당 각 개별 파티션의 이름을 수동으로 지정할 수 있습니다.

열이 데이터를 출력 하는 방법에 해당 하는 경우 **열에서 데이터로**를 선택할 수 있습니다. 이렇게 하면 데이터가 reshuffles 열이 균등 하 게 분산 되지 않은 경우 성능에 영향을 줄 수 있습니다.

**단일 파일로 출력** 은 모든 데이터를 단일 파티션으로 결합 합니다. 이렇게 하면 특히 대량 데이터 집합의 경우 긴 쓰기 시간이 발생 합니다. Azure Data Factory 팀은 명시적인 비즈니스 이유가 없으면이 옵션을 선택 **하지** 않는 것이 좋습니다.

### <a name="cosmosdb-sinks"></a>CosmosDB 싱크

CosmosDB에 쓸 때 데이터 흐름을 실행 하는 동안 처리량과 일괄 처리 크기를 변경 하면 성능이 향상 될 수 있습니다. 이러한 변경 내용은 데이터 흐름 작업 실행 중에만 적용 되며, 결론 후에 원래 컬렉션 설정으로 돌아갑니다. 

**일괄 처리 크기:** 데이터의 대략적인 행 크기를 계산 하 고 행 크기 * 일괄 처리 크기가 200만 보다 적은지 확인 합니다. 이 크기보다 작으면 일괄 처리 크기를 늘려 처리량을 높입니다.

**처리량:** 문서를 CosmosDB에 더 빨리 쓸 수 있도록 여기에서 더 높은 처리량 설정을 설정 합니다. 높은 처리량 설정에 따라 높은 수준의 비용을 염두에 두어야 합니다.

**쓰기 처리량 예산:** 분당 총 RUs 보다 작은 값을 사용 합니다. 많은 수의 Spark 파티션이 포함 된 데이터 흐름이 있는 경우 예산 처리량을 설정 하면 해당 파티션에 대 한 균형을 높일 수 있습니다.


## <a name="optimizing-transformations"></a>변형 최적화

### <a name="optimizing-joins-exists-and-lookups"></a>조인, 존재 및 조회 최적화

#### <a name="broadcasting"></a>아니거나

조인, 조회 및 존재 변환에서 하나 또는 두 데이터 스트림이 작업자 노드 메모리에 맞게 충분히 작은 경우 **브로드캐스팅을**사용 하도록 설정 하 여 성능을 최적화할 수 있습니다. 브로드캐스트는 작은 데이터 프레임을 클러스터의 모든 노드에 보내는 경우입니다. 이를 통해 Spark 엔진은 데이터를 단지 섞는 하지 않고도 조인을 수행할 수 있습니다. 기본적으로 Spark 엔진은 조인의 한 쪽을 브로드캐스트하도록 여부를 자동으로 결정 합니다. 들어오는 데이터에 대해 잘 알고 있고 한 스트림이 다른 스트림으로 크게 작은 경우 **고정** 브로드캐스트를 선택할 수 있습니다. 브로드캐스트를 고정 하 여 선택한 스트림을 브로드캐스트합니다. 

브로드캐스트 데이터의 크기가 Spark 노드에 비해 너무 크면 메모리 부족 오류가 발생할 수 있습니다. 메모리 부족 오류를 방지 하려면 메모리 액세스에 **최적화** 된 클러스터를 사용 합니다. 데이터 흐름을 실행 하는 동안 브로드캐스트 시간 제한이 발생 하는 경우 브로드캐스트 최적화를 해제할 수 있습니다. 그러나 이로 인해 데이터 흐름이 더 느리게 수행됩니다.

![조인 변환 최적화](media/data-flow/joinoptimize.png "조인 최적화")

#### <a name="cross-joins"></a>크로스 조인

조인 조건에 리터럴 값을 사용 하거나 조인의 양쪽에서 여러 개의 일치 항목을 사용 하는 경우 Spark는 조인을 크로스 조인으로 실행 합니다. 크로스 조인은 조인 된 값을 필터링 하는 전체 데카르트 곱입니다. 이는 다른 조인 형식 보다 훨씬 느립니다. 성능에 영향을 주지 않도록 조인 조건의 양쪽 모두에 대 한 열 참조가 있는지 확인 합니다.

#### <a name="sorting-before-joins"></a>조인 전 정렬

SSIS와 같은 도구의 병합 조인과 달리, 조인 변환은 필수 병합 조인 작업이 아닙니다. 조인 키를 변환 하기 전에 정렬할 필요가 없습니다. Azure Data Factory 팀은 데이터 흐름 매핑에 정렬 변환을 사용 하지 않는 것이 좋습니다.

### <a name="repartitioning-skewed-data"></a>기울어진 데이터 다시 분할

조인 및 집계와 같은 특정 변환은 데이터 파티션을 재조정 경우에 따라 데이터가 왜곡 될 수 있습니다. 기울어진 데이터는 데이터가 파티션에 균등 하 게 분산 되지 않음을 의미 합니다. 매우 왜곡 되는 데이터는 다운스트림 변환 및 싱크 쓰기 속도를 저하 시킬 수 있습니다. 모니터링 표시의 변환을 클릭 하 여 데이터 흐름 실행의 어느 시점에서 든 데이터의 왜곡도를 확인할 수 있습니다.

![왜곡도 및 첨도](media/data-flow/skewness-kurtosis.png "왜곡도 및 첨도")

모니터링 표시에는 두 가지 메트릭, 왜곡도 및 첨도와 함께 각 파티션에 데이터가 분산 되는 방식이 표시 됩니다. **왜곡도** 는 데이터의 비대칭 방법과 양수, 0, 음수 또는 정의 되지 않은 값을 가질 수 있는 방법을 측정 한 것입니다. 음수 기울이기는 왼쪽 꼬리가 오른쪽 보다 긴 것을 의미 합니다. **첨도** 는 데이터가 굵은 꼬리가 있는지 또는 밝은 꼬리가 있는지를 측정 한 것입니다. 최대 첨도 값은 바람직하지 않습니다. 이상적인 왜곡도 범위는-3에서 3 사이이 고 첨도의 범위는 10 보다 낮습니다. 이러한 숫자를 해석 하는 쉬운 방법은 파티션 차트를 살펴보고 1 개의 막대가 나머지 보다 크게 큰지 확인 하는 것입니다.

변환 후 데이터가 균등 하 게 분할 되지 않은 경우에는 [최적화 탭](#optimize-tab) 을 사용 하 여 다시 분할할 수 있습니다. 단지 섞는 데이터는 시간이 걸리고 데이터 흐름 성능을 향상 시 키 지 않을 수 있습니다.

> [!TIP]
> 데이터를 다시 분할 하지만 데이터를 재조정 하는 다운스트림 변환이 있는 경우 조인 키로 사용 되는 열에 대해 해시 분할을 사용 합니다.

## <a name="next-steps"></a>다음 단계

성능과 관련된 다음과 같은 다른 데이터 흐름 문서를 참조하세요.

- [데이터 흐름 작업](control-flow-execute-data-flow-activity.md)
- [데이터 흐름 성능 모니터링](concepts-data-flow-monitoring.md)
