---
title: Apache Spark 및 이중 쓰기 프록시를 사용하여 Azure Managed Instance for Apache Cassandra로 실시간 마이그레이션합니다.
description: Apache Spark 및 이중 쓰기 프록시를 사용하여 Azure Managed Instance for Apache Cassandra로 마이그레이션하는 방법을 알아봅니다.
author: TheovanKraay
ms.author: thvankra
ms.service: managed-instance-apache-cassandra
ms.topic: overview
ms.date: 06/02/2021
ms.openlocfilehash: 2d82e4fa00c387ca2b7de58b223a6abf11ad1491
ms.sourcegitcommit: c072eefdba1fc1f582005cdd549218863d1e149e
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/10/2021
ms.locfileid: "111956027"
---
# <a name="live-migration-to-azure-managed-instance-for-apache-cassandra-using-dual-write-proxy"></a>이중 쓰기 프록시를 사용하여 Azure Managed Instance for Apache Cassandra로 실시간 마이그레이션

> [!IMPORTANT]
> Apache Cassandra용 Azure Managed Instance는 현재 공개 미리 보기로 제공됩니다.
> 이 미리 보기 버전은 서비스 수준 계약 없이 제공되며 프로덕션 워크로드에는 사용하지 않는 것이 좋습니다. 특정 기능이 지원되지 않거나 기능이 제한될 수 있습니다.
> 자세한 내용은 [Microsoft Azure Preview에 대한 추가 사용 약관](https://azure.microsoft.com/support/legal/preview-supplemental-terms/)을 참조하세요.

가능하면 [하이브리드 클러스터](configure-hybrid-cluster.md)를 구성하여 기존 클러스터에서 Azure Managed Instance for Apache Cassandra로 데이터를 마이그레이션할 때 Apache Cassandra 네이티브 기능을 사용하는 것이 좋습니다. 그러면 Apache Cassandra의 가십 프로토콜을 사용하여 원본 데이터 센터에서 새로운 관리형 인스턴스 데이터 센터로 원활하게 데이터를 복제합니다. 그러나 원본 데이터베이스 버전이 호환되지 않거나 하이브리드 클러스터를 설정할 수 없는 경우가 있을 수 있습니다. 이 문서에서는 [이중 쓰기 프록시](https://github.com/Azure-Samples/cassandra-proxy) 및 Apache Spark를 사용하여 라이브 방식으로 Azure Managed Instance for Apache Cassandra로 데이터를 마이그레이션하는 방법을 설명합니다. 이 방법의 이점은 다음과 같습니다.

- **애플리케이션 변경 최소** - 프록시는 구성을 거의 변경하지 않거나 전혀 변경하지 않고 애플리케이션 코드의 연결을 허용할 수 있으며 모든 요청을 원본 데이터베이스로 라우팅하고 쓰기를 보조 대상으로 비동기적으로 라우팅합니다. 
- **클라이언트 유선 프로토콜 종속** - 이 방법은 백 엔드 리소스나 내부 프로토콜에 종속되지 않으므로 Apache Cassandra 유선 프로토콜을 구현하는 모든 원본 또는 대상 Cassandra 시스템에서 사용할 수 있습니다.

다음 이미지는 이 방법을 보여 줍니다.


:::image type="content" source="./media/migration/live-migration.gif" alt-text="Apache Cassandra용 Azure Managed Instance는 Apache Cassandra에 대한 관리형 서비스입니다." border="false":::

## <a name="prerequisites"></a>사전 요구 사항

* [Azure Portal](create-cluster-portal.md) 또는 [Azure CLI](create-cluster-cli.md)를 사용하여 Azure Managed Instance for Apache Cassandra 클러스터를 프로비저닝하고 [CQLSH를 사용하여 클러스터에 연결](./create-cluster-portal.md#connecting-to-your-cluster)할 수 있는지 확인합니다.

* [관리형 Cassandra VNet 내에서 Azure Databricks 계정을 프로비저닝](deploy-cluster-databricks.md)합니다. 또한 원본 Cassandra 클러스터에 대한 네트워크 액세스 권한이 있는지 확인합니다. 기록 데이터를 로드하기 위해 이 계정에 Spark 클러스터를 만듭니다.

* 원본 Cassandra 데이터베이스에서 대상 Cassandra Managed Instance 데이터베이스로 키스페이스/테이블 구성표를 이미 마이그레이션했는지 확인합니다.


## <a name="provision-a-spark-cluster"></a>Spark 클러스터 프로비저닝

Spark 3.0을 지원하는 Azure Databricks 런타임 버전 7.5를 선택하는 것이 좋습니다.

:::image type="content" source="../cosmos-db/media/cassandra-migrate-cosmos-db-databricks/databricks-runtime.png" alt-text="Databricks Runtime 버전 찾기를 보여 주는 스크린샷":::

## <a name="add-spark-dependencies"></a>Spark 종속성 추가

네이티브 및 Azure Cosmos DB Cassandra 엔드포인트 모두에 연결하려면 Apache Spark Cassandra 커넥터 라이브러리를 클러스터에 추가해야 합니다. 클러스터에서 **라이브러리** > **새로 설치** > **Maven** 을 선택한 다음 Maven 좌표에 `com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.0.0`을 추가합니다.

:::image type="content" source="../cosmos-db/media/cassandra-migrate-cosmos-db-databricks/databricks-search-packages.png" alt-text="Databricks에서 Maven 패키지 검색을 보여 주는 스크린샷":::

**설치** 를 선택한 다음 설치가 완료되면 클러스터를 다시 시작합니다.

> [!NOTE]
> Cassandra Connector 라이브러리가 설치된 후 Databricks 클러스터를 다시 시작해야 합니다.

## <a name="install-dual-write-proxy"></a>이중 쓰기 프록시 설치

이중 쓰기 중 성능을 최적화하려면 원본 Cassandra 클러스터의 모든 노드에 프록시를 설치하는 것이 좋습니다.

```bash
#assuming you do not have git already installed
sudo apt-get install git 

#assuming you do not have maven already installed
sudo apt install maven

#clone repo for dual-write proxy
git clone https://github.com/Azure-Samples/cassandra-proxy.git

#change directory
cd cassandra-proxy

#compile the proxy
mvn package
```

## <a name="start-dual-write-proxy"></a>이중 쓰기 프록시 시작

원본 Cassandra 클러스터의 모든 노드에 프록시를 설치하는 것이 좋습니다. 최소한 각 노드에서 프록시를 시작하려면 다음 명령을 실행해야 합니다. `<target-server>`를 대상 클러스터에 있는 노드 중 하나의 IP 또는 서버 주소로 바꿉니다. `<path to JKS file>`을 로컬 jks 파일 경로로 바꾸고, `<keystore password>`를 해당 암호로 바꿉니다.  

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar localhost <target-server> --proxy-jks-file <path to JKS file> --proxy-jks-password <keystore password>
```
SSL의 경우 기존 키 저장소(예: 원본 클러스터에서 사용하는 키 저장소)를 구현하거나 keytool을 사용하여 자체 서명된 인증서를 만들 수 있습니다.

```bash
keytool -genkey -keyalg RSA -alias selfsigned -keystore keystore.jks -storepass password -validity 360 -keysize 2048
```

> [!NOTE]
> 프록시를 통해 데이터베이스에 대한 SSL 연결을 설정할 때 클라이언트 애플리케이션이 이중 쓰기 프록시에 사용된 것과 동일한 키 저장소 및 암호를 사용하는지 확인합니다.

이 방법으로 프록시를 시작하면 다음 조건이 충족된다고 가정합니다.

- 원본 및 대상 엔드포인트의 사용자 이름과 암호가 동일합니다.
- 원본 및 대상 엔드포인트가 SSL을 구현합니다.

기본적으로 원본 자격 증명은 클라이언트 앱에서 전달되며 프록시에서 원본 및 대상 클러스터에 연결하는 데 사용됩니다. 필요한 경우 프록시를 시작할 때 대상 Cassandra 엔드포인트의 사용자 이름 및 암호를 별도로 지정할 수 있습니다.

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar localhost <target-server> --proxy-jks-file <path to JKS file> --proxy-jks-password <keystore password> --target-username <username> --target-password <password>
```

기본 원본 및 대상 포트는 지정되지 않은 경우 `9042`가 됩니다. 대상 또는 원본 Cassandra 엔드포인트가 다른 포트에서 실행되는 경우 `--source-port` 또는 `--target-port`를 사용하여 다른 포트 번호를 지정할 수 있습니다. 

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar localhost <target-server> --source-port 9042 --target-port 10350 --proxy-jks-file <path to JKS file> --proxy-jks-password <keystore password> --target-username <username> --target-password <password>
```

SSL을 구현하지 않는 경우 원본 또는 대상 엔드포인트에 대해 SSL을 사용하지 않도록 설정할 수도 있습니다. `--disable-source-tls` 또는 `--disable-target-tls` 플래그를 사용합니다.

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar localhost <target-server> --source-port 9042 --target-port 10350 --proxy-jks-file <path to JKS file> --proxy-jks-password <keystore password> --target-username <username> --target-password <password> --disable-source-tls true  --disable-target-tls true 
```

클러스터 노드 자체에 프록시를 설치하지 않고 별도의 머신에 설치하려는 경우가 있을 수 있습니다. 이런 경우 `<source-server>`의 IP를 지정해야 합니다.

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar <source-server> <destination-server>
```

> [!NOTE]
> 네이티브 Apache Cassandra 클러스터의 모든 노드에 프록시를 설치하고 실행하지 않으면 클라이언트 드라이버가 클러스터 내의 모든 노드에 대한 연결을 열 수 없으므로 애플리케이션의 성능에 영향을 줍니다. 

기본적으로 프록시는 포트 29042에서 수신 대기합니다. 그러나 프록시가 수신 대기하는 포트를 변경할 수도 있습니다. 원본 Cassandra 서버는 다른 포트에서 실행되고 프록시는 표준 Cassandra 포트에서 실행되도록 하여 애플리케이션 수준 코드가 변경되지 않도록 하려는 경우 이렇게 할 수 있습니다.

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar source-server destination-server --proxy-port 9042
```

> [!NOTE]
> 클러스터 노드에 프록시를 설치하면 노드를 다시 시작하지 않아도 됩니다. 그러나 애플리케이션 클라이언트가 많고 프록시를 표준 Cassandra 포트 9042에서 실행하여 애플리케이션 수준 코드가 변경되지 않도록 하려면 클러스터를 다시 시작해야 합니다. 

프록시에는 원본 엔드포인트가 대상보다 고급인 경우 필요할 수 있는 프로토콜을 강제 적용하는 몇 가지 기능이 있습니다. 이 경우 `--protocol-version` 및 `--cql-version`을 지정할 수 있습니다.

```bash
java -jar target/cassandra-proxy-1.0-SNAPSHOT-fat.jar source-server destination-server --protocol-version 4 --cql-version 3.11
```

이중 쓰기 프록시를 실행했으면 애플리케이션 클라이언트에서 포트를 변경하고 다시 시작해야 합니다. 또는 이 방법을 선택한 경우 Cassandra 포트를 변경하고 클러스터를 다시 시작해야 합니다. 그러면 프록시가 대상 엔드포인트로 쓰기를 전달하기 시작합니다. 프록시 도구에서 사용할 수 있는 [모니터링 및 메트릭](https://github.com/Azure-Samples/cassandra-proxy#monitoring)에 대해 알아볼 수 있습니다. 


## <a name="run-the-historic-data-load"></a>기록 데이터 로드 실행

데이터를 로드하려면 Databricks 계정에 Scala Notebook을 만듭니다. 원본 및 대상 Cassandra 구성을 해당 자격 증명, 원본 및 대상 키 공간과 테이블로 바꿉니다. 각 테이블에 대한 변수를 필요한 만큼 아래 샘플에 더 추가한 다음, 실행합니다. 애플리케이션에서 이중 쓰기 프록시로 요청을 보내기 시작하면 기록 데이터를 마이그레이션할 수 있습니다. 

```scala
import com.datastax.spark.connector._
import com.datastax.spark.connector.cql._
import org.apache.spark.SparkContext

// source cassandra configs
val sourceCassandra = Map( 
    "spark.cassandra.connection.host" -> "<Source Cassandra Host>",
    "spark.cassandra.connection.port" -> "9042",
    "spark.cassandra.auth.username" -> "<USERNAME>",
    "spark.cassandra.auth.password" -> "<PASSWORD>",
    "spark.cassandra.connection.ssl.enabled" -> "true",
    "keyspace" -> "<KEYSPACE>",
    "table" -> "<TABLE>"
)

//target cassandra configs
val targetCassandra = Map( 
    "spark.cassandra.connection.host" -> "<Source Cassandra Host>",
    "spark.cassandra.connection.port" -> "9042",
    "spark.cassandra.auth.username" -> "<USERNAME>",
    "spark.cassandra.auth.password" -> "<PASSWORD>",
    "spark.cassandra.connection.ssl.enabled" -> "true",
    "keyspace" -> "<KEYSPACE>",
    "table" -> "<TABLE>",
    //throughput related settings below - tweak these depending on data volumes. 
    "spark.cassandra.output.batch.size.rows"-> "1",
    "spark.cassandra.output.concurrent.writes" -> "1000",
    "spark.cassandra.connection.remoteConnectionsPerExecutor" -> "1",
    "spark.cassandra.concurrent.reads" -> "512",
    "spark.cassandra.output.batch.grouping.buffer.size" -> "1000",
    "spark.cassandra.connection.keep_alive_ms" -> "600000000"
)

//set timestamp to ensure it is before read job starts
val timestamp: Long = System.currentTimeMillis / 1000

//Read from source Cassandra
val DFfromSourceCassandra = sqlContext
  .read
  .format("org.apache.spark.sql.cassandra")
  .options(sourceCassandra)
  .load
  
//Write to target Cassandra
DFfromSourceCassandra
  .write
  .format("org.apache.spark.sql.cassandra")
  .options(targetCassandra)
  .option("writetime", timestamp)
  .mode(SaveMode.Append)
  .save
```

> [!NOTE]
> 위의 Scala 샘플에서 `timestamp`는 원본 테이블의 모든 데이터를 읽기 전의 현재 시간으로 설정되어 있고, `writetime`은 소급 적용된 이 타임스탬프로 설정되어 있습니다. 따라서 기록 데이터가 대상 엔드포인트에 로드될 때 기록되는 레코드는 기록 데이터를 읽는 동안 이중 쓰기 프록시의 이후 타임스탬프로 제공되는 업데이트를 덮어쓸 수 없습니다. 어떤 이유로든 ‘정확한’ 타임스탬프를 유지해야 하는 경우 [이](https://github.com/scylladb/scylla-migrator) 샘플처럼 타임스탬프를 유지하는 기록 데이터 마이그레이션 방법을 사용해야 합니다. 

## <a name="validation"></a>유효성 검사

기록 데이터 로드가 완료되면 데이터베이스를 동기화하고 중단할 준비를 해야 합니다. 그러나 최종적으로 중단하기 전에 원본과 대상의 유효성 검사를 수행하여 요청 결과가 일치하는지 확인하는 것이 좋습니다.


## <a name="next-steps"></a>다음 단계

> [!div class="nextstepaction"]
> [Azure CLI를 사용하여 Apache Cassandra용 Azure Managed Instance 리소스 관리](manage-resources-cli.md)