---
title: Azure Vm에 대 한 TCP/IP 성능 튜닝 | Microsoft Docs
description: 다양 한 일반적인 TCP/IP 성능 조정 방법 및 Azure Vm과의 관계에 대해 알아봅니다.
services: virtual-network
documentationcenter: na
author: rimayber
manager: paragk
editor: ''
ms.assetid: ''
ms.service: virtual-network
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 04/02/2019
ms.author: rimayber
ms.reviewer: dgoddard, stegag, steveesp, minale, btalb, prachank
ms.openlocfilehash: dc77f3267813bd049274f44e43c4d64b0eb3801e
ms.sourcegitcommit: d7008edadc9993df960817ad4c5521efa69ffa9f
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/08/2020
ms.locfileid: "86120282"
---
# <a name="tcpip-performance-tuning-for-azure-vms"></a>Azure Vm에 대 한 TCP/IP 성능 튜닝

이 문서에서는 Azure에서 실행 되는 가상 컴퓨터에 사용할 때 고려해 야 하는 일반적인 TCP/IP 성능 조정 방법 및 몇 가지 사항을 설명 합니다. 기술의 기본적인 개요를 제공 하 고이를 튜닝할 수 있는 방법을 살펴봅니다.

## <a name="common-tcpip-tuning-techniques"></a>일반적인 TCP/IP 튜닝 기술

### <a name="mtu-fragmentation-and-large-send-offload"></a>MTU, 조각화 및 대량 송신 오프 로드

#### <a name="mtu"></a>MTU

MTU (최대 전송 단위)는 네트워크 인터페이스를 통해 전송할 수 있는 가장 큰 크기 프레임 (패킷) (바이트)입니다. MTU는 구성 가능한 설정입니다. Azure Vm에서 사용 되는 기본 MTU 및 대부분의 네트워크 장치에 대 한 기본 설정은 1500 바이트입니다.

#### <a name="fragmentation"></a>조각화

조각화는 네트워크 인터페이스의 MTU를 초과 하는 패킷을 보낼 때 발생 합니다. TCP/IP 스택은 인터페이스의 MTU를 따르는 더 작은 조각 (조각)으로 패킷을 나눕니다. 조각화는 IP 계층에서 발생 하며 TCP와 같은 기본 프로토콜과는 독립적입니다. MTU가 1500 인 네트워크 인터페이스를 통해 2000 바이트 패킷을 보내면 패킷이 1 1500 바이트 패킷 및 1 500 바이트 패킷으로 구분 됩니다.

원본 및 대상 간의 경로에서 네트워크 장치는 MTU를 초과 하는 패킷을 삭제 하거나 패킷을 더 작은 부분으로 조각화 할 수 있습니다.

#### <a name="the-dont-fragment-bit-in-an-ip-packet"></a>IP 패킷에서 조각화 안 함 비트

No Fragment (DF) 비트는 IP 프로토콜 헤더의 플래그입니다. DF 비트는 발신자와 수신자 간의 경로에서 네트워크 장치가 패킷을 조각화 해서는 안 됨을 나타냅니다. 여러 가지 이유로이 비트를 설정할 수 있습니다. 한 가지 예는이 문서의 "경로 MTU 검색" 섹션을 참조 하세요. 네트워크 장치에서 조각화 안 함 비트가 설정 된 패킷을 수신 하 고 해당 패킷이 장치의 인터페이스 MTU를 초과 하는 경우 장치에서 패킷을 삭제 하는 것이 표준 동작입니다. 장치가 ICMP 조각화 필요 메시지를 패킷의 원래 원본으로 다시 보냅니다.

#### <a name="performance-implications-of-fragmentation"></a>조각화의 성능 영향

조각화는 성능에 부정적인 영향을 미칠 수 있습니다. 성능에 영향을 주는 주요 이유 중 하나는 패킷 조각화 및 리어셈블리의 CPU/메모리 영향입니다. 네트워크 장치에서 패킷을 조각화 해야 하는 경우 조각화를 수행 하기 위해 CPU/메모리 리소스를 할당 해야 합니다.

패킷이 리어셈블하는 경우에도 마찬가지입니다. 네트워크 장치는 수신 될 때까지 모든 조각을 저장 해야 원래 패킷으로 다시 어셈블할 수 있습니다. 이 조각 및 리어셈블리 프로세스는 대기 시간을 유발할 수도 있습니다.

조각화의 다른 가능한 부정적 의미는 조각화 된 패킷이 순서 대로 도착 하지 않을 수 있다는 것입니다. 패킷이 순서 대로 수신 되 면 일부 유형의 네트워크 장치에서 패킷을 삭제할 수 있습니다. 이 경우 전체 패킷을 다시 전송 해야 합니다.

조각은 일반적으로 네트워크 방화벽과 같은 보안 장치나 네트워크 장치의 수신 버퍼가 고갈 된 경우에 삭제 됩니다. 네트워크 장치의 수신 버퍼를 모두 사용 하는 경우 네트워크 장치에서 조각화 된 패킷을 리 리 려 하지만 패킷을 저장 하 고 reassume 리소스를 갖지 않습니다.

조각화는 부정적인 작업으로 볼 수 있지만 인터넷을 통해 다양 한 네트워크를 연결 하는 경우 조각화에 대 한 지원이 필요 합니다.

#### <a name="benefits-and-consequences-of-modifying-the-mtu"></a>MTU 수정의 이점 및 결과

일반적으로 MTU를 늘려서 보다 효율적인 네트워크를 만들 수 있습니다. 전송 된 모든 패킷에는 원래 패킷에 추가 된 헤더 정보가 있습니다. 조각화가 더 많은 패킷을 생성 하는 경우 헤더 오버 헤드가 증가 하 여 네트워크 효율성이 낮아집니다.

예를 들면 다음과 같습니다. 이더넷 헤더 크기는 14 바이트와 4 바이트 프레임 검사 시퀀스를 통해 프레임 일관성을 유지 합니다. 1 2000 바이트 패킷이 전송 되 면 18 바이트의 이더넷 오버 헤드가 네트워크에 추가 됩니다. 패킷이 1500 바이트 패킷과 500 바이트 패킷으로 조각화 되는 경우 각 패킷은 18 바이트의 이더넷 헤더 (총 36 바이트)를 포함 합니다.

MTU를 늘릴 경우 더 효율적인 네트워크를 만들 필요는 없습니다. 응용 프로그램이 500 바이트 패킷만 보내는 경우에는 MTU가 1500 바이트 또는 9000 바이트 인지에 관계 없이 동일한 헤더 오버 헤드가 발생 합니다. 네트워크는 MTU의 영향을 받는 더 큰 패킷 크기를 사용 하는 경우에만 더 효율적입니다.

#### <a name="azure-and-vm-mtu"></a>Azure 및 VM MTU

Azure Vm의 기본 MTU는 1500 바이트입니다. Azure Virtual Network 스택은 1400 바이트에서 패킷을 조각화 하려고 시도 합니다.

Vm의 MTU가 1500 인 경우에도 Virtual Network 스택은 1400 바이트로 패킷을 조각화 하므로 근본적으로 비효율적입니다. 네트워크 패킷의 비율이 1400 또는 1500 바이트 보다 훨씬 작습니다.

#### <a name="azure-and-fragmentation"></a>Azure 및 조각화

Virtual Network stack은 "순서가 잘못 된 조각" (즉, 원래의 조각화 된 순서로 도착 하지 않은 조각화 된 패킷을 삭제 하도록 설정 되어 있습니다. 이러한 패킷은 주로 FragmentSmack 이라는 11 월 2018에 발표 된 네트워크 보안 취약점 때문에 삭제 됩니다.

FragmentSmack는 Linux 커널이 조각화 된 IPv4 및 IPv6 패킷의 리어셈블리를 처리 하는 방법에 결함이 있습니다. 원격 공격자는이 결함을 사용 하 여 비용이 많이 드는 조각 리어셈블리 작업을 트리거할 수 있으며,이로 인해 대상 시스템에서 CPU가 증가 하 고 서비스가 거부 될 수 있습니다.

#### <a name="tune-the-mtu"></a>MTU 조정

다른 운영 체제에서와 마찬가지로 Azure VM MTU를 구성할 수 있습니다. 그러나 MTU를 구성 하는 경우 위에서 설명한 대로 Azure에서 발생 하는 조각화를 고려해 야 합니다.

사용자가 VM Mtu를 늘리지 않는 것은 권장 되지 않습니다. 이 토론은 Azure에서 MTU를 구현 하 고 조각화를 수행 하는 방법에 대 한 자세한 내용을 설명 하기 위한 것입니다.

> [!IMPORTANT]
>응용 프로그램 성능에 부정적인 영향을 미칠 수 있으므로 MTU 증가는 성능을 향상 시키는 것을 알 수 없습니다.
>
>

#### <a name="large-send-offload"></a>대량 송신 오프 로드

LSO (Large send offload)는 이더넷 어댑터에 대 한 패킷의 조각화를 오프 로드 하 여 네트워크 성능을 향상 시킬 수 있습니다. LSO를 사용 하도록 설정 하면 TCP/IP 스택은 대량 TCP 패킷을 만들고이를 전달 하기 전에이를 이더넷 어댑터에 전송 합니다. LSO의 혜택은 CPU에서 MTU를 준수 하는 크기로 패킷을 분할 하 고 해당 처리를 하드웨어에서 수행 되는 이더넷 인터페이스로 오프 로드 하는 것입니다. LSO의 이점에 대해 자세히 알아보려면 [large send Offload 지원](https://docs.microsoft.com/windows-hardware/drivers/network/performance-in-network-adapters#supporting-large-send-offload-lso)을 참조 하세요.

LSO를 사용 하는 경우 Azure 고객은 패킷 캡처를 수행할 때 많은 프레임 크기를 볼 수 있습니다. 이러한 많은 프레임 크기를 사용 하면 일부 고객이 조각화가 발생 하거나 그렇지 않을 때 많은 MTU를 사용 하 고 있다고 생각할 수 있습니다. LSO를 사용 하 여 이더넷 어댑터는 더 큰 TCP 패킷을 만들기 위해 더 큰 MSS (최대 세그먼트 크기)를 TCP/IP 스택에 보급할 수 있습니다. 이렇게 분할 되지 않은 전체 프레임은 이더넷 어댑터로 전달 되며 VM에서 수행 된 패킷 캡처에 표시 됩니다. 그러나 패킷은 이더넷 어댑터의 MTU에 따라 이더넷 어댑터에 의해 더 작은 여러 프레임으로 분할 됩니다.

### <a name="tcp-mss-window-scaling-and-pmtud"></a>TCP MSS 창 크기 조정 및 PMTUD

#### <a name="tcp-maximum-segment-size"></a>TCP 최대 세그먼트 크기

Tcp MSS (최대 세그먼트 크기)는 tcp 패킷의 조각화를 방지 하는 TCP 세그먼트의 크기를 제한 하는 설정입니다. 운영 체제는 일반적으로 다음 수식을 사용 하 여 MSS를 설정 합니다.

`MSS = MTU - (IP header size + TCP header size)`

IP 헤더와 TCP 헤더는 각각 20 바이트 또는 총 40 바이트입니다. 따라서 MTU가 1500 인 인터페이스의 MSS는 1460이 됩니다. 그러나 MSS는 구성 가능 합니다.

이 설정은 원본 및 대상 간에 TCP 세션이 설정 되어 있는 경우 TCP 3 방향 핸드셰이크에서에 동의한 것입니다. 양쪽 모두 MSS 값을 보내며 둘 중 낮은 값이 TCP 연결에 사용 됩니다.

원본 및 대상의 Mtu는 MSS 값을 결정 하는 유일한 요소는 아닙니다. Azure VPN Gateway을 비롯 한 VPN 게이트웨이와 같은 중간 네트워크 장치는 네트워크 성능을 최적화 하기 위해 원본 및 대상에 독립적으로 MTU를 조정할 수 있습니다.

#### <a name="path-mtu-discovery"></a>경로 MTU 검색

MSS가 협상 되었지만 사용할 수 있는 실제 MSS를 나타내지 않을 수 있습니다. 이는 원본과 대상 간의 경로에 있는 다른 네트워크 장치의 MTU 값이 원본 및 대상 보다 낮을 수 있기 때문입니다. 이 경우 MTU가 패킷 보다 작은 장치에서 패킷이 삭제 됩니다. 장치는 해당 MTU를 포함 하는 ICMP 조각화 필요 (유형 3, 코드 4) 메시지를 다시 보냅니다. 이 ICMP 메시지를 통해 원본 호스트는 해당 경로 MTU를 적절 하 게 줄일 수 있습니다. 이 프로세스를 PMTUD (경로 MTU 검색) 라고 합니다.

PMTUD 프로세스는 비효율적 이며 네트워크 성능에 영향을 줍니다. 네트워크 경로의 MTU를 초과 하는 패킷을 전송 하는 경우에는 더 낮은 MSS로 패킷을 다시 전송 해야 합니다. 발신자가 ICMP 조각화 필요 메시지를 받지 못한 경우, 경로 (일반적으로 *Pmtud 블랙 홀*이라고 함)의 네트워크 방화벽 때문에 보낸 사람이 MSS를 낮출 필요가 없다는 것을 알 수 없으며 지속적으로 패킷을 재전송 합니다. Azure VM MTU를 늘리지 않는 것이 좋습니다.

#### <a name="vpn-and-mtu"></a>VPN 및 MTU

캡슐화를 수행 하는 Vm (예: IPsec Vpn)을 사용 하는 경우 패킷 크기 및 MTU와 관련 된 몇 가지 추가 고려 사항이 있습니다. Vpn은 패킷에 더 많은 헤더를 추가 합니다. 그러면 패킷 크기가 늘어나고 더 작은 MSS가 필요 합니다.

Azure의 경우 TCP MSS 고정을 1350 바이트 및 터널 인터페이스 MTU를 1400으로 설정 하는 것이 좋습니다. 자세한 내용은 [VPN 장치 및 IPSec/IKE 매개 변수 페이지](https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-about-vpn-devices)를 참조 하세요.

### <a name="latency-round-trip-time-and-tcp-window-scaling"></a>대기 시간, 왕복 시간 및 TCP 창 배율

#### <a name="latency-and-round-trip-time"></a>대기 시간 및 왕복 시간

네트워크 대기 시간은 파이버 광 네트워크에서의 빛 속도에 따라 결정 됩니다. 또한 TCP의 네트워크 처리량은 두 네트워크 장치 간의 RTT (왕복 시간)에 의해 효과적으로 관리 됩니다.

| | | | |
|-|-|-|-|
|**Route**|**거리**|**단방향 시간**|**RTT**|
|뉴욕 ~ 샌프란시스코|4148 km|21ms|42 밀리초|
|뉴욕 ~ 런던|5585 km|28 밀리초|56 밀리초|
|뉴욕 ~ 시드니|15993 km|80ms|160 밀리초|

다음 표에서는 두 위치 간의 직선 거리를 보여 줍니다. 네트워크에서 거리는 일반적으로 직선 거리 보다 깁니다. 다음은 빛 속도의 영향을 받은 최소 RTT를 계산 하는 간단한 수식입니다.

`minimum RTT = 2 * (Distance in kilometers / Speed of propagation)`

전파 속도는 200을 사용할 수 있습니다. 조명이 1 밀리초로 이동 하는 거리 (킬로미터)입니다.

예를 들어 샌프란시스코와 샌프란시스코를 만들어 보겠습니다. 직선 거리가 4148입니다. 수식에 해당 값을 연결 하면 다음과 같이 표시 됩니다.

`Minimum RTT = 2 * (4,148 / 200)`

수식의 출력은 밀리초 단위입니다.

최상의 네트워크 성능을 얻으려면 논리적 옵션은 두 항목 사이에 최단 거리를 사용 하 여 대상을 선택 하는 것입니다. 또한 트래픽 경로를 최적화 하 고 대기 시간을 줄이도록 가상 네트워크를 디자인 해야 합니다. 자세한 내용은이 문서의 "네트워크 디자인 고려 사항" 섹션을 참조 하세요.

#### <a name="latency-and-round-trip-time-effects-on-tcp"></a>TCP에 대 한 대기 시간 및 왕복 시간 효과

라운드트립 시간은 최대 TCP 처리량에 직접적인 영향을 주지 않습니다. TCP 프로토콜에서 *window 크기* 는 발신자가 수신자 로부터 승인을 받아야 하는 tcp 연결을 통해 전송할 수 있는 최대 트래픽 양입니다. TCP MSS가 1460로 설정 되 고 TCP 창 크기가 65535로 설정 된 경우 발신자는 수신자 로부터 승인을 받기 전에 45 패킷을 보낼 수 있습니다. 발신자가 승인을 받지 못하면 데이터를 다시 전송 합니다. 수식은 다음과 같습니다.

`TCP window size / TCP MSS = packets sent`

이 예제에서 65535/1460은 45로 반올림 됩니다.

안정적인 데이터 배달을 보장 하는 메커니즘인 "승인 대기 중" 상태는 RTT가 TCP 처리량에 영향을 주는 것입니다. 전송 자가 승인을 기다리는 시간이 길수록 더 많은 데이터를 전송 하기 전에 대기 해야 합니다.

단일 TCP 연결의 최대 처리량을 계산 하는 수식은 다음과 같습니다.

`Window size / (RTT latency in milliseconds / 1,000) = maximum bytes/second`

이 표에서는 단일 TCP 연결의 최대 메가바이트/초 처리량을 보여 줍니다. 가독성을 위해 측정 단위에는 메가바이트를 사용 합니다.

| | | | |
|-|-|-|-|
|**TCP 창 크기 (바이트)**|**RTT 대기 시간 (밀리초)**|**최대 메가바이트/초 처리량**|**최대 메가 비트/초 처리량**|
|65,535|1|65.54|524.29|
|65,535|30|2.18|17.48|
|65,535|60|1.09|8.74|
|65,535|90|.73|5.83|
|65,535|120|.55|4.37|

패킷이 손실 되 면 보낸 사람이 이미 보낸 데이터를 재전송 하는 동안 TCP 연결의 최대 처리량이 줄어듭니다.

#### <a name="tcp-window-scaling"></a>TCP 창 크기 조정

TCP 창 크기 조정은 승인이 필요 하기 전에 더 많은 데이터를 전송할 수 있도록 TCP 창 크기를 동적으로 늘리는 기술입니다. 이전 예제에서 45 패킷은 승인을 요청 하기 전에 전송 됩니다. 승인이 필요 하기 전에 전송할 수 있는 패킷 수를 늘리면 발신자가 승인을 대기 하는 횟수가 줄어들어 TCP 최대 처리량이 증가 합니다.

다음 표에서는 이러한 관계를 보여 줍니다.

| | | | |
|-|-|-|-|
|**TCP 창 크기 (바이트)**|**RTT 대기 시간 (밀리초)**|**최대 메가바이트/초 처리량**|**최대 메가 비트/초 처리량**|
|65,535|30|2.18|17.48|
|131070|30|4.37|34.95|
|262140|30|8.74|69.91|
|524280|30|17.48|139.81|

그러나 TCP 창 크기의 TCP 헤더 값은 2 바이트 길이입니다. 즉, 수신 기간의 최대값은 65535입니다. 최대 창 크기를 늘리려면 TCP 창 배율 인수가 도입 되었습니다.

배율 인수는 운영 체제에서 구성할 수 있는 설정 이기도 합니다. 배율 인수를 사용 하 여 TCP 창 크기를 계산 하는 수식은 다음과 같습니다.

`TCP window size = TCP window size in bytes \* (2^scale factor)`

다음은 창 배율 인수 3의 계산과 창 크기 (65535)입니다.

`65,535 \* (2^3) = 262,140 bytes`

배율 인수가 14 이면 TCP 창 크기가 14 (허용 되는 최대 오프셋)입니다. TCP 창 크기는 1073725440 바이트 (8.5 기가 비트)입니다.

#### <a name="support-for-tcp-window-scaling"></a>TCP 창 크기 조정 지원

Windows는 서로 다른 연결 형식에 대해 서로 다른 배율 인수를 설정할 수 있습니다. (연결의 클래스에는 데이터 센터, 인터넷 등이 있습니다.) PowerShell 명령을 사용 하 여 `Get-NetTCPConnection` 창 크기 조정 연결 유형을 볼 수 있습니다.

```powershell
Get-NetTCPConnection
```

`Get-NetTCPSetting`PowerShell 명령을 사용 하 여 각 클래스의 값을 볼 수 있습니다.

```powershell
Get-NetTCPSetting
```

PowerShell 명령을 사용 하 여 Windows에서 초기 TCP 창 크기와 TCP 크기 조정 인수를 설정할 수 있습니다 `Set-NetTCPSetting` . 자세한 내용은 [NetTCPSetting](https://docs.microsoft.com/powershell/module/nettcpip/set-nettcpsetting?view=win10-ps)를 참조 하세요.

```powershell
Set-NetTCPSetting
```

다음은에 대 한 유효한 TCP 설정입니다 `AutoTuningLevel` .

| | | | |
|-|-|-|-|
|**AutoTuningLevel**|**배율 인수**|**승수 크기 조정**|**<br/>최대 창 크기를 계산 하는 수식**|
|사용 안 함|None|None|창 크기|
|제한|4|2 ^ 4|창 크기 * (2 ^ 4)|
|매우 제한|2|2 ^ 2|창 크기 * (2 ^ 2)|
|보통|8|2 ^ 8|창 크기 * (2 ^ 8)|
|실험적|14|2 ^ 14|창 크기 * (2 ^ 14)|

이러한 설정은 TCP 성능에 영향을 미칠 가능성이 가장 높습니다. 하지만 인터넷을 통해 Azure의 제어 외부에 있는 다른 많은 요소가 TCP 성능에 영향을 줄 수도 있습니다.

#### <a name="increase-mtu-size"></a>MTU 크기 늘리기

더 큰 MTU는 더 큰 MSS를 의미 하므로 MTU를 늘리면 TCP 성능이 향상 될 수 있습니다. 그렇지 않을 가능성이 있습니다. TCP 트래픽 외에 패킷 크기에는 장단점이 있습니다. 앞에서 설명한 대로 TCP 처리량 성능에 영향을 주는 가장 중요 한 요인은 TCP 창 크기, 패킷 손실 및 RTT입니다.

> [!IMPORTANT]
> Azure 고객은 가상 머신에서 기본 MTU 값을 변경 하지 않는 것이 좋습니다.
>
>

### <a name="accelerated-networking-and-receive-side-scaling"></a>가속 네트워킹 및 수신측 배율

#### <a name="accelerated-networking"></a>가속된 네트워킹

가상 컴퓨터 네트워크 기능은 게스트 VM과 하이퍼바이저/호스트 모두에서 CPU 집약적입니다. 호스트를 통해 전송은 되는 모든 패킷은 모든 가상 네트워크 캡슐화 및 캡슐화 해제를 포함 하 여 호스트 CPU에 의해 소프트웨어에서 처리 됩니다. 따라서 호스트를 통과 하는 트래픽이 많을 수록 CPU 부하가 높아집니다. 또한 호스트 CPU가 다른 작업을 사용 하는 경우 네트워크 처리량 및 대기 시간에도 영향을 줍니다. Azure는 가속화 된 네트워킹을 통해이 문제를 해결 합니다.

가속화 된 네트워킹은 Azure의 사내 프로그래밍 가능 하드웨어 및 SR-IOV와 같은 기술을 통해 일관 된 ultralow 네트워크 대기 시간을 제공 합니다. 가속화 된 네트워킹은 Cpu 및 FPGA 기반 SmartNICs로 많은 Azure 소프트웨어 정의 네트워킹 스택을 이동 합니다. 이러한 변경을 통해 최종 사용자 응용 프로그램에서 계산 주기를 회수할 수 있습니다 .이를 통해 VM에 부하를 줄이고, 지터를 줄이고, 대기 시간의 불일치를 줄일 수 있습니다. 즉, 성능이 더 결정적 일 수 있습니다.

가속화 된 네트워킹을 사용 하면 게스트 VM에서 호스트를 우회 하 고 호스트의 SmartNIC를 사용 하 여 데이터 경로를 직접 설정할 수 있으므로 성능이 향상 됩니다. 가속화 된 네트워킹의 몇 가지 이점은 다음과 같습니다.

- **낮은 대기 시간/초당 패킷 (초당 패킷 수)**: 데이터 경로에서 가상 스위치를 제거 하면 호스트가 호스트에서 처리 하는 데 걸리는 시간을 제거 하 고 VM에서 처리 될 수 있는 패킷 수를 늘립니다.

- **감소 된 지터**: 가상 스위치 처리는 적용 해야 하는 정책의 양과 처리를 수행 하는 CPU의 워크 로드에 따라 달라 집니다. 정책 적용을 하드웨어로 오프 로드 하면 VM에 직접 패킷을 전달 하 여 이러한 가변성을 제거 하 여 호스트 간 통신과 모든 소프트웨어 인터럽트 및 컨텍스트 전환을 제거 합니다.

- **Cpu 사용률 감소**: 호스트에서 가상 스위치를 건너뛰면 네트워크 트래픽을 처리 하기 위한 cpu 사용률을 줄일 수 있습니다.

가속 네트워킹을 사용 하려면 해당 하는 각 VM에서 명시적으로 사용 하도록 설정 해야 합니다. 지침은 [가속화 된 네트워킹을 사용 하 여 Linux 가상 머신 만들기](https://docs.microsoft.com/azure/virtual-network/create-vm-accelerated-networking-cli) 를 참조 하세요.

#### <a name="receive-side-scaling"></a>수신측 배율

RSS (수신측 배율)는 다중 프로세서 시스템의 여러 Cpu에서 수신 처리를 분산 하 여 네트워크 트래픽 수신을 보다 효율적으로 분산 하는 네트워크 드라이버 기술입니다. 간단히 말해 RSS를 사용 하면 시스템에서 사용 가능한 모든 Cpu를 사용 하는 것이 아니라 사용 가능한 모든 Cpu를 사용 하므로 더 많은 트래픽을 처리할 수 있습니다. RSS에 대 한 자세한 기술 설명은 [수신측 배율 소개](https://docs.microsoft.com/windows-hardware/drivers/network/introduction-to-receive-side-scaling)를 참조 하세요.

VM에서 가속화 된 네트워킹을 사용 하는 경우 최상의 성능을 얻으려면 RSS를 사용 하도록 설정 해야 합니다. 또한 RSS는 가속화 된 네트워킹을 사용 하지 않는 Vm에 대 한 혜택을 제공할 수 있습니다. RSS를 사용 하도록 설정 했는지 여부를 확인 하는 방법과이를 사용 하도록 설정 하는 방법에 대 한 개요는 [Azure 가상 컴퓨터의 네트워크 처리량 최적화](https://aka.ms/FastVM)를 참조 하세요.

### <a name="tcp-time_wait-and-time_wait-assassination"></a>TCP TIME_WAIT 및 TIME_WAIT assassination

TCP TIME_WAIT는 네트워크 및 응용 프로그램 성능에 영향을 주는 또 다른 일반적인 설정입니다. TCP를 정상적으로 수행 하는 동안 클라이언트 또는 서버 (원본 IP: 원본 포트 + 대상 IP: 대상 포트)로 많은 소켓을 열고 닫는 사용 중인 Vm에서 지정 된 소켓이 오랜 시간 동안 TIME_WAIT 상태로 끝날 수 있습니다. TIME_WAIT 상태는를 닫기 전에 소켓에서 추가 데이터를 배달 하도록 허용 하는 것입니다. 따라서 TCP/IP 스택은 일반적으로 클라이언트의 TCP SYN 패킷을 자동으로 삭제 하 여 소켓을 다시 사용 하는 것을 방지 합니다.

소켓이 TIME_WAIT 된 시간을 구성할 수 있습니다. 30 초에서 240 초 사이에 있을 수 있습니다. 소켓은 유한 리소스 이며 지정 된 시간에 사용할 수 있는 소켓의 수를 구성할 수 있습니다. 사용 가능한 소켓 수는 일반적으로 약 3만입니다. 사용 가능한 소켓이 사용 되는 경우 또는 클라이언트와 서버의 TIME_WAIT 설정이 일치 하지 않는 경우, VM이 TIME_WAIT 상태에서 소켓을 다시 사용 하려고 하면 TCP SYN 패킷이 자동으로 삭제 되므로 새 연결이 실패 합니다.

아웃 바운드 소켓의 포트 범위 값은 일반적으로 운영 체제의 TCP/IP 스택 내에서 구성할 수 있습니다. TCP TIME_WAIT 설정 및 소켓 재사용의 경우에도 마찬가지입니다. 이러한 수치를 변경 하면 확장성이 향상 될 수 있습니다. 그러나 이러한 변경으로 인해 상호 운용성 문제가 발생할 수 있습니다. 이러한 값을 변경 하는 경우 주의 해야 합니다.

TIME_WAIT assassination를 사용 하 여 이러한 크기 조정 제한을 해결할 수 있습니다. TIME_WAIT assassination를 사용 하면 새 연결의 IP 패킷에 있는 시퀀스 번호가 이전 연결에서 마지막 패킷의 시퀀스 번호를 초과 하는 경우와 같은 특정 상황에서 소켓을 다시 사용할 수 있습니다. 이 경우 운영 체제는 새 연결을 설정할 수 있도록 허용 하 고 (새 SYN/ACK를 수락 함), TIME_WAIT 상태 였던 이전 연결을 강제로 닫습니다. 이 기능은 Azure의 Windows Vm에서 지원 됩니다. 다른 Vm의 지원에 대 한 자세한 내용은 OS 공급 업체에 문의 하세요.

TCP TIME_WAIT 설정 및 원본 포트 범위를 구성 하는 방법에 대 한 자세한 내용은 [네트워크 성능을 향상 시키기 위해 수정할 수 있는 설정](https://docs.microsoft.com/biztalk/technical-guides/settings-that-can-be-modified-to-improve-network-performance)을 참조 하세요.

## <a name="virtual-network-factors-that-can-affect-performance"></a>성능에 영향을 줄 수 있는 가상 네트워크 요소

### <a name="vm-maximum-outbound-throughput"></a>VM 최대 아웃 바운드 처리량

Azure는 다양 한 성능 기능을 포함 하는 다양 한 VM 크기와 유형을 제공 합니다. 이러한 기능 중 하나는 네트워크 처리량 (또는 대역폭) 이며 Mbps (초당 메가 비트)로 측정 됩니다. 가상 컴퓨터는 공유 하드웨어에서 호스트 되므로 동일한 하드웨어를 사용 하 여 가상 컴퓨터 간에 네트워크 용량을 비교적 공유 해야 합니다. 더 큰 가상 컴퓨터에 더 작은 가상 컴퓨터 보다 더 많은 대역폭이 할당 됩니다.

각 가상 머신에 할당된 네트워크 대역폭은 가상 머신에서의 송신(아웃바운드) 트래픽으로 측정됩니다. 가상 컴퓨터에서 나가는 모든 네트워크 트래픽은 대상에 관계없이 할당된 제한에 대해 계산됩니다. 예를 들어, 가상 머신의 제한이 1000-Mbps 인 경우 해당 제한은 동일한 가상 네트워크의 다른 가상 머신을 대상으로 하는 아웃 바운드 트래픽 또는 Azure 외부에 있는 다른 가상 머신을 대상으로 하는지 여부를 적용 합니다.

수신은 측정되거나 직접 제한되지 않습니다. 그러나 CPU 및 저장소 제한과 같은 다른 요소는 들어오는 데이터를 처리 하는 가상 컴퓨터의 기능에 영향을 줄 수 있습니다.

가속화 된 네트워킹은 대기 시간, 처리량 및 CPU 사용률을 포함 하 여 네트워크 성능을 향상 시 키도 록 설계 되었습니다. 가속화 된 네트워킹은 가상 컴퓨터의 처리량을 향상 시킬 수 있지만 가상 컴퓨터의 할당 된 대역폭 까지만 수행할 수 있습니다.

Azure virtual machines에는 하나 이상의 네트워크 인터페이스가 연결 되어 있습니다. 여기에는 여러 가지가 있을 수 있습니다. 가상 컴퓨터에 할당 된 대역폭은 컴퓨터에 연결 된 모든 네트워크 인터페이스에서 모든 아웃 바운드 트래픽의 합계입니다. 즉, 컴퓨터에 연결 된 네트워크 인터페이스 수에 관계 없이 가상 컴퓨터 별로 대역폭이 할당 됩니다.

예상 되는 아웃 바운드 처리량과 각 VM 크기에서 지 원하는 네트워크 인터페이스 수는 [Azure의 Windows 가상 머신에 대 한 크기](https://docs.microsoft.com/azure/virtual-machines/windows/sizes?toc=%2fazure%2fvirtual-network%2ftoc.json)에 자세히 설명 되어 있습니다. 최대 처리량을 확인 하려면 **일반적인 용도**와 같은 유형을 선택한 다음 결과 페이지 (예: "Dv2 시리즈")에서 크기 시리즈에 대 한 섹션을 찾습니다. 각 계열에 대해 마지막 열에는 "최대 Nic/예상 네트워크 대역폭 (Mbps)" 이라는 네트워킹 사양을 제공 하는 테이블이 있습니다.

처리량 제한은 가상 컴퓨터에 적용됩니다. 처리량은 다음 요인의 영향을 받지 않습니다.

- **네트워크 인터페이스 수**: 대역폭 제한은 가상 컴퓨터에서 모든 아웃 바운드 트래픽의 합계에 적용 됩니다.

- **가속화 된 네트워킹**:이 기능은 게시 된 제한을 달성 하는 데 도움이 될 수 있지만 제한을 변경 하지는 않습니다.

- **트래픽 대상**: 모든 대상이 아웃바운드 제한에 대해 계산됩니다.

- **프로토콜**: 모든 프로토콜을 통한 모든 아웃바운드 트래픽이 제한에 대해 계산됩니다.

자세한 내용은 [가상 컴퓨터 네트워크 대역폭](https://aka.ms/AzureBandwidth)을 참조 하세요.

### <a name="internet-performance-considerations"></a>인터넷 성능 고려 사항

이 문서 전체에서 설명 했 듯이, 인터넷의 요소와 Azure의 제어 범위는 네트워크 성능에 영향을 줄 수 있습니다. 이러한 요소 중 일부는 다음과 같습니다.

- **대기 시간**: 두 대상 간의 라운드트립 시간은 중간 네트워크에서 발생 하는 문제의 영향을 받을 수 있습니다. 즉, "최단" 거리 경로를 사용 하지 않는 트래픽과, 최적의 피어 링 경로에 의해 영향을 받을 수 있습니다.

- **패킷 손실**: 패킷 손실은 네트워크 정체, 실제 경로 문제 및 실적이 떨어지는 네트워크 장치에 의해 발생할 수 있습니다.

- **MTU 크기/조각화**: 경로를 따라 조각화 하면 데이터가 도착 하거나 패킷을 배달 하는 데 영향을 줄 수 있는 패킷을 벗어난 지연 시간이 발생할 수 있습니다.

경로 추적는 원본 장치와 대상 장치 간의 모든 네트워크 경로를 따라 네트워크 성능 특성 (예: 패킷 손실 및 대기 시간)을 측정 하는 데 적합 한 도구입니다.

### <a name="network-design-considerations"></a>네트워크 디자인 고려 사항

이 문서의 앞부분에서 설명한 고려 사항과 함께 가상 네트워크의 토폴로지는 네트워크의 성능에 영향을 줄 수 있습니다. 예를 들어 트래픽을 단일 허브 가상 네트워크에 전역적으로 backhauls 하는 허브 및 스포크 설계는 네트워크 대기 시간을 도입 하 여 전반적인 네트워크 성능에 영향을 줍니다.

네트워크 트래픽이 통과 하는 네트워크 장치 수는 전체 대기 시간에도 영향을 줄 수 있습니다. 예를 들어 허브 및 스포크 디자인에서 트래픽이 인터넷에 전송을 하기 전에 스포크 네트워크 가상 어플라이언스 및 허브 가상 어플라이언스를 통해 전달 되는 경우 네트워크 가상 어플라이언스는 대기 시간이 발생할 수 있습니다.

### <a name="azure-regions-virtual-networks-and-latency"></a>Azure 지역, 가상 네트워크 및 대기 시간

Azure 지역은 일반적인 지역에 존재 하는 여러 데이터 센터로 구성 됩니다. 이러한 데이터 센터는 실제로 서로의 옆에 있지 않을 수 있습니다. 경우에 따라 10 킬로미터 만큼 구분 됩니다. 가상 네트워크는 Azure 실제 데이터 센터 네트워크를 기반으로 하는 논리적 오버레이입니다. 가상 네트워크는 데이터 센터 내의 특정 네트워크 토폴로지를 의미 하지 않습니다.

예를 들어 동일한 가상 네트워크 및 서브넷에 있는 두 Vm은 서로 다른 랙, 행 또는 데이터 센터에 있을 수 있습니다. 파이버 광 케이블의 피트 또는 킬로미터의 광섬유 케이블을 기준으로 분리할 수 있습니다. 이러한 변형으로 인해 서로 다른 Vm 간에 가변 대기 시간 (몇 밀리초 차이가 있음)이 발생할 수 있습니다.

Vm의 지리적 배치와 두 Vm 간의 잠재적인 결과 대기 시간은 가용성 집합 및 가용성 영역 구성에 의해 영향을 받을 수 있습니다. 그러나 한 지역의 데이터 센터 간 거리는 지역에 따라 달라 지 며 주로 지역에서 데이터 센터 토폴로지의 영향을 받습니다.

### <a name="source-nat-port-exhaustion"></a>원본 NAT 포트 소모

Azure의 배포는 공용 인터넷 및/또는 공용 IP 공간에서 Azure 외부의 끝점과 통신할 수 있습니다. 인스턴스가 아웃 바운드 연결을 시작 하면 Azure는 개인 IP 주소를 공용 IP 주소에 동적으로 매핑합니다. Azure에서이 매핑을 만든 후 아웃 바운드 시작 흐름에 대 한 반환 트래픽도 흐름이 시작 된 개인 IP 주소에 도달할 수 있습니다.

모든 아웃 바운드 연결에 대해 Azure Load Balancer는 일정 시간 동안이 매핑을 유지 해야 합니다. Azure의 다중 테 넌 트 특성을 사용 하면 모든 VM의 모든 아웃 바운드 흐름에 대해이 매핑을 유지 관리 하는 것은 리소스를 많이 사용 합니다 따라서 Azure Virtual Network의 구성에 따라 설정 되는 제한이 있습니다. 또는 더 정확 하 게 말해 Azure VM은 지정 된 시간에 특정 수의 아웃 바운드 연결만 만들 수 있습니다. 이러한 제한에 도달 하면 VM에서 더 많은 아웃 바운드 연결을 만들 수 없습니다.

그러나이 동작은 구성 가능 합니다. SNAT 및 SNAT 포트 소모에 대 한 자세한 내용은 [이 문서](https://docs.microsoft.com/azure/load-balancer/load-balancer-outbound-connections)를 참조 하세요.

## <a name="measure-network-performance-on-azure"></a>Azure에서 네트워크 성능 측정

이 문서의 다양 한 성능 최대값은 두 Vm 간의 네트워크 대기 시간/RTT (왕복 시간)와 관련이 있습니다. 이 섹션에서는 대기 시간/RTT를 테스트 하는 방법과 TCP 성능 및 VM 네트워크 성능을 테스트 하는 방법에 대 한 몇 가지 제안을 제공 합니다. 이 섹션에 설명 된 기술을 사용 하 여 이전에 설명한 TCP/IP 및 네트워크 값을 튜닝 하 고 성능 테스트할 수 있습니다. 대기 시간, MTU, MSS 및 창 크기 값을 이전에 제공 된 계산에 연결 하 고 이론적 최대값을 테스트 중에 관찰 하는 실제 값과 비교할 수 있습니다.

### <a name="measure-round-trip-time-and-packet-loss"></a>라운드트립 시간 및 패킷 손실 측정

TCP 성능은 RTT 및 패킷 손실에 크게 의존 합니다. Windows 및 Linux에서 사용할 수 있는 PING 유틸리티는 RTT 및 패킷 손실을 측정 하는 가장 쉬운 방법을 제공 합니다. PING의 출력에는 원본 및 대상 간의 최소/최대/평균 대기 시간이 표시 됩니다. 또한 패킷 손실이 표시 됩니다. PING은 기본적으로 ICMP 프로토콜을 사용 합니다. PsPing을 사용 하 여 TCP RTT를 테스트할 수 있습니다. 자세한 내용은 [Psping](https://docs.microsoft.com/sysinternals/downloads/psping)을 참조 하세요.

### <a name="measure-actual-throughput-of-a-tcp-connection"></a>TCP 연결의 실제 처리량 측정

NTttcp는 Linux 또는 Windows VM의 TCP 성능을 테스트 하기 위한 도구입니다. 다양 한 TCP 설정을 변경한 다음 NTttcp를 사용 하 여 혜택을 테스트할 수 있습니다. 이러한 응용 프로그램은 Azure AD Graph API를 사용할 수 있습니다. 자세한 내용은 다음 리소스를 참조하세요.

- [대역폭/처리량 테스트 (NTttcp)](https://aka.ms/TestNetworkThroughput)

- [NTttcp 유틸리티](https://gallery.technet.microsoft.com/NTttcp-Version-528-Now-f8b12769)

### <a name="measure-actual-bandwidth-of-a-virtual-machine"></a>가상 컴퓨터의 실제 대역폭 측정

IPerf 라는 도구를 사용 하 여 다양 한 VM 유형, 가속화 된 네트워킹 등의 성능을 테스트할 수 있습니다. iPerf는 Linux 및 Windows 에서도 사용할 수 있습니다. iPerf는 TCP 또는 UDP를 사용 하 여 전체 네트워크 처리량을 테스트할 수 있습니다. iPerf TCP 처리량 테스트는이 문서에서 설명 하는 요소 (예: 대기 시간 및 RTT)의 영향을 받습니다. 따라서 최대 처리량을 테스트 하려는 경우에는 UDP가 더 나은 결과를 얻을 수 있습니다.

자세한 내용은 다음 문서를 참조하세요.

- [Express 경로 네트워크 성능 문제 해결](https://docs.microsoft.com/azure/expressroute/expressroute-troubleshooting-network-performance)

- [가상 네트워크에 대한 VPN 처리량의 유효성을 검사하는 방법](https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-validate-throughput-to-vnet)

### <a name="detect-inefficient-tcp-behaviors"></a>비효율적인 TCP 동작 검색

패킷 캡처에서 Azure 고객은 네트워크 성능 문제를 나타낼 수 있는 tcp 플래그 (SACK, DUP ACK, 재전송 및 빠른 재전송)가 있는 TCP 패킷을 볼 수 있습니다. 이러한 패킷은 특히 패킷 손실의 결과로 나타나는 네트워크 비효율성을 표시 합니다. 하지만 패킷 손실은 Azure 성능 문제로 인해 발생 하는 것은 아닙니다. 성능 문제는 응용 프로그램 문제, 운영 체제 문제 또는 Azure 플랫폼과 직접적인 관련이 없을 수 있는 기타 문제의 결과일 수 있습니다.

또한 일부 재전송 및 중복 Ack는 네트워크에서 정상입니다. TCP 프로토콜은 안정적으로 빌드됩니다. 패킷 캡처에서 이러한 TCP 패킷의 증명 정보는 과도 한 경우를 제외 하 고는 시스템 네트워크 문제를 나타내지는 않습니다.

이러한 패킷 유형은이 문서의 다른 섹션에 설명 된 이유로 TCP 처리량이 최대 성능을 달성 하지 않는다는 것을 나타냅니다.

## <a name="next-steps"></a>다음 단계

이제 Azure Vm에 대 한 TCP/IP 성능 조정에 대해 알아보았습니다. 이제 [가상 네트워크를 계획](https://docs.microsoft.com/azure/virtual-network/virtual-network-vnet-plan-design-arm) 하는 데 필요한 기타 고려 사항 또는 [가상 네트워크 연결 및 구성에 대해 자세히 알아볼](https://docs.microsoft.com/azure/virtual-network/)수 있습니다.
