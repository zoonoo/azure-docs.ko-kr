---
title: Visual Studio 및 C#을 사용하는 Apache Storm 토폴로지 - Azure HDInsight
description: C#으로 Storm 토폴로지를 만드는 방법을 알아봅니다. Visual studio 용 Hadoop 도구를 사용 하 여 Visual Studio에서 단어 개수 토폴로지를 만듭니다.
ROBOTS: NOINDEX
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 12/31/2019
ms.openlocfilehash: 1903c2faab865152d1f3666f3c9dadd745058b56
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/28/2020
ms.locfileid: "75612294"
---
# <a name="develop-c-topologies-for-apache-storm-by-using-the-data-lake-tools-for-visual-studio"></a>Data Lake tools for Visual Studio를 사용하여 Apache Storm의 C# 토폴로지 개발

Visual Studio용 Azure Data Lake(Apache Hadoop) 도구를 사용하여 C# Apache Storm 토폴로지를 만드는 방법을 알아봅니다. 이 문서는 Visual Studio에서 Storm 프로젝트를 만들고, 프로젝트를 로컬로 테스트하고, Azure HDInsight 클러스터에서 Apache Storm에 배포하는 과정을 보여 줍니다.

또한 C# 및 Java 구성 요소를 사용하는 하이브리드 토폴로지를 만드는 방법에 대해서도 배웁니다.

C # 토폴로지에서는 .NET 4.5을 사용 하 고 Mono를 사용 하 여 HDInsight 클러스터에서 실행 합니다. 잠재적 호환성 문제에 대 한 자세한 내용은 [Mono 호환성](https://www.mono-project.com/docs/about-mono/compatibility/)을 참조 하세요. C # 토폴로지를 사용 하려면 프로젝트에서 사용 하 `Microsoft.SCP.Net.SDK` 는 NuGet 패키지를 0.10.0.6 이상 이상 버전으로 업데이트 해야 합니다. 패키지 버전은 HDInsight에 설치된 Storm의 주 버전과도 일치해야 합니다.

| HDInsight 버전 | Apache Storm 버전 | SCP.NET 버전 | 기본 모노 버전 |
|:-----------------:|:-------------:|:---------------:|:--------------------:|
| 3.4 | 0.10.0.x | 0.10.0.x | 3.2.8 |
| 3.5 | 1.0.2.x | 1.0.0.x | 4.2.1 |
| 3.6 | 1.1.0.x | 1.0.0.x | 4.2.8 |

## <a name="prerequisite"></a>필수 요소

HDInsight의 Apache Storm 클러스터. [Azure Portal을 사용하여 Apache Hadoop 클러스터 만들기](../hdinsight-hadoop-create-linux-clusters-portal.md)를 참조하고 **클러스터 유형**에 **Storm**을 선택합니다.

## <a name="install-visual-studio"></a>Visual Studio 설치

[Visual Studio](https://visualstudio.microsoft.com/downloads/)를 사용 하 여 SCP.NET로 c # 토폴로지를 개발할 수 있습니다. 이 지침에서는 Visual Studio 2019을 사용 하지만 이전 버전의 Visual Studio를 사용할 수도 있습니다.

## <a name="install-data-lake-tools-for-visual-studio"></a>Data Lake Tools for Visual Studio 설치

Data Lake tools for Visual Studio를 설치하려면 [Data Lake tools for Visual Studio 시작](../hadoop/apache-hadoop-visual-studio-tools-get-started.md#install-data-lake-tools-for-visual-studio)을 참조하세요.

## <a name="install-java"></a>Java 설치

Visual Studio에서 Storm 토폴로지를 제출하면 SCP.NET은 토폴로지 및 종속성이 포함된 zip 파일을 생성합니다. Java는 Linux 기반 클러스터와 호환이 더 잘되는 형식을 사용하기 때문에 이러한 zip 파일을 만드는 데 사용됩니다.

1. 개발 환경에 JDK(Java Developer Kit) 7 이상을 설치합니다. Oracle JDK는 [Oracle](https://openjdk.java.net/)에서 가져올 수 있습니다. [다른 Java 배포](/java/azure/jdk/)를 사용할 수도 있습니다.

2. `JAVA_HOME` 환경 변수를 Java가 포함 된 디렉터리로 설정 합니다.

3. 디렉터리를 `PATH` `%JAVA_HOME%\bin` 포함 하도록 환경 변수를 설정 합니다.

다음 c # 콘솔 응용 프로그램을 빌드하고 실행 하 여 Java와 JDK가 올바르게 설치 되었는지 확인할 수 있습니다.

```csharp
using System;
using System.IO;
namespace ConsoleApplication2
{
   class Program
   {
       static void Main(string[] args)
       {
           string javaHome = Environment.GetEnvironmentVariable("JAVA_HOME");
           if (!string.IsNullOrEmpty(javaHome))
           {
               string jarExe = Path.Combine(javaHome + @"\bin", "jar.exe");
               if (File.Exists(jarExe))
               {
                   Console.WriteLine("JAVA Is Installed properly");
                    return;
               }
               else
               {
                   Console.WriteLine("A valid JAVA JDK is not found. Looks like JRE is installed instead of JDK.");
               }
           }
           else
           {
             Console.WriteLine("A valid JAVA JDK is not found. JAVA_HOME environment variable is not set.");
           }
       }  
   }
}
```

## <a name="apache-storm-templates"></a>Apache Storm 템플릿

Data Lake Tools for Visual Studio는 다음 템플릿을 제공합니다.

| 프로젝트 형식 | 데모 |
| --- | --- |
| Storm 애플리케이션 |빈 Storm 토폴로지 프로젝트 |
| Storm Azure SQL 기록기 샘플 |Azure SQL Database에 쓰는 방법. |
| Storm Azure Cosmos DB 판독기 샘플 |Azure Cosmos DB에서 읽는 방법 |
| Storm Azure Cosmos DB 기록기 샘플 |Azure Cosmos DB에 기록하는 방법 |
| Storm 이벤트 허브 판독기 샘플 |Azure Event Hubs에서 읽는 방법 |
| Storm 이벤트 허브 기록기 샘플 |Azure Event Hubs에 쓰는 방법 |
| Storm HBase 판독기 샘플 |HDInsight 클러스터의 HBase에서 읽는 방법 |
| Storm HBase 기록기 샘플 |HDInsight 클러스터의 HBase에 쓰는 방법 |
| Storm 하이브리드 샘플 |Java 구성 요소를 사용하는 방법 |
| Storm 샘플 |기본 단어 카운트 토폴로지 |

> [!WARNING]  
> 일부 템플릿은 Linux 기반 HDInsight에서 작동합니다. 템플릿에서 사용하는 NuGet 패키지는 Mono와 호환되지 않을 수 있습니다. 잠재적 문제를 식별 하려면 [Mono 호환성](https://www.mono-project.com/docs/about-mono/compatibility/) 및 [.net 이식성 분석기](../hdinsight-hadoop-migrate-dotnet-to-linux.md#automated-portability-analysis)사용을 참조 하세요.

이 문서의 단계에서는 기본 Storm 애플리케이션 프로젝트 형식을 사용하여 토폴로지를 만들 수 있습니다.

### <a name="apache-hbase-templates"></a>Apache HBase 템플릿

HBase 판독기 및 기록기 템플릿은 HBase Java API가 아니라 HBase REST API를 사용하여 HDInsight 클러스터의 HBase와 통신합니다.

### <a name="eventhub-templates"></a>EventHub 템플릿

> [!IMPORTANT]  
> EventHub 판독기 템플릿에 포함된 Java 기반 EventHub spout 구성 요소는 HDInsight 버전 3.5 이상의 Storm에서 작동하지 않을 수 있습니다. 이 구성 요소의 업데이트 된 버전은 [GitHub](https://github.com/hdinsight/hdinsight-storm-examples/tree/master/HDI3.5/lib)에 있습니다.

이 구성 요소를 사용하고 HDInsight 3.5의 Storm에서 작동하는 토폴로지의 예는 [GitHub](https://github.com/Azure-Samples/hdinsight-dotnet-java-storm-eventhub)를 참조하세요.

## <a name="create-a-c-topology"></a>C# 토폴로지 만들기

Visual Studio에서 c # 토폴로지 프로젝트를 만들려면 다음을 수행 합니다.

1. Visual Studio를 엽니다.

1. **시작** 창에서 **새 프로젝트 만들기**를 선택합니다.

1. **새 프로젝트 만들기** 창에서로 스크롤하고 **스톰 응용 프로그램**을 선택 하 고 **다음**을 선택 합니다.

1. **새 프로젝트 구성** 창에서 **프로젝트 이름** 으로 *WordCount*를 입력 하 고, 프로젝트의 **위치** 디렉터리 경로를 만든 다음, **만들기**를 선택 합니다.

    ![스톰 응용 프로그램, 새 프로젝트 구성 대화 상자, Visual Studio](./media/apache-storm-develop-csharp-visual-studio-topology/apache-storm-new-project.png)

프로젝트를 만든 후에는 다음 파일이 있어야 합니다.

* *Program.cs*: 프로젝트에 대 한 토폴로지 정의입니다. 기본적으로 하나의 Spout 및 하나의 Bolt로 구성된 기본 토폴로지가 만들어집니다.

* *Spout.cs*: 난수를 내보내는 예제 Spout입니다.

* *Bolt.cs*: Spout에서 내보낸 숫자의 개수를 유지하는 예제 Bolt입니다.

프로젝트를 만들면 NuGet은 최신 [SCP.NET 패키지](https://www.nuget.org/packages/Microsoft.SCP.Net.SDK/)를 다운로드합니다.

### <a name="implement-the-spout"></a>spout 만들기

다음으로 외부 원본에서 토폴로지의 데이터를 읽는 데 사용 되는 spout에 대 한 코드를 추가 합니다. 이 Spout는 문장을 토폴로지에 임의로 내보냅니다.

1. *Spout.cs*를 엽니다. spout의 주요 구성 요소:

   * `NextTuple`: Spout이 새 튜플을 내보낼 수 있는 경우 스톰에 의해 호출 됩니다.

   * `Ack`(트랜잭션 토폴로지만 해당): spout에서 전송 된 튜플에 대 한 토폴로지의 다른 구성 요소에 의해 시작 된 승인을 처리 합니다. 튜플을 승인하면 spout가 다운스트림 구성 요소에 의해 성공적으로 처리되었음을 알 수 있습니다.

   * `Fail`(트랜잭션 토폴로지만 해당): 토폴로지의 다른 구성 요소에 대 한 실패 처리 중인 튜플을 처리 합니다. 메서드를 `Fail` 구현 하면 다시 처리 될 수 있도록 튜플을 다시 내보낼 수 있습니다.

2. `Spout` 클래스의 내용을 다음 텍스트로 바꿉니다.

    ```csharp
    private Context ctx;
    private Random r = new Random();
    string[] sentences = new string[] {
        "the cow jumped over the moon",
        "an apple a day keeps the doctor away",
        "four score and seven years ago",
        "snow white and the seven dwarfs",
        "i am at two with nature"
    };

    public Spout(Context ctx)
    {
        // Set the instance context
        this.ctx = ctx;

        Context.Logger.Info("Generator constructor called");

        // Declare Output schema
        Dictionary<string, List<Type>> outputSchema = new Dictionary<string, List<Type>>();
        // The schema for the default output stream is
        // a tuple that contains a string field
        outputSchema.Add("default", new List<Type>() { typeof(string) });
        this.ctx.DeclareComponentSchema(new ComponentStreamSchema(null, outputSchema));
    }

    // Get an instance of the spout
    public static Spout Get(Context ctx, Dictionary<string, Object> parms)
    {
        return new Spout(ctx);
    }

    public void NextTuple(Dictionary<string, Object> parms)
    {
        Context.Logger.Info("NextTuple enter");
        // The sentence to be emitted
        string sentence;

        // Get a random sentence
        sentence = sentences[r.Next(0, sentences.Length - 1)];
        Context.Logger.Info("Emit: {0}", sentence);
        // Emit it
        this.ctx.Emit(new Values(sentence));

        Context.Logger.Info("NextTuple exit");
    }

    public void Ack(long seqId, Dictionary<string, Object> parms)
    {
        // Only used for transactional topologies
    }

    public void Fail(long seqId, Dictionary<string, Object> parms)
    {
        // Only used for transactional topologies
    }
    ```

### <a name="implement-the-bolts"></a>bolt 구현

이제이 예제에서 두 개의 스톰 볼트를 만듭니다.

1. 프로젝트에서 기존 *Bolt.cs* 를 삭제합니다.

2. **솔루션 탐색기**에서 프로젝트를 마우스 오른쪽 단추로 클릭 하 고**새 항목** **추가** > 를 선택 합니다. 목록에서 **Storm Bolt**를 선택하고 이름으로 *Splitter.cs*를 입력합니다. 새 파일의 코드에서 네임 스페이스 이름을로 `WordCount`변경 합니다. 그런 다음이 프로세스를 반복 하 여 *Counter.cs*라는 두 번째 볼트를 만듭니다.

   * *Splitter.cs*: 문장을 개별 단어로 분할 하 고 새 단어 스트림을 내보내는 볼트를 구현 합니다.

   * *Counter.cs*: 각 단어를 계산 하 고 새 단어 스트림과 각 단어의 수를 내보내는 볼트를 구현 합니다.

     > [!NOTE]  
     > 이러한 Bolt는 스트림을 읽고 쓰지만 데이터베이스 또는 서비스와 같은 소스와 통신하는 데 Bolt를 사용할 수 있습니다.

3. *Splitter.cs*를 엽니다. 이 클래스에는 기본적 `Execute`으로 하나의 메서드만 있습니다. 이 `Execute` 메서드는 볼트가 처리할 튜플을 받을 때 호출 됩니다. 여기에서 들어오는 튜플을 읽고 처리하며 나가는 튜플을 내보낼 수 있습니다.

4. `Splitter` 클래스의 콘텐츠를 다음 코드로 바꿉니다.

    ```csharp
    private Context ctx;

    // Constructor
    public Splitter(Context ctx)
    {
        Context.Logger.Info("Splitter constructor called");
        this.ctx = ctx;

        // Declare Input and Output schemas
        Dictionary<string, List<Type>> inputSchema = new Dictionary<string, List<Type>>();
        // Input contains a tuple with a string field (the sentence)
        inputSchema.Add("default", new List<Type>() { typeof(string) });
        Dictionary<string, List<Type>> outputSchema = new Dictionary<string, List<Type>>();
        // Outbound contains a tuple with a string field (the word)
        outputSchema.Add("default", new List<Type>() { typeof(string) });
        this.ctx.DeclareComponentSchema(new ComponentStreamSchema(inputSchema, outputSchema));
    }

    // Get a new instance of the bolt
    public static Splitter Get(Context ctx, Dictionary<string, Object> parms)
    {
        return new Splitter(ctx);
    }

    // Called when a new tuple is available
    public void Execute(SCPTuple tuple)
    {
        Context.Logger.Info("Execute enter");

        // Get the sentence from the tuple
        string sentence = tuple.GetString(0);
        // Split at space characters
        foreach (string word in sentence.Split(' '))
        {
            Context.Logger.Info("Emit: {0}", word);
            //Emit each word
            this.ctx.Emit(new Values(word));
        }

        Context.Logger.Info("Execute exit");
    }
    ```

5. *Counter.cs*를 열고 클래스 내용을 다음 코드로 바꿉니다.

    ```csharp
    private Context ctx;

    // Dictionary for holding words and counts
    private Dictionary<string, int> counts = new Dictionary<string, int>();

    // Constructor
    public Counter(Context ctx)
    {
        Context.Logger.Info("Counter constructor called");
        // Set instance context
        this.ctx = ctx;

        // Declare Input and Output schemas
        Dictionary<string, List<Type>> inputSchema = new Dictionary<string, List<Type>>();
        // A tuple containing a string field - the word
        inputSchema.Add("default", new List<Type>() { typeof(string) });

        Dictionary<string, List<Type>> outputSchema = new Dictionary<string, List<Type>>();
        // A tuple containing a string and integer field - the word and the word count
        outputSchema.Add("default", new List<Type>() { typeof(string), typeof(int) });
        this.ctx.DeclareComponentSchema(new ComponentStreamSchema(inputSchema, outputSchema));
    }

    // Get a new instance
    public static Counter Get(Context ctx, Dictionary<string, Object> parms)
    {
        return new Counter(ctx);
    }

    // Called when a new tuple is available
    public void Execute(SCPTuple tuple)
    {
        Context.Logger.Info("Execute enter");

        // Get the word from the tuple
        string word = tuple.GetString(0);
        // Do we already have an entry for the word in the dictionary?
        // If no, create one with a count of 0
        int count = counts.ContainsKey(word) ? counts[word] : 0;
        // Increment the count
        count++;
        // Update the count in the dictionary
        counts[word] = count;

        Context.Logger.Info("Emit: {0}, count: {1}", word, count);
        // Emit the word and count information
        this.ctx.Emit(Constants.DEFAULT_STREAM_ID, new List<SCPTuple> { tuple }, new Values(word, count));
        Context.Logger.Info("Execute exit");
    }
    ```

### <a name="define-the-topology"></a>토폴로지 정의

Spout 및 bolt는 그래프로 정렬되며, 이는 구성 요소 간에 데이터의 흐름 방식을 정의합니다. 이 토폴로지의 경우 그래프는 다음과 같습니다.

![Spout 및 볼트 구성 요소 정렬 다이어그램, 폭풍 토폴로지](./media/apache-storm-develop-csharp-visual-studio-topology/word-count-topology1.png)

Spout는 분할자 볼트의 인스턴스로 배포 되는 문장을 내보냅니다. Splitter bolt는 Counter bolt로 배포된 단어로 문장을 나눕니다.

카운터 인스턴스는 로컬 단어 수를 저장 하므로 특정 단어가 동일한 카운터 볼트 인스턴스로 흐르도록 합니다. 각 인스턴스는 특정 단어를 계속 추적합니다. Splitter bolt는 상태를 유지하지 않으므로 실제로 splitter의 어떤 인스턴스가 어떤 문장을 받는지 중요하지 않습니다.

*Program.cs*를 엽니다. 중요 한 메서드는 `GetTopologyBuilder`스톰에 제출 되는 토폴로지를 정의 하는 데 사용 되는입니다. 이전에 설명한 토폴로지 `GetTopologyBuilder` 를 구현 하려면의 내용을 다음 코드로 바꿉니다.

```csharp
// Create a new topology named 'WordCount'
TopologyBuilder topologyBuilder = new TopologyBuilder(
    "WordCount" + DateTime.Now.ToString("yyyyMMddHHmmss"));

// Add the spout to the topology.
// Name the component 'sentences'
// Name the field that is emitted as 'sentence'
topologyBuilder.SetSpout(
    "sentences",
    Spout.Get,
    new Dictionary<string, List<string>>()
    {
        {Constants.DEFAULT_STREAM_ID, new List<string>(){"sentence"}}
    },
    1);
// Add the splitter bolt to the topology.
// Name the component 'splitter'
// Name the field that is emitted 'word'
// Use suffleGrouping to distribute incoming tuples
//   from the 'sentences' spout across instances
//   of the splitter
topologyBuilder.SetBolt(
    "splitter",
    Splitter.Get,
    new Dictionary<string, List<string>>()
    {
        {Constants.DEFAULT_STREAM_ID, new List<string>(){"word"}}
    },
    1).shuffleGrouping("sentences");

// Add the counter bolt to the topology.
// Name the component 'counter'
// Name the fields that are emitted 'word' and 'count'
// Use fieldsGrouping to ensure that tuples are routed
//   to counter instances based on the contents of field
//   position 0 (the word). This could also have been
//   List<string>(){"word"}.
//   This ensures that the word 'jumped', for example, will always
//   go to the same instance
topologyBuilder.SetBolt(
    "counter",
    Counter.Get,
    new Dictionary<string, List<string>>()
    {
        {Constants.DEFAULT_STREAM_ID, new List<string>(){"word", "count"}}
    },
    1).fieldsGrouping("splitter", new List<int>() { 0 });

// Add topology config
topologyBuilder.SetTopologyConfig(new Dictionary<string, string>()
{
    {"topology.kryo.register","[\"[B\"]"}
});

return topologyBuilder;
```

## <a name="submit-the-topology"></a>토폴로지 제출

이제 HDInsight 클러스터에 토폴로지를 제출할 준비가 되었습니다.

1. **보기** > **서버 탐색기**로 이동 합니다.

1. **Azure**를 마우스 오른쪽 단추로 클릭 하 고 **Microsoft Azure 구독에 연결**...을 선택 하 여 로그인 프로세스를 완료 합니다.

1. **솔루션 탐색기**에서 프로젝트를 마우스 오른쪽 단추로 클릭 하 고 **HDInsight의 스톰에 제출을**선택 합니다.

1. **토폴로지 제출** 대화 상자의 **스톰 클러스터** 드롭다운 목록에서 HDInsight 클러스터의 스톰을 선택 하 고 **제출**을 선택 합니다. **출력** 창을 확인 하 여 전송의 성공 여부를 확인할 수 있습니다.

    토폴로지가 성공적으로 제출 되 면 클러스터에 대 한 **스톰 토폴로지 보기** 창이 표시 됩니다. 실행 중인 토폴로지에 대 한 정보를 보려면 목록에서 **WordCount** 토폴로지를 선택 합니다.

    ![스톰 토폴로지 보기 창, HDInsight 클러스터, Visual Studio](./media/apache-storm-develop-csharp-visual-studio-topology/storm-topology-view.png)

    > [!NOTE]  
    > **서버 탐색기**에서 **Storm 토폴로지**를 볼 수도 있습니다. **Azure** > **hdinsight**를 확장 하 고 hdinsight 클러스터의 스톰을 마우스 오른쪽 단추로 클릭 한 다음 **스톰 토폴로지 보기**를 선택 합니다.

    토폴로지의 구성 요소에 대 한 정보를 보려면 다이어그램에서 구성 요소를 선택 합니다.

1. **토폴로지 요약** 섹션에서 **Kill** 을 선택 하 여 토폴로지를 중지 합니다.

    > [!NOTE]  
    > Storm 토폴로지는 비활성화되거나 클러스터가 삭제될 때까지 계속 실행됩니다.

## <a name="transactional-topology"></a>트랜잭션 토폴로지

이전 토폴로지는 비트랜잭션입니다. 토폴로지의 구성 요소는 메시지를 재생 하는 기능을 구현 하지 않습니다. 트랜잭션 토폴로지의 예를 보려면 프로젝트를 만들고 프로젝트 형식으로 **Storm 샘플**을 선택합니다.

트랜잭션 토폴로지는 데이터 재생을 지원하기 위해 다음과 같이 구현합니다.

* **메타 데이터 캐싱**: spout는 내보낸 데이터에 대 한 메타 데이터를 저장 해야 하므로 오류가 발생 하는 경우 데이터를 검색 하 고 다시 내보낼 수 있습니다. 샘플로 내보낸 데이터는 작기 때문에 각 튜플의 원시 데이터는 재생을 위해 사전에 저장됩니다.

* **Ack**: 토폴로지의 각 Bolt는 `this.ctx.Ack(tuple)`를 호출하여 튜플을 성공적으로 처리했음을 승인할 수 있습니다. 모든 볼트가 튜플을 승인한 경우 spout의 `Ack` 메서드가 호출 됩니다. `Ack` 메서드를 통해 Spout가 재생용으로 캐시된 데이터를 제거할 수 있습니다.

* **Fail**: 각 Bolt는 `this.ctx.Fail(tuple)`을 호출하여 튜플 처리에 실패했음을 나타냅니다. 캐시된 메타데이터를 사용하여 튜플을 재생할 수 있는 Spout의 `Fail` 메서드로 오류가 전파됩니다.

* **Sequence ID**: 튜플을 내보낼 때 고유한 시퀀스 ID를 지정할 수 있습니다. 이 값은 재생 (`Ack` 및 `Fail`) 처리에 대 한 튜플을 식별 합니다. 예를 들어 **스톰 샘플** 프로젝트의 spout는 데이터를 내보낼 때 다음 메서드 호출을 사용 합니다.

  `this.ctx.Emit(Constants.DEFAULT_STREAM_ID, new Values(sentence), lastSeqId);`

  이 코드는에 `lastSeqId`포함 된 시퀀스 ID 값과 함께 문장이 포함 된 튜플을 기본 스트림으로 내보냅니다. 이 예제에서는 `lastSeqId` 가 내보내지는 모든 튜플에 대해가 증가 합니다.

**Storm 샘플** 프로젝트에 설명된 대로 구성 요소가 트랜잭션인지 여부는 구성에 따라 런타임으로 설정할 수 있습니다.

## <a name="hybrid-topology-with-c-and-java"></a>C# 및 Java를 통한 하이브리드 토폴로지

또한 Data Lake Tools for Visual Studio를 사용하여 일부 구성 요소가 C#이고 다른 구성 요소가 Java인 하이브리드 토폴로지를 만들 수 있습니다.

하이브리드 토폴로지의 예를 보려면 프로젝트를 만들고 **Storm 하이브리드 샘플**을 선택합니다. 이 샘플 형식은 다음 개념을 보여 줍니다.

* **Java spout** 및 **c # 볼트**: `HybridTopology_javaSpout_csharpBolt` 클래스에서 정의 됩니다.

  트랜잭션 버전은 `HybridTopologyTx_javaSpout_csharpBolt` 클래스에서 정의 됩니다.

* **C # spout** 및 **Java 볼트**: `HybridTopology_csharpSpout_javaBolt` 클래스에서 정의 됩니다.

  트랜잭션 버전은 `HybridTopologyTx_csharpSpout_javaBolt` 클래스에서 정의 됩니다.

  > [!NOTE]  
  > 이 버전은 텍스트 파일에서 Clojure 코드를 Java 구성 요소로 사용하는 방법을 설명하기도 합니다.

프로젝트가 제출될 때 사용된 토폴로지를 전환하려면 클러스터에 제출하기 전에 사용하려는 토폴로지로 `[Active(true)]` 문을 이동합니다.

> [!NOTE]  
> 필요한 모든 Java 파일이 *JavaDependency* 폴더에서 이 프로젝트의 일부로 제공됩니다.

하이브리드 토폴로지를 만들고 제출할 때는 다음 사항을 고려 하세요.

* 를 `JavaComponentConstructor` 사용 하 여 spout 또는 볼트에 대 한 Java 클래스의 인스턴스를 만듭니다.

* Java `microsoft.scp.storm.multilang.CustomizedInteropJSONSerializer` 개체에서 JSON으로 java 구성 요소에서 데이터를 직렬화 하거나 제외 하려면를 사용 합니다.

* 서버에 토폴로지를 제출할 때 **Java 파일 경로**를 지정하려면 **추가 구성** 옵션을 사용해야 합니다. 지정 된 경로는 Java 클래스를 포함 하는 JAR 파일이 있는 디렉터리 여야 합니다.

### <a name="azure-event-hubs"></a>Azure Event Hubs

SCP.Net 버전 0.9.4.203은 Event Hub Spout(Event Hubs로부터 읽는 Java Spout)로 작업하기 위한 새로운 클래스와 메서드를 소개합니다. 이벤트 허브 spout (예: **스톰 EventHub 판독기 샘플** 템플릿 사용)를 사용 하는 토폴로지를 만들 때는 다음 api를 사용 합니다.

* `EventHubSpoutConfig`클래스: spout 구성 요소에 대 한 구성이 포함 된 개체를 만듭니다.

* `TopologyBuilder.SetEventHubSpout`메서드: 토폴로지에 이벤트 허브 spout 구성 요소를 추가 합니다.

> [!NOTE]  
> Spout에서 생성 한 데이터 `CustomizedInteropJSONSerializer` 를 직렬화 하려면 여전히를 사용 해야 합니다.

## <a name="use-configurationmanager"></a>ConfigurationManager 사용

**ConfigurationManager** 를 사용 하 여 볼트 및 spout 구성 요소에서 구성 값을 검색 하지 마십시오. 이렇게 하면 null 포인터 예외가 발생할 수 있습니다. 대신, 프로젝트에 대 한 구성을 스톰 토폴로지에는 토폴로지 컨텍스트의 키 및 값 쌍으로 전달 합니다. 구성 값을 사용하는 각 구성 요소는 초기화 중에 컨텍스트에서 값을 검색해야 합니다.

다음 코드에서는 이러한 값을 검색하는 방법을 보여 줍니다.

```csharp
public class MyComponent : ISCPBolt
{
    // To hold configuration information loaded from context
    Configuration configuration;
    ...
    public MyComponent(Context ctx, Dictionary<string, Object> parms)
    {
        // Save a copy of the context for this component instance
        this.ctx = ctx;
        // If it exists, load the configuration for the component
        if(parms.ContainsKey(Constants.USER_CONFIG))
        {
            this.configuration = parms[Constants.USER_CONFIG] 
                as System.Configuration.Configuration;
        }
        // Retrieve the value of "Foo" from configuration
        var foo = this.configuration.AppSettings.Settings["Foo"].Value;
    }
    ...
}
```

`Get` 메서드를 사용하여 구성 요소의 인스턴스를 반환하는 경우 `Context` 및 `Dictionary<string, Object>` 매개 변수가 생성자에 모두 전달되는지 확인해야 합니다. 다음 예제는 이러한 값을 적절히 전달하는 기본 `Get` 메서드입니다.

```csharp
public static MyComponent Get(Context ctx, Dictionary<string, Object> parms)
{
    return new MyComponent(ctx, parms);
}
```

## <a name="how-to-update-scpnet"></a>SCP.NET 업데이트 방법

SCP.NET의 최신 릴리스는 NuGet을 통해 패키지 업그레이드를 지원합니다. 새 업데이트를 사용할 수 있을 때 업그레이드 알림을 받게 됩니다. 업그레이드를 수동으로 확인하려면 다음 단계를 수행합니다.

1. **솔루션 탐색기**에서 프로젝트를 마우스 오른쪽 단추로 클릭 하 고 **NuGet 패키지 관리**를 선택 합니다.

2. 패키지 관리자에서 **업데이트**를 선택합니다. SCP.NET 지원 패키지에 대 한 업데이트를 사용할 수 있는 경우 나열 됩니다. 패키지에 대해 **업데이트** 를 선택한 다음 **변경 내용 미리 보기** 대화 상자에서 **확인** 을 선택 하 여 설치 합니다.

> [!IMPORTANT]  
> NuGet을 사용하지 않는 SCP.NET의 이전 버전으로 프로젝트를 만든 경우 다음 단계를 수행하여 최신 버전으로 업데이트해야 합니다.
>
> 1. **솔루션 탐색기**에서 프로젝트를 마우스 오른쪽 단추로 클릭 하 고 **NuGet 패키지 관리**를 선택 합니다.
> 2. **검색** 필드를 사용 하 여를 검색 하 고 프로젝트 `Microsoft.SCP.Net.SDK` 에 추가 합니다.

## <a name="troubleshoot-common-issues-with-topologies"></a>토폴로지의 일반적인 문제 해결

### <a name="null-pointer-exceptions"></a>Null 포인터 예외

Linux 기반 HDInsight 클러스터에서 c # 토폴로지를 사용 하는 경우 **ConfigurationManager** 를 사용 하 여 런타임에 구성 설정을 읽는 spout 구성 요소에서 null 포인터 예외가 반환 될 수 있습니다.

프로젝트에 대한 구성이 토폴로지 컨텍스트의 키 및 값 쌍으로 Storm 토폴로지에 전달됩니다. 초기화 될 때 구성 요소에 전달 되는 사전 개체에서 검색할 수 있습니다.

자세한 내용은이 문서의 [Use ConfigurationManager](#use-configurationmanager) 섹션을 참조 하세요.

### <a name="systemtypeloadexception"></a>System.TypeLoadException

Linux 기반 HDInsight 클러스터에서 c # 토폴로지를 사용 하는 경우 다음과 같은 오류가 발생할 수 있습니다.

`System.TypeLoadException: Failure has occurred while loading a type.`

이 오류는 Mono에서 지 원하는 .NET 버전과 호환 되지 않는 이진 파일을 사용할 때 발생 합니다.

Linux 기반 HDInsight 클러스터의 경우 프로젝트에서 .NET 4.5에 대해 컴파일된 이진 파일을 사용하는지 확인하십시오.

### <a name="test-a-topology-locally"></a>로컬로 토폴로지 테스트

토폴로지를 클러스터에 쉽게 배포할 수 있지만 경우에 따라 토폴로지를 로컬로 테스트 해야 할 수도 있습니다. 다음 단계를 사용 하 여이 문서의 예제 토폴로지를 개발 환경에서 로컬로 실행 하 고 테스트할 수 있습니다.

> [!WARNING]  
> 로컬 테스트는 기본 C# 전용 토폴로지에서만 작동합니다. 하이브리드 토폴로지나 여러 스트림을 사용하는 토폴로지에는 로컬 테스트를 사용할 수 없습니다.

1. **솔루션 탐색기**에서 프로젝트를 마우스 오른쪽 단추로 클릭하고 **속성**을 선택합니다. 프로젝트 속성에서 그런 다음 **출력 유형을** **콘솔 응용 프로그램**으로 변경 합니다.

   ![HDInsight 스톰 응용 프로그램, 프로젝트 속성, 출력 형식](./media/apache-storm-develop-csharp-visual-studio-topology/hdi-output-type-window.png)

   > [!NOTE]
   > 토폴로지를 클러스터로 배포하기 전에 **출력 유형**을 **클래스 라이브러리**로 다시 변경해야 합니다.

1. **솔루션 탐색기**에서 프로젝트를 마우스 오른쪽 단추로 클릭하고 **추가** > **새 항목**을 선택합니다. **클래스**를 선택 하 고 클래스 이름으로 *LocalTest.cs* 를 입력 합니다. 마지막으로 **추가**를 선택 합니다.

1. *LocalTest.cs*를 열고 맨 위에 다음 `using` 문을 추가 합니다.

    ```csharp
    using Microsoft.SCP;
    ```

1. `LocalTest` 클래스의 내용으로 다음 코드를 사용 합니다.

    ```csharp
    // Drives the topology components
    public void RunTestCase()
    {
        // An empty dictionary for use when creating components
        Dictionary<string, Object> emptyDictionary = new Dictionary<string, object>();

        #region Test the spout
        {
            Console.WriteLine("Starting spout");
            // LocalContext is a local-mode context that can be used to initialize
            // components in the development environment.
            LocalContext spoutCtx = LocalContext.Get();
            // Get a new instance of the spout, using the local context
            Spout sentences = Spout.Get(spoutCtx, emptyDictionary);

            // Emit 10 tuples
            for (int i = 0; i < 10; i++)
            {
                sentences.NextTuple(emptyDictionary);
            }
            // Use LocalContext to persist the data stream to file
            spoutCtx.WriteMsgQueueToFile("sentences.txt");
            Console.WriteLine("Spout finished");
        }
        #endregion

        #region Test the splitter bolt
        {
            Console.WriteLine("Starting splitter bolt");
            // LocalContext is a local-mode context that can be used to initialize
            // components in the development environment.
            LocalContext splitterCtx = LocalContext.Get();
            // Get a new instance of the bolt
            Splitter splitter = Splitter.Get(splitterCtx, emptyDictionary);

            // Set the data stream to the data created by the spout
            splitterCtx.ReadFromFileToMsgQueue("sentences.txt");
            // Get a batch of tuples from the stream
            List<SCPTuple> batch = splitterCtx.RecvFromMsgQueue();
            // Process each tuple in the batch
            foreach (SCPTuple tuple in batch)
            {
                splitter.Execute(tuple);
            }
            // Use LocalContext to persist the data stream to file
            splitterCtx.WriteMsgQueueToFile("splitter.txt");
            Console.WriteLine("Splitter bolt finished");
        }
        #endregion

        #region Test the counter bolt
        {
            Console.WriteLine("Starting counter bolt");
            // LocalContext is a local-mode context that can be used to initialize
            // components in the development environment.
            LocalContext counterCtx = LocalContext.Get();
            // Get a new instance of the bolt
            Counter counter = Counter.Get(counterCtx, emptyDictionary);

            // Set the data stream to the data created by splitter bolt
            counterCtx.ReadFromFileToMsgQueue("splitter.txt");
            // Get a batch of tuples from the stream
            List<SCPTuple> batch = counterCtx.RecvFromMsgQueue();
            // Process each tuple in the batch
            foreach (SCPTuple tuple in batch)
            {
                counter.Execute(tuple);
            }
            // Use LocalContext to persist the data stream to file
            counterCtx.WriteMsgQueueToFile("counter.txt");
            Console.WriteLine("Counter bolt finished");
        }
        #endregion
    }
    ```

    코드 주석을 읽어보세요. 이 코드는 `LocalContext` 를 사용 하 여 개발 환경에서 구성 요소를 실행 합니다. 구성 요소 간의 데이터 스트림을 로컬 드라이브의 텍스트 파일로 유지 합니다.

1. *Program.cs*를 열고 다음 코드를 `Main` 메서드에 추가 합니다.

    ```csharp
    Console.WriteLine("Starting tests");
    System.Environment.SetEnvironmentVariable("microsoft.scp.logPrefix", "WordCount-LocalTest");
    // Initialize the runtime
    SCPRuntime.Initialize();

    //If we are not running under the local context, throw an error
    if (Context.pluginType != SCPPluginType.SCP_NET_LOCAL)
    {
        throw new Exception(string.Format("unexpected pluginType: {0}", Context.pluginType));
    }
    // Create test instance
    LocalTest tests = new LocalTest();
    // Run tests
    tests.RunTestCase();
    Console.WriteLine("Tests finished");
    Console.ReadKey();
    ```

1. 변경 내용을 저장 한 다음 **F5 키** 를 누르거나 **디버그** > **디버깅 시작** 을 선택 하 여 프로젝트를 시작 합니다. 콘솔 창이 나타나며 로그 상태가 테스트로 진행됩니다. 표시 `Tests finished` 되 면 아무 키나 선택 하 여 창을 닫습니다.

1. **Windows 탐색기**를 사용하여 프로젝트가 포함된 디렉터리를 찾습니다. 예: *C\\: Users\\\<your_user_name \\>source\\리포지토리\\WordCount\\WordCount*. 그런 다음이 디렉터리에서 *Bin*을 열고 *디버그*를 선택 합니다. 테스트를 실행 *했을 때*생성 된 텍스트 파일 ( *문장과*, test.txt 및 *splitter .txt*)이 표시 됩니다. 각각의 텍스트 파일을 열고 데이터를 검사합니다.

   > [!NOTE]  
   > 문자열 데이터는 이러한 파일에 10진수 값의 배열로 유지됩니다. 예를 들어 `[[97,103,111]]` , **splitter .txt** 파일의는 *전*단어를 나타냅니다.

> [!NOTE]  
> HDInsight 클러스터에 배포 하기 전에 프로젝트 속성에서 **프로젝트 형식을** **클래스 라이브러리로** 다시 설정 해야 합니다.

### <a name="log-information"></a>로그 정보

`Context.Logger`를 사용하여 토폴로지 구성 요소에서 정보를 쉽게 로깅할 수 있습니다. 예를 들어 다음 명령은 정보 제공용 로그 항목을 만듭니다.

`Context.Logger.Info("Component started");`

로깅된 정보는 **서버 탐색기**에서 찾을 수 있는 **Hadoop 서비스 로그**에서 볼 수 있습니다. HDInsight의 Storm 클러스터에 대한 항목을 확장한 다음 **Hadoop 서비스 로그**를 확장합니다. 마지막으로 보려는 로그 파일을 선택합니다.

> [!NOTE]  
> 로그는 사용자의 클러스터에서 사용되는 Azure 스토리지 계정에 저장됩니다. Visual Studio에서 로그를 보려면 스토리지 계정을 소유하는 Azure 구독에 로그인해야 합니다.

### <a name="view-error-information"></a>오류 정보 보기

실행 중인 토폴로지에서 발행한 오류를 보려면 다음 단계를 따릅니다.

1. **서버 탐색기**에서 HDInsight 클러스터의 스톰을 마우스 오른쪽 단추로 클릭 하 고 **스톰 토폴로지 보기**를 선택 합니다.

   **Spout** 및 **Bolts**의 경우 **마지막 오류** 열에 마지막 오류에 대한 정보가 있습니다.

2. 오류가 나열 된 구성 요소에 대 한 **SPOUT id** 또는 **볼트 id** 를 선택 합니다. 세부 정보 페이지에는 페이지 아래쪽의 **오류** 섹션에 추가 오류 정보가 표시 됩니다.

3. 자세한 내용을 보려면 페이지의 **실행자** 섹션에서 **포트** 를 선택 하 여 최근 몇 분 동안의 스톰 작업자 로그를 확인 합니다.

### <a name="errors-submitting-topologies"></a>토폴로지 제출 중 오류

HDInsight에 토폴로지를 제출 하는 동안 오류가 발생 하는 경우 HDInsight 클러스터에서 토폴로지 제출을 처리 하는 서버 쪽 구성 요소에 대 한 로그를 찾을 수 있습니다. 이러한 로그를 다운로드 하려면 명령줄에서 다음 명령을 사용 합니다.

```cmd
scp sshuser@clustername-ssh.azurehdinsight.net:/var/log/hdinsight-scpwebapi/hdinsight-scpwebapi.out .
```

*sshuser*를 클러스터의 SSH 사용자 계정으로 바꿉니다. *Clustername* 을 HDInsight 클러스터의 이름으로 바꿉니다. HDInsight에서 `scp` 및 `ssh` 사용에 대한 자세한 내용은 [HDInsight에서 SSH 사용](../hdinsight-hadoop-linux-use-ssh-unix.md)을 참조하세요.

여러 가지 이유로 제출이 실패할 수 있습니다.

* JDK가 설치 되지 않았거나 경로에 없습니다.
* 필수 Java 종속성은 제출에 포함 되지 않습니다.
* 종속성이 호환 되지 않습니다.
* 토폴로지 이름이 중복 되었습니다.

*Hdinsight-scpwebapi* 로그 파일에이 포함 되어 `FileNotFoundException`있으면 다음 조건에 따라 예외가 발생할 수 있습니다.

* JDK는 개발 환경의 경로에 없습니다. JDK가 개발 환경에 설치되어 있고 `%JAVA_HOME%/bin`이 경로에 있는지 확인합니다.
* Java 종속성이 없습니다. 필요한 .jar 파일을 제출의 일부로 포함 하 고 있는지 확인 합니다.

## <a name="next-steps"></a>다음 단계

Event Hubs에서 데이터를 처리하는 방법의 예는 [HDInsight의 Storm으로 Azure Event Hubs에서 이벤트 처리](apache-storm-develop-csharp-event-hub-topology.md)를 참조하세요.

스트림 데이터를 여러 스트림으로 분할하는 C# 토폴로지의 예제는 [C# Storm 예제](https://github.com/Blackmist/csharp-storm-example)를 참조하세요.

C# 토폴로지 생성에 대한 자세한 내용은 [GitHub](https://github.com/hdinsight/hdinsight-storm-examples/blob/master/SCPNet-GettingStarted.md)를 참조하세요.

HDInsight 사용 방법 및 HDInsight의 Storm에 대한 추가 샘플은 다음 문서를 참조하세요.

**Microsoft SCP.NET**

* [Azure HDInsight의 Apache Storm에 대 한 SCP 프로그래밍 가이드](apache-storm-scp-programming-guide.md)

**HDInsight의 Apache Storm**

* [Azure HDInsight에서 Apache Storm 토폴로지 배포 및 관리](apache-storm-deploy-monitor-topology-linux.md)
* [Azure HDInsight에서 Apache Storm 토폴로지 예제](apache-storm-example-topology.md)

**HDInsight의 Apache Hadoop**

* [Azure HDInsight의 Apache Hive 및 HiveQL 무엇 인가요?](../hadoop/hdinsight-use-hive.md)
* [HDInsight의 Apache Hadoop에서 MapReduce 사용](../hadoop/hdinsight-use-mapreduce.md)

**HDInsight의 Apache HBase**

* [Azure HDInsight에서 Apache HBase 사용](../hbase/apache-hbase-tutorial-get-started-linux.md)
