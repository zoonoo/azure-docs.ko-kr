---
title: Azure Machine Learning 데이터 준비 사용 방법에 대한 심층 가이드 | Microsoft Docs
description: 이 문서에서는 Azure Machine Learning 데이터 준비에서 데이터 문제를 해결하는 방법에 대한 개요 및 세부 정보를 제공합니다.
services: machine-learning
author: euangMS
ms.author: euang
manager: lanceo
ms.reviewer: jmartens, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: core
ms.workload: data-services
ms.custom: ''
ms.devlang: ''
ms.topic: article
ms.date: 02/01/2018
ROBOTS: NOINDEX
ms.openlocfilehash: 7536e67d0ae4973008c8acc91a99a7d0d286f9b8
ms.sourcegitcommit: 32d218f5bd74f1cd106f4248115985df631d0a8c
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 09/24/2018
ms.locfileid: "46988736"
---
# <a name="data-preparations-user-guide"></a>데이터 준비 사용자 가이드 

[!INCLUDE [workbench-deprecated](../../../includes/aml-deprecating-preview-2017.md)] 


Azure Machine Learning 데이터 준비 경험은 다양한 기능을 제공합니다. 이 문서는 환경의 심층 부분에 대해 설명합니다.

### <a name="step-execution-history-and-caching"></a>단계 실행, 기록 및 캐싱 
데이터 준비 단계 기록은 성능상의 이유로 일련의 캐시를 유지 관리합니다. 단계를 선택하고 캐시에 도달하면 다시 실행하지 않습니다. 단계 기록의 끝에 쓰기 블록이 있고 단계의 앞뒤로 이동하지만 변경하지 않는 경우 쓰기는 처음 이후에 트리거되지 않습니다. 다음과 같은 경우에 새로운 쓰기가 발생하여 이전 쓰기를 덮어씁니다.

- 쓰기 블록을 변경하는 경우
- 새 변환 블록을 추가하고 쓰기 블록 위로 이동하여 캐시 무효화를 생성하는 경우
- 쓰기 블록 위의 블록 속성을 변경하여 캐시 무효화를 생성하는 경우
- 샘플에서 새로 고침을 선택하는 경우(모든 캐시가 무효화됨)

### <a name="error-values"></a>오류 값

해당 값을 적절하게 처리할 수 없으므로 입력 값에 대한 데이터 변환이 실패할 수 있습니다. 예를 들어 형식 강제 변환 작업의 경우에 입력 문자열 값을 지정된 대상 형식으로 캐스팅할 수 없는 경우 강제 변환이 실패합니다. 형식 강제 변환 작업은 문자열 형식의 열을 숫자 또는 부울 형식으로 변환하거나 존재하지 않는 열을 복제하려고 시도할 수 있습니다. (이 오류는 *열 X 복제* 작업 전에 *열 X 삭제* 작업을 이동한 결과로 발생합니다.)

이러한 경우 데이터 준비에서 출력으로 오류 값을 생성합니다. 오류 값은 이전 작업이 지정한 값에 대해 실패했음을 나타냅니다. 내부적으로 첫 번째 클래스 값 형식으로 처리되지만 오류 값이 있으면 기본 열 형식을 변경하지 않습니다. 열 전체가 오류 값으로 구성된 경우도 마찬가지입니다.

오류 값은 쉽게 식별할 수 있습니다. 빨간색으로 강조 표시되고 "오류"로 읽습니다. 오류의 원인을 확인하기 위해 오류 값 위에 커서를 올리면 실패에 대한 텍스트 설명이 표시됩니다.

오류 값은 전파됩니다. 오류 값이 발생한 후에 대부분의 경우 대부분의 작업을 통해 오류로 전파됩니다. 이를 바꾸거나 제거하는 방법은 세 가지가 있습니다.

* Replace
    -  열을 마우스 오른쪽 단추로 클릭하고 **오류 값 바꾸기**를 선택합니다. 그런 다음 열의 각 오류 값에 대한 대체 값을 선택할 수 있습니다.

* 제거
    - 데이터 준비에는 오류 값을 유지하거나 제거하는 대화형 필터가 포함되어 있습니다.
    - 열을 마우스 오른쪽 단추로 클릭하고 **열 필터링**을 선택합니다. 오류 값을 유지 또는 제거하려면 *"is error"* 또는 *"is not error"* 조건을 사용하여 조건부를 만듭니다.

* Python 식을 사용하여 조건에 따라 오류 값에 작동합니다. 자세한 내용은 [Python 확장에 대한 섹션](data-prep-python-extensibility-overview.md)을 참조하세요.

### <a name="sampling"></a>샘플링
데이터 원본 파일은 하나 이상의 소스(로컬 파일 시스템 또는 원격 위치)에서 원시 데이터를 사용합니다. 샘플 블록을 사용하면 샘플을 생성하여 데이터 하위 집합의 사용 여부를 지정할 수 있습니다. 다음 단계의 작업 수행 시 큰 데이터 세트가 아닌 데이터 샘플에서 작업하면 종종 성능이 더 좋게 됩니다.

각 데이터 원본 파일에 대해 여러 샘플을 생성하고 저장할 수 있습니다. 그러나 하나의 샘플만 활성 샘플로 설정할 수 있습니다. 데이터 원본 마법사의 샘플을 만들거나 편집하거나 삭제할 수 있습니다. 또는 샘플 블록을 편집할 수 있습니다. 기본적으로 데이터 원본을 참조하는 모든 데이터 준비 파일은 데이터 원본 파일에 지정된 샘플을 사용합니다.

사용 가능한 많은 샘플링 전략이 있습니다(각각 구성 가능한 매개 변수가 다름).

#### <a name="top"></a>상위
이 전략은 로컬 또는 원격 파일에 적용할 수 있습니다. 처음 N개의 행(개수로 지정됨)을 데이터 원본으로 가져옵니다.

#### <a name="random-n"></a>임의 N개 
이 전략은 로컬 파일에만 적용할 수 있습니다. 임의 행 N개(개수로 지정됨)를 데이터 원본으로 가져옵니다. 개수도 동일한 경우 동일한 샘플이 생성되도록 특정 시드를 제공할 수 있습니다.

#### <a name="random-"></a>임의 % 
이 전략은 로컬 또는 원격 파일에 적용할 수 있습니다. 두 경우 모두 임의 N개 전략과 마찬가지로 확률 및 시드를 제공해야 합니다.

원격 파일의 샘플에 대해 추가 매개 변수를 제공해야 합니다.

- 샘플 생성기 
  - 샘플 생성에 사용할 Spark 클러스터 또는 원격 Docker 계산 대상을 선택합니다. 이 목록에 나타나도록 프로젝트에 대한 계산 대상을 미리 만들어야 합니다. [Azure Machine Learning에서 GPU를 사용하는 방법](how-to-use-gpu.md)의 "새 계산 대상 만들기" 섹션에서 단계를 수행하여 계산 대상을 만듭니다.
- 샘플 저장소 
  - 원격 샘플을 저장하는 중간 저장소 위치를 제공합니다. 이 경로는 입력된 파일 위치와 다른 디렉터리여야 합니다.

#### <a name="full-file"></a>전체 파일 
이 전략은 로컬 파일에만 적용할 수 있으며 전체 파일을 데이터 원본에 가져옵니다. 해당 파일을 너무 큰 경우 이 옵션은 앱에서 이후의 작업이 느려질 수 있습니다. 다른 샘플링 전략을 사용하는 것이 더 적절할 수 있습니다.


### <a name="fork-merge-and-append"></a>분기, 병합 및 추가

데이터 세트에 필터를 적용하면 작업을 통해 데이터가 두 개의 결과 집합으로 분할됩니다. 한 집합은 필터에서 성공한 레코드를 나타내고 다른 집합은 실패한 레코드를 나타냅니다. 두 경우 모두 사용자가 표시할 결과 집합을 선택할 수 있습니다. 사용자는 다른 데이터 세트를 취소하거나 새 데이터 흐름에 배치할 수 있습니다. 후자 옵션을 분기라고 합니다.

분기하려면: 
1. 열을 선택하고 마우스 오른쪽 단추를 클릭하여 열 **필터링**을 선택합니다.

2. **수행할 작업**에서 필터를 전달하는 결과 집합을 표시하려면 **행 유지**를 선택합니다.

3. 실패한 집합을 표시하려면 **행 제거**를 선택합니다.

4. **조건** 뒤에 **필터링된 행을 포함하여 데이터 흐름 만들기**를 선택하여 표시되지 않은 결과 집합을 새 데이터 흐름으로 분기합니다.


이 방법은 추가 준비가 필요한 데이터 집합을 구분하는 데 자주 사용됩니다. 분기된 데이터 세트를 준비한 후에는 원래 데이터 흐름의 결과 집합과 데이터를 병합하는 것이 일반적입니다. 병합(분기 작업의 반대)을 수행하려면 다음 작업 중 하나를 사용합니다.

- **행 추가**. 두 개 이상의 데이터 흐름을 세로(행 단위)로 병합합니다. 
- **열 추가**. 두 개 이상의 데이터 흐름을 가로(열 단위)로 병합합니다.


>[!NOTE]
>열 충돌이 발생하는 경우 열 추가에 실패합니다.


병합 작업 후 원본 데이터 흐름에서 하나 이상의 데이터 흐름을 참조합니다. 데이터 준비에서 단계 목록 아래에 있는 앱의 오른쪽 아래 모서리에서 알림을 통해 알려줍니다.


참조되는 데이터 흐름의 모든 작업에는 참조된 데이터 흐름에서 사용되는 샘플을 새로 고칠 부모 데이터 흐름이 필요합니다. 이 경우에 확인 대화 상자가 오른쪽 아래 모서리에 있는 데이터 흐름 참조 알림을 바꿉니다. 해당 대화 상자는 변경사항을 모든 종속성 데이터 흐름에 동기화하도록 데이터 흐름을 새로 고쳐야 할지 확인합니다.

### <a name="list-of-appendices"></a>부록 목록 
* [지원되는 데이터 원본](data-prep-appendix2-supported-data-sources.md)  
* [지원되는 변환](data-prep-appendix3-supported-transforms.md)  
* [지원되는 검사기](data-prep-appendix4-supported-inspectors.md)  
* [지원되는 대상](data-prep-appendix5-supported-destinations.md)  
* [Python의 샘플 필터 식](data-prep-appendix6-sample-filter-expressions-python.md)  
* [Python의 샘플 변환 데이터 흐름 식](data-prep-appendix7-sample-transform-data-flow-python.md)  
* [Python의 샘플 데이터 원본](data-prep-appendix8-sample-source-connections-python.md)  
* [Python의 샘플 대상 연결](data-prep-appendix9-sample-destination-connections-python.md)  
* [Python의 샘플 열 변환](data-prep-appendix10-sample-custom-column-transforms-python.md)  
