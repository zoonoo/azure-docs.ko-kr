---
title: AutoML을 사용하여 과잉 맞춤 및 불균형 데이터 방지
titleSuffix: Azure Machine Learning
description: Azure Machine Learning의 자동화된 기계 학습 솔루션을 사용하여 ML 모델의 일반적인 문제를 식별하고 관리합니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: e1191c01ce3f62f34c351cefd29a5e40aa68bfd3
ms.sourcegitcommit: fdec8e8bdbddcce5b7a0c4ffc6842154220c8b90
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/19/2020
ms.locfileid: "83658404"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>자동화된 기계 학습으로 과잉 맞춤 및 불균형 데이터 방지

과잉 맞춤 및 불균형 데이터는 기계 학습 모델을 빌드할 때 나타나는 일반적인 문제입니다. 기본적으로 Azure Machine Learning의 자동화된 기계 학습은 이러한 위험을 식별하는 데 유용한 차트 및 메트릭을 제공하고, 이러한 위험을 완화하는 데 유용한 모범 사례를 구현합니다. 

## <a name="identify-over-fitting"></a>과잉 맞춤 식별

기계 학습의 과잉 맞춤은 모델이 학습 데이터에 너무 잘 맞아서 보이지 않는 테스트 데이터를 정확하게 예측할 수 없을 때 발생합니다. 즉, 모델은 단순히 학습 데이터의 특정 패턴 및 노이즈를 기억하지만 실제 데이터를 예측하기에 충분히 유연하지 않습니다.

다음에 나오는 학습된 모델 및 해당 학습과 테스트 정확도를 고려해 보세요.

| 모델 | 학습 정확도 | 테스트 정확도 |
|-------|----------------|---------------|
| A | 99.9% | 95% |
| b | 87% | 87% |
| C | 99.9% | 45% |

모델 **A**의 경우 보이지 않는 데이터에 대한 테스트 정확도가 학습 정확도보다 낮으면 모델이 과잉 맞춤된다는 일반적인 오해가 발생합니다. 그러나 테스트 정확도는 항상 학습 정확도보다 작아야 하고, 과잉 맞춤과 적정 맞춤의 구분은 얼마나 덜 정확한지로 연결됩니다. 

모델 **A** 및 **B** 모델을 비교할 때 모델 **A**는 테스트 정확도가 더 높으므로 더 나은 모델이지만, 테스트 정확도는 95%에서 약간 더 낮아지더라도 과잉 맞춤이 있음을 암시하는 중요한 차이점은 아닙니다. 학습 및 테스트 정확도는 긴밀하게 통합되기 때문에 모델 **B**를 선택하지 않을 것입니다.

모델 **C**는 과잉 맞춤의 명확한 사례를 나타냅니다. 학습 정확도는 매우 높지만 테스트 정확도는 별로 높지 않습니다. 이러한 구분은 주관적이지만 문제 및 데이터에 대한 지식과 허용되는 오류 크기를 토대로 이루어집니다.

## <a name="prevent-over-fitting"></a>과도 맞춤 방지

대부분의 황당한 경우에 과도 맞춤 모델은 학습 중에 표시되는 기능 값을 조합하면 대상에 대해 항상 정확히 동일한 결과가 발생한다고 가정하게 됩니다.

과도 맞춤을 방지하는 가장 좋은 방법은 다음과 같은 ML 모범 사례를 따르는 것입니다.

* 더 많은 학습 데이터 사용 및 통계 편향 제거
* 대상 누출 방지
* 보다 적은 기능 사용
* **정규화 및 하이퍼 매개 변수 최적화**
* **모델 복잡성 제한 사항**
* **교차 유효성 검사**

자동화된 ML의 컨텍스트에서 위의 처음 세 항목은 **구현하는 모범 사례**입니다. 굵게 표시한 마지막 3개 항목은 기본적으로 과잉 맞춤으로부터 보호하기 위해 **자동화된 ML이 구현하는 모범 사례**입니다. 자동화된 ML 이외의 설정에서는 과잉 맞춤 모델을 방지하기 위해 6가지 모범 사례를 모두 따르는 것이 좋습니다.

### <a name="best-practices-you-implement"></a>구현하는 모범 사례

**더 많은 데이터**를 사용하는 것이 과도 맞춤을 방지하는 가장 간단하고 좋은 방법이며, 추가된 이점으로 정확도가 높아지기도 합니다. 더 많은 데이터를 사용하는 경우 모델이 정확한 패턴을 기억하는 것이 더 어려워지며, 더 많은 조건을 수용하기 위해 강제로 좀 더 유연한 솔루션에 연결해야 합니다. 또한 **통계 편향**을 인식하여 학습 데이터에 라이브 예측 데이터에 존재하지 않는 격리된 패턴이 포함되지 않도록 해야 합니다. 이 시나리오는 학습 및 테스트 세트 간에 과잉 맞춤이 발생하지 않지만 라이브 테스트 데이터와 비교할 때 과잉 맞춤이 있을 수 있으므로 해결하기 어려울 수 있습니다.

**대상 누출**은 학습/테스트 세트 사이에서는 과잉 맞춤을 볼 수 없지만 예측 시간에 과잉 맞춤이 발생하는 비슷한 문제입니다. 대상 누출은 일반적으로 예측 시간에 없어야 하는 데이터에 액세스하여 학습 동안 모델이 "속임수를 쓸 때" 발생합니다. 예를 들어, 금요일의 상품 가격을 월요일에 예측해야 하지만 기능 중 하나에 실수로 목요일의 데이터가 포함되면 모델은 미래를 볼 수 없으므로 해당 데이터는 예측 시간에 없는 데이터가 됩니다. 대상 누출은 놓치기 쉬운 실수이지만 문제에 대해 비정상적으로 높은 정확도로 규정되는 경우가 많습니다. 주식가를 예측하려고 하며 95% 정확도로 모델을 학습하는 경우 기능에서 대상 누출이 발생할 가능성이 높습니다.

**기능을 제거**하면 모델에서 특정 패턴을 기억하는 데 사용할 필드가 너무 많아지지 않고 보다 유연해지므로 과잉 맞춤을 방지하는 데 도움이 될 수 있습니다. 정량적으로 측정하는 것은 어려울 수 있지만 기능을 제거하고 동일한 정확도를 유지할 수 있는 경우 모델을 더 유연하게 만들어 과잉 맞춤 위험을 줄일 수 있습니다.

### <a name="best-practices-automated-ml-implements"></a>자동화된 ML 구현 모범 사례

**정규화**는 복잡한 과잉 맞춤 모델에 패널티를 부여하여 비용 함수를 최소화하는 프로세스입니다. 정규화 함수에는 여러 가지 형식이 있지만 일반적으로 모델 계수 크기, 분산 및 복잡성에 모두 패널티를 부여합니다. 자동화된 ML은 과잉 맞춤을 제어하는 다른 모델 하이퍼 매개 변수 설정 조합으로 L1(Lasso), L2(Ridge) 및 ElasticNet(L1 및 L2를 동시에)를 사용합니다. 간단히 말해, 자동화된 ML은 모델의 규정 수준을 변경하고 최상의 결과를 선택합니다.

또한 자동화된 ML은 과잉 맞춤을 방지하기 위해 명시적인 **모델 복잡성 제한 사항**을 구현합니다. 대부분의 경우 이 구현은 개별 트리의 최대 깊이가 제한되고 포리스트 또는 앙상블 기술에 사용되는 총 트리 수가 제한되는 의사 결정 트리 또는 프리스트 알고리즘에 특히 적합합니다.

**CV(교차 유효성 검사)** 는 전체 학습 데이터의 여러 하위 세트를 가져오고 각 하위 세트에 대해 모델을 학습하는 프로세스입니다. 이 개념은 모델이 "운이 좋아" 하나의 하위 세트로도 정확도가 매우 높다는 것이지만, 많은 하위 세트를 사용할 경우 모델이 매번 이러한 높은 정확도를 얻지는 못합니다. CV를 수행할 때 유효성 검사 홀드아웃 데이터 세트를 제공하고, CV 겹(하위 세트 수)을 지정하면 자동화된 ML은 모델을 학습하고 하이퍼 매개 변수를 조정하여 유효성 검사 세트의 오류를 최소화합니다 하나의 CV 겹은 과잉 맞춤될 수 있지만, 많은 CV 겹을 사용하면 최종 모델이 과잉 맞춤될 확률을 줄일 수 있습니다. 모델을 한 번 학습하는 대신 각 *n*개 CV 하위 세트에 대해 1번씩 학습하므로 학습 시간이 더 길어지고 그에 따라 더 많은 비용이 초래된다는 단점이 있습니다. 

> [!NOTE]
> 교차 유효성 검사는 기본적으로 사용하도록 설정되어 있지 않으며 자동 ML 설정에서 구성해야 합니다. 그러나 교차 유효성 검사를 구성하고 유효성 검사 데이터 세트를 제공한 후에는 프로세스가 자동으로 수행됩니다. 참조 항목 

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>불균형 데이터를 사용하여 모델 식별

불균형 데이터는 기계 학습 분류 시나리오의 데이터에서 일반적으로 발견되며, 각 클래스에서 불균형 비율로 관찰되는 데이터를 나타냅니다. 이러한 불균형은 입력 데이터가 한 클래스 쪽으로 편향되어 학습된 모델이 해당 편향을 모방하게 되므로 모델의 정확성의 긍정적인 효과를 잘못 인식하게 할 수 있습니다. 

분류 알고리즘은 일반적으로 정확도로 계산되므로 모델의 정확도 점수를 확인하는 것은 불균형 데이터의 영향을 받았는지 식별하는 좋은 방법입니다. 실제로 특정 클래스에 대해 매우 높은 정확도나 매우 낮은 정확도를 보였나요?

또한 자동화된 ML 실행은 다음 차트를 자동으로 생성하므로 모델 분류의 정확성을 이해하고 불균형 데이터의 영향을 받을 수 있는 모델을 식별하는 데 도움이 될 수 있습니다.

차트| Description
---|---
[혼동 행렬](how-to-understand-automated-ml.md#confusion-matrix)| 데이터의 실제 레이블에 대해 올바르게 분류된 레이블을 평가합니다. 
[정밀도-재현율](how-to-understand-automated-ml.md#precision-recall-chart)| 발견된 데이터의 레이블 인스턴스 비율에 대해 올바른 레이블의 비율을 평가합니다. 
[ROC 곡선](how-to-understand-automated-ml.md#roc)| 가양성 레이블 비율에 대해 올바른 레이블의 비율을 평가합니다.

## <a name="handle-imbalanced-data"></a>불균형 데이터 처리 

기계 학습 워크플로를 단순화하는 목표의 일환으로, 자동화된 ML은 불균형 데이터를 처리하는 데 도움이 되는 다음과 같은 기본 제공 기능을 제공합니다. 

- **가중치 열**: 자동화된 ML은 가중치가 적용된 열을 입력으로 지원하여 데이터의 행에 대한 가중치를 높이거나 낮춤으로써 클래스를 더 또는 덜 "중요"하게 만들 수 있습니다.

- 자동화된 ML에서 사용되는 알고리즘은 최대 20:1의 불균형을 적절히 처리할 수 있습니다. 즉, 가장 일반적인 클래스는 가장 덜 일반적인 클래스보다 20배 더 많은 데이터 행을 포함할 수 있습니다.

다음 기술에서는 자동화된 ML 외부의 불균형 데이터를 처리하는 추가 옵션에 대해 설명합니다. 

- 더 작은 클래스를 업샘플링하거나 더 큰 클래스를 다운샘플링하여 클래스 불균형을 균일화하는 재샘플링. 이러한 방법을 사용하려면 처리 및 분석을 위한 전문 기술이 필요합니다.

- 불균형 데이터를 보다 잘 처리하는 성능 메트릭을 사용합니다. 예를 들어, F1 점수는 정밀도 및 재현률의 가중 평균입니다. 정밀도는 분류자의 정확도를 측정하며 낮은 정밀도는 가양성 수가 높음을 나타냅니다. 재현율은 분류자의 완전성을 측정하며 낮은 재현율은 가음성 수가 높음을 나타냅니다. 

## <a name="next-steps"></a>다음 단계

예제를 통해 자동화된 Machine Learning을 사용하는 모델을 작성하는 방법을 알아봅니다.

+ [자습서: Azure Machine Learning을 사용하여 자동으로 회귀 모델 학습](tutorial-auto-train-models.md)을 따릅니다.

+ 자동 학습 실험 설정을 구성합니다.
  + Azure Machine Learning Studio의 경우 [이러한 단계를 사용](how-to-use-automated-ml-for-ml-models.md)합니다.
  + Python SDK를 사용하는 경우 [이러한 단계를 사용](how-to-configure-auto-train.md)합니다.


