---
title: ML Studio (클래식)에 대 한 데이터 준비-팀 데이터 과학 프로세스
description: 기계 학습에 효과적으로 사용될 수 있도록 준비하기 위해 데이터를 전처리하고 정리합니다.
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: caedcf313ab809e9607907545f26ca1b62bbeca7
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/28/2020
ms.locfileid: "76720047"
---
# <a name="tasks-to-prepare-data-for-enhanced-machine-learning"></a>확장된 기계 학습을 위한 데이터 준비 작업
데이터를 미리 처리 하 고 정리 하는 작업은 모델 학습에 데이터 집합을 사용 하기 전에 수행 해야 하는 중요 한 작업입니다. 원시 데이터는 노이즈가 많고, 불안정하고, 값이 누락된 경우가 종종 있습니다. 이러한 데이터를 모델링에 사용하면 결과가 잘못될 수 있습니다. 이러한 작업은 TDSP(팀 데이터 과학 프로세스)의 일부이며 일반적으로 필요한 전처리를 검색하고 계획하는 데 사용되는 데이터 세트의 초기 탐색을 수행합니다. TDSP 프로세스에 대한 자세한 지침은 [팀 데이터 과학 프로세스](overview.md)에 설명된 단계를 참조하세요.

데이터 탐색 태스크와 같은 사전 처리 및 정리 태스크는 SQL 또는 Hive 또는 Azure Machine Learning Studio (클래식)와 같은 다양 한 도구와 언어, 데이터의 저장 위치 및 형식 지정 방법에 따라 R 또는 Python과 같은 다양 한 도구와 언어에서 수행할 수 있습니다. TDSP는 반복 성향을 띠기 때문에, 이러한 작업은 프로세스의 워크플로 내의 다양한 단계에서 발생할 수 있습니다.

이 문서에서는 Azure Machine Learning Studio (클래식)에 데이터를 수집 하기 전이나 후에 수행할 수 있는 다양 한 데이터 처리 개념 및 작업을 소개 합니다.

Azure Machine Learning Studio (클래식) 내에서 수행 되는 데이터 탐색 및 전처리의 예는 [데이터 사전 처리](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/) 비디오를 참조 하세요.

## <a name="why-pre-process-and-clean-data"></a>데이터 전처리 및 정리가 필요한 이유
실제 데이터는 다양한 소스 및 프로세스에서 수집되며 데이터 세트의 품질을 떨어트리는 이상값 또는 손상된 값이 포함될 수 있습니다. 다음과 같은 일반적인 데이터 품질 문제가 자주 발생합니다.

* **불완전**: 데이터에 특성이 없거나 값이 누락되었습니다.
* **노이즈가 많은**: 데이터에 잘못된 레코드 또는 이상값이 있습니다.
* **불일치**: 데이터에 충돌하는 레코드 또는 일치하지 않는 값이 있습니다.

우수한 예측 모델을 구축하려면 우수한 데이터가 필요합니다. "쓰레기를 넣고 쓰레기를 얻는 현상"을 방지하고 데이터 품질을 높여서 궁극적으로 모델 성능을 높이려면 데이터 상태 검사를 수행하여 조기에 데이터 문제를 발견하고 적절한 데이터 처리 및 정리 단계를 결정하는 것이 중요합니다.

## <a name="what-are-some-typical-data-health-screens-that-are-employed"></a>가장 일반적으로 사용되는 데이터 상태 검사 방법으로 어떤 것이 있습니까?
다음을 검사하여 데이터의 전체적인 품질을 확인할 수 있습니다.

* **레코드**수입니다.
* **특성** (또는 **기능**)의 수입니다.
* 특성 **데이터 형식** (명목, 서 수 또는 연속)입니다.
* **누락 된 값**의 수입니다.
* **잘 구성** 된 데이터입니다.
  * 데이터가 TSV 또는 CSV로 되어 있으면 열 구분 기호 및 줄 구분 기호가 열과 줄을 항상 올바르게 구분하는지 확인합니다.
  * 데이터가 HTML 또는 XML 형식이면 해당 표준에 따라 올바르게 구성되었는지 확인합니다.
  * 또한 반 구조적 데이터 또는 구조화되지 않은 데이터에서 구조적 정보를 추출하려면 구문 분석이 필요할 수 있습니다.
* **데이터 레코드가 일치 하지 않습니다**. 값의 범위가 허용되는지 확인하세요. 예를 들어 데이터에 학생 GPA (학년 평균)이 포함 된 경우 GPA이 지정 된 범위 (예: 0 ~ 4)에 있는지 확인 합니다.

데이터 관련 문제를 발견 하면 **처리 단계가** 필요 합니다. 여기에는 누락 된 값 정리, 데이터 정규화, 분할, 텍스트 처리를 사용 하 여 데이터 정렬에 영향을 줄 수 있는 포함 된 문자 제거 및/또는 바꾸기, 공통 필드의 혼합 데이터 형식 등이 포함 됩니다.

**Azure Machine Learning은 올바른 형식의 테이블 형식 데이터**를 사용 합니다.  데이터가 이미 테이블 형식으로 되어 있는 경우에는 Machine Learning에서 Azure Machine Learning Studio (클래식)를 사용 하 여 데이터 사전 처리를 직접 수행할 수 있습니다.  데이터가 테이블 형식이 아닌 XML 형식이라고 한다면 데이터를 테이블 형식으로 변환하려면 구분 분석이 필요할 수 있습니다.  

## <a name="what-are-some-of-the-major-tasks-in-data-pre-processing"></a>데이터 전처리의 주요 작업
* **데이터 정리**: 누락 된 값을 입력 하 고, 잡음이 있는 데이터와 이상 값을 검색 하 고 제거 합니다.
* **데이터 변환**: 데이터를 정규화 하 여 차원 및 노이즈를 줄입니다.
* **데이터 감소**: 데이터를 쉽게 처리할 수 있도록 데이터 레코드 또는 특성을 샘플링 합니다.
* **데이터**분할: 특정 기계 학습 방법과 함께 사용 하기 쉽도록 연속 특성을 범주 특성으로 변환 합니다.
* **텍스트 정리**: 데이터의 불일치를 일으킬 수 있는 포함 된 문자를 제거 합니다. 예를 들어 탭으로 구분 된 데이터 파일에 포함 된 탭, 레코드를 중단할 수 있는 포함 된 새 줄 등이 있습니다.

아래 섹션에서는 일부 데이터 처리 단계에 대해 자세히 설명합니다.

## <a name="how-to-deal-with-missing-values"></a>누락된 값을 처리하는 방법
누락된 값을 처리하려면 누락된 값이 문제 해결에 더 나은 이유를 먼저 확인하는 것이 좋습니다. 일반적인 누락 값 처리 방법은 다음과 같습니다.

* **삭제**: 값이 누락된 레코드를 제거합니다.
* **더미 대체**: 누락된 값을 더미로 대체합니다. 예를 들어 범주 값은 *알 수 없음*, 숫자 값은 0으로 대체합니다.
* **평균 대체**: 누락된 값이 숫자이면 평균으로 대체합니다.
* **빈도 대체**: 누락된 값이 범주이면 가장 빈도가 높은 항목으로 대체합니다.
* **회귀 대체**: 회귀 메서드를 사용하여 누락된 값을 회귀된 값으로 대체합니다.  

## <a name="how-to-normalize-data"></a>데이터를 정규화하는 방법
데이터 정규화는 숫자 값을 지정 된 범위에 다시 조정 합니다. 일반적인 데이터 정규화 방법은 다음과 같습니다.

* **최소-최대 정규화**: 0과 1 사이에서 데이터를 선형적으로 범위로 변환합니다. 여기서 최소값은 0, 최대값은 1로 조정됩니다.
* **Z 점수 정규화**: 평균 및 표준 편차를 기반으로 데이터 조정: 데이터와 평균의 차이를 표준 편차로 나눕니다.
* **소수점 배열**: 특성 값의 소수점을 이동하여 데이터 크기를 조정합니다.  

## <a name="how-to-discretize-data"></a>데이터를 분할하는 방법
연속 값을 명목 특성 또는 간격으로 변환하여 데이터를 분할할 수 있습니다. 다음은 이 작업을 수행하는 방법 중 일부입니다.

* **동일 너비 범주화**: 특성의 모든 가능한 값 범위를 크기가 같은 N개의 그룹으로 나누고 bin 번호를 사용하여 bin에 속하는 값을 할당합니다.
* **동일 높이 범주화**: 특성의 모든 가능한 값 범위를 인스턴스 수가 같은 N개의 그룹으로 나누고 bin 번호를 사용하여 bin에 속하는 값을 할당합니다.  

## <a name="how-to-reduce-data"></a>데이터를 줄이는 방법
데이터를 쉽게 처리할 수 있도록 데이터 크기를 줄이는 다양한 방법이 있습니다. 데이터 크기 및 도메인에 따라 다음 방법을 적용할 수 있습니다.

* **레코드 샘플링**: 데이터 레코드를 샘플링하고 데이터에서 대표적인 하위 집합만 선택합니다.
* **특성 샘플링**: 데이터에서 가장 중요한 특성의 하위 집합만 선택합니다.  
* **집계**: 데이터를 여러 그룹으로 나누고 각 그룹에 대한 숫자를 저장 합니다. 예를 들어 어떤 식당 체인의 지난 20년 간 일일 수익을 월별 수익으로 집계하면 데이터 크기를 줄일 수 있습니다.  

## <a name="how-to-clean-text-data"></a>텍스트 데이터를 정리하는 방법
**테이블 형식 데이터의 텍스트 필드에** 는 열 맞춤 및/또는 레코드 경계에 영향을 주는 문자가 포함 될 수 있습니다. 예를 들어 탭으로 구분 된 파일에 포함 된 탭으로 인해 열이 잘못 정렬 되 고 줄 바꿈 문자가 포함 된 줄 바꿈 문자가 기록 됩니다. 텍스트를 쓰거나 읽는 동안 잘못 된 텍스트 인코딩 처리가 발생 하 여 정보 손실이 발생 하 고 읽을 수 없는 문자가 실수로 도입 됩니다 (예: null). 또한 텍스트 구문 분석에 영향을 줄 수 있습니다. 데이터를 올바르게 정렬하고 구조화되지 않은 데이터 또는 반 구조적 데이터에서 구조적 데이터를 추출할 수 있도록 텍스트 필드를 정리하려면 신중한 구문 분석 및 편집 작업이 필요할 수 있습니다.

**데이터 탐색**을 통해 초기에 데이터를 살펴볼 수 있습니다. 이 단계에서 다양한 데이터 문제를 파악하고 그에 맞는 적절한 방법을 적용하여 이러한 문제를 해결할 수 있습니다.  문제의 원인이 무엇인지, 문제가 어떻게 시작되었는지 등의 질문에 대한 답을 고민해 보는 것이 중요합니다. 이 프로세스를 사용 하면이 문제를 해결 하기 위해 수행 해야 하는 데이터 처리 단계를 결정할 수도 있습니다. 최종 사용 사례와 가상 사용자를 식별 하 여 데이터 처리 작업의 우선 순위를 지정할 수도 있습니다.

## <a name="references"></a>참조
> *데이터 마이닝: 개념 및 기술*, Third Edition, Morgan Kaufmann, 2011, Jiawei Han, Micheline Kamber 및 Jian Pei
> 
> 

