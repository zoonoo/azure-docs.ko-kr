---
title: '승격 된 의사 결정 트리 회귀: 모듈 참조'
titleSuffix: Azure Machine Learning
description: Azure Machine Learning에서 향상 된 의사 결정 트리 회귀 모듈을 사용 하 여 부스트를 사용 하는 회귀 트리의 앙상블을 만드는 방법에 대해 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: xiaoharper
ms.author: zhanxia
ms.date: 10/22/2019
ms.openlocfilehash: 4271a180a0f00ae921de9b8deb9a3e5123f9b519
ms.sourcegitcommit: a9b1f7d5111cb07e3462973eb607ff1e512bc407
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/22/2020
ms.locfileid: "76314490"
---
# <a name="boosted-decision-tree-regression-module"></a>승격 된 의사 결정 트리 회귀 모듈

이 문서에서는 Azure Machine Learning 디자이너의 모듈을 설명 합니다.

이 모듈을 사용 하 여 부스트를 사용 하는 회귀 트리의 앙상블을 만듭니다. *부스트* 는 각 트리가 이전 트리에 종속 됨을 의미 합니다. 알고리즘은 앞에 오는 트리의 나머지를 맞추는 방법으로 학습 합니다. 따라서 의사 결정 트리 앙상블이 승격되면 정확도는 개선되지만 적용 범위가 감소할 약간의 위험이 따릅니다.  
  
이 회귀 메서드는 감독 된 학습 메서드 이므로 *레이블이 지정 된 데이터 집합이*필요 합니다. 레이블 열은 숫자 값을 포함 해야 합니다.  

> [!NOTE]
> 숫자 변수를 사용하는 데이터 집합에만 이 모듈을 사용합니다.  

모델을 정의한 후에는 [학습 모델](./train-model.md)을 사용 하 여 학습 합니다.

  
## <a name="more-about-boosted-regression-trees"></a>승격 된 회귀 트리에 대 한 자세한 정보  

승격은 모음 만들기, 임의 포리스트 등과 함께 앙상블 모델을 만드는 여러 기존 방법 중 하나입니다.  Azure Machine Learning에서 승격 된 의사 결정 트리는 마트 그라데이션 상승 알고리즘의 효율적인 구현을 사용 합니다. 경사 승격은 회귀 문제에 대한 기계 학습 기술로, 미리 정의된 손실 함수를 사용해 각 단계의 오류를 측정하고 다음 단계에서 오류를 수정하는 방식으로 각 회귀 트리를 단계별로 작성합니다. 따라서 예측 모델은 실제로는 더 약한 예측 모델의 앙상블입니다.  
  
회귀 문제에서 부스트는 일련의 트리를 단계별로 작성 한 다음 임의의 구별할 손실 함수를 사용 하 여 최적의 트리를 선택 합니다.  
  
자세한 내용은 다음 문서를 참조하세요.  
  
+ [https://wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting](https://wikipedia.org/wiki/Gradient_boosting)

    그라데이션 향상에 대 한이 위키백과 문서에서는 승격 된 트리에 대해 약간의 배경을 제공 합니다. 
  
-  [https://research.microsoft.com/apps/pubs/default.aspx?id=132652](https://research.microsoft.com/apps/pubs/default.aspx?id=132652)  

    Microsoft Research: From RankNet to LambdaRank to LambdaMART: 개요. By J.C. Burges.

경사 승격 방법은 분류 문제에도 사용할 수 있습니다. 이 경우에는 해당 문제를 적절한 손실 함수가 포함된 회귀로 줄입니다. 분류 작업의 승격 된 트리 구현에 대 한 자세한 내용은 [2 클래스 승격 된 의사 결정 트리](./two-class-boosted-decision-tree.md)를 참조 하세요.  

## <a name="how-to-configure-boosted-decision-tree-regression"></a>승격 된 의사 결정 트리 회귀를 구성 하는 방법

1.  승격 된 **의사 결정 트리** 모듈을 파이프라인에 추가 합니다. **회귀** 범주의 **Machine Learning**, **초기화**에서이 모듈을 찾을 수 있습니다. 
  
2.  **강사 모드 만들기** 옵션을 설정 하 여 모델을 학습 하는 방법을 지정 합니다.  
  
    -   **단일 매개 변수**: 모델을 구성 하는 방법을 알고 있으며 특정 값 집합을 인수로 제공 하는 경우이 옵션을 선택 합니다.  
   
  
3. **트리 당 최대 리프 수**: 모든 트리에서 만들 수 있는 터미널 노드 (리프)의 최대 수를 표시 합니다.  

    이 값을 늘리면 트리 크기가 커지고 정밀도는 높아질 수 있지만 학습 시간이 더 길어지고 과잉 맞춤이 발생할 수 있습니다.  

4. **리프 노드당 최소 샘플 수**: 트리에서 터미널 노드 (리프)를 만드는 데 필요한 최소 사례 수를 표시 합니다.

    이 값을 늘려 새 규칙을 작성하기 위한 임계값을 늘립니다. 예를 들어, 기본값이 1이면 단일 사례만으로도 새 규칙을 하나 작성할 수 있습니다. 값을 5로 늘리면 학습 데이터에 동일한 조건을 만족하는 사례가 다섯 개 이상 있어야 합니다.

5. **학습 률**: 학습 하는 동안 단계 크기를 정의 하는 0에서 1 사이의 숫자를 입력 합니다. 학습 속도는 최적의 솔루션에 대 한 학습자 수렴의 속도 또는 속도를 결정 합니다. 단계 크기가 너무 큰 경우 최적의 솔루션을 과도 하 게 사용할 수 있습니다. 단계 크기가 너무 작은 경우 학습은 최상의 솔루션에서 수렴 하는 데 더 오래 걸립니다.

6. **생성 된 트리 수**: 앙상블에서 만들 의사 결정 트리의 총 수를 표시 합니다. 더 많은 의사 결정 트리를 만들어 잠재적으로 더 나은 검사를 얻을 수 있지만 학습 시간이 늘어납니다.

    또한이 값은 학습 된 모델을 시각화할 때 표시 되는 트리 수를 제어 합니다. 단일 트리를 보거나 인쇄 하려면 값을 1로 설정 하면 됩니다. 그러나 한 개의 트리 (초기 매개 변수 집합이 있는 트리)만 생성 되며 추가 반복은 수행 되지 않습니다.

7. **난수 초기값**: 임의의 초기값으로 사용할 선택적인 음수가 아닌 정수를 입력 합니다. 초기값을 지정 하면 동일한 데이터 및 매개 변수가 있는 실행에 대해 재현 가능성 됩니다.

    기본적으로 임의 초기값은 0으로 설정 됩니다. 즉, 시스템 클록에서 초기 초기값을 가져옵니다.
  
8. **알 수 없는 범주 수준 허용**: 학습 및 유효성 검사 집합에 알 수 없는 값에 대 한 그룹을 만들려면이 옵션을 선택 합니다. 이 옵션의 선택을 취소 하면 모델에서 학습 데이터에 포함 된 값만 수락할 수 있습니다. 알려진 값에 대 한 모델의 정확도가 떨어질 수 있지만 새 (알 수 없는) 값에 대해 더 나은 예측을 제공할 수 있습니다.

9. 학습 데이터 집합 및 학습 모듈 중 하나를 추가 합니다.

    - 담당자 **모드 만들기** 옵션을 **단일 매개 변수**로 설정 하는 경우 [모델 학습](train-model.md) 모듈을 사용 합니다.  
  
    

10. 파이프라인을 실행합니다.  
  
## <a name="results"></a>결과

학습 완료 후:

+ 모델을 점수 매기기에 사용 하려면 [점수 모델](./score-model.md)에 연결 하 여 새 입력 예제에 대 한 값을 예측 합니다.

+ 학습 된 모델의 스냅숏을 저장 하려면 **학습 된 모델** 의 오른쪽 패널에서 **출력** 탭을 선택 하 고 **데이터 집합 등록** 아이콘을 클릭 합니다. 학습 된 모델의 복사본은 모듈 트리에 모듈로 저장 되며 파이프라인의 연속 실행에서 업데이트 되지 않습니다.

## <a name="next-steps"></a>다음 단계

Azure Machine Learning [사용할 수 있는 모듈 집합](module-reference.md) 을 참조 하세요. 
