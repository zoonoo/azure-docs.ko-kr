---
title: 서비스에 대 한 HA를 확장 하 고 제공 하는 상태 프로브
titleSuffix: Azure Load Balancer
description: 이 문서에서는 상태 프로브를 사용 하 여 인스턴스를 모니터링 하는 방법에 대해 알아봅니다 Azure Load Balancer
services: load-balancer
documentationcenter: na
author: asudbring
manager: kumudD
ms.service: load-balancer
ms.devlang: na
ms.topic: article
ms.custom: seodec18
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 09/17/2019
ms.author: allensu
ms.openlocfilehash: ffb9480508366b223e49f173df3dc76cb711116d
ms.sourcegitcommit: 984c5b53851be35c7c3148dcd4dfd2a93cebe49f
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/28/2020
ms.locfileid: "76769181"
---
# <a name="load-balancer-health-probes"></a>Load Balancer 상태 프로브

Azure Load Balancer에서 부하 분산 규칙을 사용 하는 경우 Load Balancer에서 백 엔드 끝점 상태를 검색할 수 있도록 상태 프로브를 지정 해야 합니다.  상태 프로브 및 프로브 응답의 구성에 따라 새 흐름을 수신할 백 엔드 풀 인스턴스가 결정 됩니다. 상태 프로브를 사용 하 여 백 엔드 끝점에서 응용 프로그램의 오류를 검색할 수 있습니다. 또한 상태 프로브에 대한 사용자 지정 응답을 생성하고 흐름 제어를 위해 상태 프로브를 사용하여 부하 또는 계획된 가동 중지 시간을 관리할 수 있습니다. 상태 프로브가 실패 하면 Load Balancer는 해당 비정상 인스턴스에 대 한 새 흐름 전송을 중지 합니다. 아웃 바운드 연결에는 영향을 주지 않으며 인바운드 연결만 영향을 받습니다.

상태 프로브는 여러 프로토콜을 지원합니다. 특정 상태 프로브 프로토콜의 가용성은 SKU Load Balancer 따라 다릅니다.  또한이 표에 표시 된 것 처럼 Load Balancer SKU에 따라 서비스의 동작이 달라 집니다.

| | 표준 SKU | 기본 SKU |
| --- | --- | --- |
| [상태 프로브 유형](#types) | TCP, HTTP, HTTPS | TCP, HTTP |
| [프로브 다운 동작](#probedown) | 모든 프로브가 다운되고, 모든 TCP 흐름이 계속됩니다. | 모든 프로브는 모든 TCP 흐름이 만료 됩니다. | 


>[!IMPORTANT]
>신뢰할 수 있는 서비스를 만들려면 아래 중요 한 [설계 지침](#design) 을 포함 하 여이 문서 전체를 검토 합니다.

>[!IMPORTANT]
>Load Balancer 상태 프로브는 168.63.129.16 IP 주소에서 시작되며, 프로브에서 인스턴스를 표시하기 위해 차단되지 않아야 합니다.  자세한 내용은 [원본 IP 주소 프로브](#probesource)를 검토하세요.

## <a name="probes"></a>프로브 구성

상태 프로브 구성은 다음 요소로 구성 됩니다.

- 개별 프로브 사이의 간격 기간
- 프로브가 다른 상태로 전환 되기 전에 관찰 해야 하는 프로브 응답의 수입니다.
- 프로브 프로토콜
- 프로브 포트
- Http (S) 프로브를 사용할 때 HTTP GET에 사용할 HTTP 경로입니다.

>[!NOTE]
>Azure PowerShell, Azure CLI, 템플릿 또는 API를 사용 하는 경우 프로브 정의가 필수가 아니거나 확인 되지 않습니다. 프로브 유효성 검사 테스트는 Azure Portal을 사용 하는 경우에만 수행 됩니다.

## <a name="understanding-application-signal-detection-of-the-signal-and-reaction-of-the-platform"></a>응용 프로그램 신호 이해, 신호 검색 및 플랫폼 반응 이해

프로브 응답 수는 두 가지 모두에 적용 됩니다.

- 인스턴스를 위쪽으로 표시할 수 있는 성공적인 프로브 수
- 인스턴스가 종료 된 것으로 표시 되는 실패 한 프로브 수입니다.

지정 된 시간 제한 및 간격 값은 인스턴스를 위쪽 또는 아래쪽으로 표시할지 여부를 결정 합니다.  간격의 기간에 프로브 응답 수를 곱하여 프로브 응답을 검색 해야 하는 기간을 결정 합니다.  그리고 서비스는 필요한 프로브를 달성 한 후에도 반응 합니다.

예제를 사용 하 여 더 많은 동작을 설명할 수 있습니다. 프로브 응답 수를 2로 설정 하 고 간격을 5 초로 설정한 경우 2 초 간격 내에서 프로브 실패 2 개를 관찰 해야 함을 의미 합니다.  응용 프로그램의 상태가 변경 될 수 있을 때 프로브를 전송 하는 시간이 동기화 되지 않기 때문에 다음과 같은 두 가지 시나리오에서 검색할 시간을 바인딩할 수 있습니다.

1. 첫 번째 프로브가 도착 하기 직전에 응용 프로그램에서 실패 한 프로브 응답을 생성 하기 시작 하면이 이벤트의 검색에는 10 초 (2 x 5 초 간격)와 응용 프로그램에서 첫 번째 오류가 발생할 때 실패를 알리기 시작 하는 시간이 프로브가 도착 했습니다.  이 검색은 10 초 이상 소요 된다고 가정할 수 있습니다.
2. 첫 번째 프로브가 도착 한 후에 응용 프로그램에서 실패 한 프로브 응답을 생성 하기 시작 하는 경우 이러한 이벤트의 검색은 다음 프로브 도착 (및 실패)과 다른 10 초 (2 x 5 초 간격)까지 시작 되지 않습니다.  이 검색은 15 초 미만으로 수행 되는 것으로 간주할 수 있습니다.

이 예에서는 검색이 발생 한 후이 변경에 반응 하는 데 약간의 시간이 걸립니다.  즉, 다음에 따라이 사용 됩니다. 

1. 응용 프로그램이 상태 변경을 시작 하는 경우
2. 이 변경 내용이 검색 되 고 필요한 조건 (지정 된 간격으로 전송 된 프로브 수)을 충족 하는 경우
3. 플랫폼에서 감지를 전달 하는 경우 

실패 한 프로브에 대 한 반응은 응용 프로그램에서 신호의 변경에 반응 하는 데 최대 10 초 이상, 최대 15 초 이상까지 소요 될 수 있습니다.  이 예는 발생 하는 상황을 보여 주기 위해 제공 됩니다. 그러나이 예제에 나와 있는 위의 대략적인 지침을 벗어나는 정확한 기간을 예측할 수는 없습니다.
 
## <a name="types"></a>프로브 유형

상태 프로브에서 사용 하는 프로토콜은 다음 중 하나로 구성할 수 있습니다.

- [TCP 수신기](#tcpprobe)
- [HTTP 엔드포인트](#httpprobe)
- [HTTPS 엔드포인트](#httpsprobe)

사용 가능한 프로토콜은 사용 되는 Load Balancer SKU에 따라 다릅니다.

|| TCP | HTTP | HTTPS |
| --- | --- | --- | --- |
| 표준 SKU |    &#9989; |   &#9989; |   &#9989; |
| 기본 SKU |   &#9989; |   &#9989; | &#10060; |

### <a name="tcpprobe"></a> TCP 프로브

TCP 프로브는 정의된 포트를 통해 3방향 개방형 TCP 핸드셰이크를 수행하여 연결을 시작합니다.  TCP 프로브는 4방향 폐쇄형 TCP 핸드셰이크를 사용하여 연결을 종료합니다.

최소 프로브 간격은 5초이고, 비정상 응답의 최소 수는 2입니다.  모든 간격의 총 지속 시간은 120초를 초과할 수 없습니다.

TCP 프로브가 실패하는 경우는 다음과 같습니다.
* 인스턴스의 TCP 수신기가 제한 시간 동안 전혀 응답하지 않습니다.  프로브는 프로브 다운을 표시하기 전에 응답하지 않도록 구성된 실패한 프로브 요청의 수에 따라 표시됩니다.
* 프로브가 인스턴스에서 TCP 재설정을 받습니다.

다음은 리소스 관리자 템플릿에서 이러한 종류의 프로브 구성을 표현할 수 있는 방법을 보여 줍니다.

```json
    {
      "name": "tcp",
      "properties": {
        "protocol": "Tcp",
        "port": 1234,
        "intervalInSeconds": 5,
        "numberOfProbes": 2
      },
```

### <a name="httpprobe"></a><a name="httpsprobe"></a> HTTP/HTTPS 프로브

>[!NOTE]
>HTTPS 프로브는 [표준 Load Balancer](load-balancer-standard-overview.md)에만 제공됩니다.

HTTP 및 HTTPS 프로브는 TCP 프로브에서 구축되고, 지정된 경로가 포함된 HTTP GET을 실행합니다. 두 프로브 모두 HTTP GET에 대한 상대 경로를 지원합니다. HTTPS 프로브는 TLS(전송 계층 보안, SSL이라고도 함)가 추가되었다는 점을 제외하면 HTTP 프로브와 동일합니다. 인스턴스에서 제한 시간 내에 200 HTTP 상태로 응답하면 상태 프로브가 표시됩니다.  이 상태 프로브는 기본적으로 구성된 상태 프로브 포트를 15초마다 확인하려고 합니다. 최소 프로브 간격은 5초입니다. 모든 간격의 총 지속 시간은 120초를 초과할 수 없습니다.

HTTP/HTTPS 프로브는 프로브 포트가 서비스 자체의 수신기 이기도 한 경우 부하 분산 장치 순환에서 인스턴스를 제거 하는 사용자 고유의 논리를 구현 하는 데 유용할 수도 있습니다. 예를 들어 CPU 백분율이 90%를 초과하고 200 이외의 HTTP 상태를 반환하는 경우 인스턴스를 제거하도록 결정할 수 있습니다. 

> [!NOTE] 
> HTTPS 프로브를 사용 하려면 전체 체인에서 SHA256의 최소 서명 해시가 있는 인증서를 사용 해야 합니다.

Cloud Services를 사용하고 w3wp.exe를 사용하는 웹 역할이 있는 경우 웹 사이트의 자동 모니터링도 수행할 수 있습니다. 웹 사이트 코드에서 실패하면 부하 분산 장치 프로브로 200이 아닌 상태를 반환합니다.

HTTP/HTTPS 프로브가 실패하는 경우는 다음과 같습니다.
* 프로브 엔드포인트에서 200 이외의 HTTP 응답 코드(예: 403, 404 또는 500)를 반환합니다. 이 경우 상태 프로브가 즉시 가동 중단 상태로 표시됩니다. 
* 프로브 엔드포인트는 31초의 제한 시간 동안 전혀 응답하지 않습니다. 프로브가 실행 중이 아니라고 표시되고, 모든 시간 제한 간격의 합계에 도달하기 전에 다중 프로브 요청이 응답하지 않을 수 있습니다.
* 프로브 엔드포인트에서 TCP 재설정을 통해 연결을 닫습니다.

다음은 리소스 관리자 템플릿에서 이러한 종류의 프로브 구성을 표현할 수 있는 방법을 보여 줍니다.

```json
    {
      "name": "http",
      "properties": {
        "protocol": "Http",
        "port": 80,
        "requestPath": "/",
        "intervalInSeconds": 5,
        "numberOfProbes": 2
      },
```

```json
    {
      "name": "https",
      "properties": {
        "protocol": "Https",
        "port": 443,
        "requestPath": "/",
        "intervalInSeconds": 5,
        "numberOfProbes": 2
      },
```

### <a name="guestagent"></a>게스트 에이전트 프로브(클래식만)

클라우드 서비스 역할(작업자 역할 및 웹 역할)은 기본적으로 게스트 에이전트를 사용하여 프로브를 모니터링합니다.  게스트 에이전트 프로브는 최후의 구성입니다.  상태 프로브는 항상 TCP 또는 HTTP 프로브를 통해 명시적으로 사용합니다. 게스트 에이전트 프로브는 대부분의 애플리케이션 시나리오에 대해 명시적으로 정의된 프로브만큼 효과적이지 않습니다.

게스트 에이전트 프로브는 VM 내부의 게스트 에이전트를 검사합니다. 그런 다음 인스턴스가 준비 상태인 경우에만 수신 대기하며 HTTP 200 OK로 응답합니다. 다른 상태는 사용 중, 재생 중 또는 중지 중입니다.

자세한 내용은 [상태 프로브에 대한 서비스 정의 파일(csdef) 구성](https://msdn.microsoft.com/library/azure/ee758710.aspx) 또는 [클라우드 서비스를 위한 공용 부하 분산 장치 만들기 시작](https://docs.microsoft.com/azure/load-balancer/load-balancer-get-started-internet-classic-cloud#check-load-balancer-health-status-for-cloud-services)을 참조하세요.

게스트 에이전트가 HTTP 200 OK로 응답하는 데 실패하면 부하 분산 장치가 인스턴스를 응답하지 않음으로 표시합니다. 그런 다음, 해당 인스턴스에 흐름을 보내지 않도록 중지합니다. 부하 분산 장치는 인스턴스를 계속 검사합니다. 

게스트 에이전트에서 200 HTTP로 응답하면 부하 분산 장치는 새 흐름을 해당 인스턴스에 다시 보냅니다.

웹 역할을 사용하는 경우 웹 사이트 코드는 일반적으로 w3wp.exe에서 실행되며 이는 Azure 패브릭 또는 게스트 에이전트에서 모니터링하지 않습니다. w3wp.exe(예: HTTP 500 응답)의 실패는 게스트 에이전트에 보고되지 않습니다. 결과적으로 부하 분산 장치는 해당 인스턴스를 순환에서 제거하지 않습니다.

<a name="health"></a>
## <a name="probehealth"></a>검색 동작

TCP, HTTP 및 HTTPS 상태 프로브는 정상으로 간주 되며 다음과 같은 경우 백엔드 끝점을 정상으로 표시 합니다.

* VM이 부팅된 후에는 상태 프로브가 성공 상태로 표시됩니다.
* 백 엔드 끝점을 정상으로 표시 하는 데 필요한 프로브 수가 지정 되어 있습니다.

정상 상태를 달성 한 모든 백 엔드 끝점은 새 흐름을 받을 수 있습니다.  

> [!NOTE]
> 상태 프로브가 변동 되는 경우 부하 분산 장치는 백엔드 끝점을 다시 정상 상태로 전환 하기 전에 더 오래 대기 합니다. 이러한 추가 대기 시간은 의도적인 정책으로, 사용자 및 인프라를 보호합니다.

## <a name="probedown"></a>프로브 다운 동작

### <a name="tcp-connections"></a>TCP 연결

새 TCP 연결은 남은 정상 백엔드 끝점에 성공 합니다.

백 엔드 끝점의 상태 프로브가 실패 하면이 백 엔드 끝점에 대 한 TCP 연결이 설정 됩니다.

백 엔드 풀의 모든 인스턴스에 대한 모든 프로브가 실패하면 새 흐름을 백 엔드 풀로 보내지 않습니다. 표준 Load Balancer는 설정된 TCP 흐름이 계속되도록 허용합니다.  기본 Load Balancer는 백 엔드 풀에 대한 기존의 모든 TCP 흐름을 종료합니다.
 
Load Balancer는 통과 서비스(TCP 연결을 종료하지 않음)이며, 클라이언트와 VM의 게스트 OS 및 애플리케이션 사이에 항상 흐름이 존재합니다. 모든 프로브를 사용 하는 풀을 사용 하면 흐름을 받고 SYN ACK로 응답 하는 정상적인 백 엔드 끝점이 없으므로 프런트 엔드가 TCP 연결 열기 시도 (SYN)에 응답 하지 않습니다.

### <a name="udp-datagrams"></a>UDP 데이터그램

UDP 데이터 그램은 정상 백엔드 끝점으로 전달 됩니다.

UDP는 비연결형이며 UDP에 대해 추적된 흐름 상태가 없습니다. 백 엔드 끝점의 상태 프로브가 실패 하면 기존 UDP 흐름이 백 엔드 풀의 다른 정상 인스턴스로 이동 합니다.

백 엔드 풀의 모든 인스턴스에 대한 모든 프로브가 실패하면 기본 및 표준 Load Balancer에 대한 기존 UDP 흐름이 종료됩니다.

<a name="source"></a>
## <a name="probesource"></a>원본 IP 주소 프로브

Load Balancer는 내부 상태 모델에 분산 프로빙 서비스를 사용합니다. 프로빙 서비스는 VM이 있는 각 호스트에 상주하며, 필요할 때 고객 구성별로 상태 프로브를 생성하도록 프로그래밍할 수 있습니다. 상태 프로브 트래픽은 상태 프로브를 생성하는 프로빙 서비스와 고객 VM 간을 직접 이동합니다. 모든 Load Balancer 상태 프로브는 해당 원본으로 168.63.129.16 IP 주소에서 시작됩니다.  RFC1918 공간이 아닌 VNet 내의 IP 주소 공간을 사용할 수 있습니다.  전역적으로 예약된 Microsoft 소유의 IP 주소를 사용하면 IP 주소가 VNet 내에서 사용하는 IP 주소 공간과 충돌할 가능성이 줄어듭니다.  이 IP 주소는 모든 지역에서 동일하고 변경되지 않으며, 내부 Azure 플랫폼 구성 요소만 이 IP 주소에서 패킷을 소싱할 수 있으므로 보안 위험을 초래하지 않습니다. 

AzureLoadBalancer 서비스 태그는 [네트워크 보안 그룹](../virtual-network/security-overview.md)에서 이 원본 IP 주소를 식별하고 기본적으로 상태 프로브 트래픽을 허용합니다.

상태 프로브를 Load Balancer 하는 것 외에도 [다음 작업은이 IP 주소를 사용](../virtual-network/what-is-ip-address-168-63-129-16.md)합니다.

- VM 에이전트에서 플랫폼과 통신하도록 설정하여 "준비" 상태에 있음을 알립니다.
- DNS 가상 서버와 통신하도록 설정하여 사용자 지정 DNS 서버를 정의하지 않은 고객에게 필터링된 이름 확인을 제공합니다.  이 필터링을 통해 고객은 배포의 호스트 이름만 확인할 수 있습니다.
- VM이 Azure의 DHCP 서비스에서 동적 IP 주소를 가져올 수 있도록 합니다.

## <a name="design"></a> 디자인 지침

상태 프로브는 서비스를 탄력적으로 유지하고 확장할 수 있도록 하는 데 사용됩니다. 구성 또는 디자인 패턴이 잘못되면 서비스의 가용성 및 확장성에 영향을 줄 수 있습니다. 이 전체 문서를 검토하고, 이 프로브 응답이 가동 중지 또는 가동 상태로 표시될 경우 시나리오에 미치는 영향과 애플리케이션 시나리오의 가용성에 어떤 영향을 미칠지 고려하세요.

응용 프로그램에 대 한 상태 모델을 디자인할 때 해당 인스턴스의 상태 __와__ 사용자가 제공 하는 응용 프로그램 서비스를 반영 하는 백 엔드 끝점의 포트를 검색 해야 합니다.  애플리케이션 포트와 프로브 포트는 동일하지 않아도 됩니다.  일부 시나리오에서는 프로브 포트가 애플리케이션이 서비스를 제공하는 포트와 달라야 할 수 있습니다.  

때때로 애플리케이션이 애플리케이션 상태를 검색할 뿐만 아니라 인스턴스가 새 흐름을 수신할지 여부를 Load Balancer에 직접 신호로 알리는 상태 프로브 응답을 생성하는 것이 유용할 수 있습니다.  상태 프로브가 실패하도록 하여 애플리케이션이 새 흐름에 대한 역압 및 스로틀 전달을 생성할 수 있도록 프로브 응답을 조작하거나 애플리케이션의 유지 관리를 준비하고 시나리오 드레이닝을 시작할 수 있습니다.  표준 Load Balancer를 사용하는 경우 [프로브의 작동 중지](#probedown) 신호가 발생하면 유휴 시간 종료 또는 연결 종료가 나타날 때까지 항상 TCP 흐름이 계속됩니다. 

UDP 부하 분산의 경우, 백 엔드 끝점에서 사용자 지정 상태 프로브 신호를 생성 하 고 해당 수신기를 대상으로 하는 TCP, HTTP 또는 HTTPS 상태 프로브를 사용 하 여 UDP 응용 프로그램의 상태를 반영 해야 합니다.

[표준 Load Balancer](load-balancer-standard-overview.md)와 함께 [HA 포트 부하 분산 규칙](load-balancer-ha-ports-overview.md)을 사용하면, 모든 포트의 부하가 분산되고 단일 상태 프로브 응답에는 전체 인스턴스의 상태가 반영되어야 합니다.

이 구성을 사용할 경우 시나리오에서 연속 오류로 이어질 수 있으므로 VNet의 다른 인스턴스로 상태 프로브를 받는 인스턴스를 통해 상태 프로브를 변환하거나 프록시하지 않아야 합니다.  타사 어플라이언스 세트가 Load Balancer 리소스의 백 엔드 풀에 배포되어 어플라이언스에 대한 확장 및 중복성을 제공하고, 타사 어플라이언스가 어플라이언스 뒤에 있는 다른 가상 머신으로 프록시 또는 변환하는 포트를 프로브하도록 상태 프로브가 구성되어 있다고 가정합니다.  사용 중인 동일한 포트를 프로브하여 요청을 변환하거나 어플라이언스 뒤의 다른 가상 머신으로 프록시하려는 경우, 어플라이언스 뒤의 단일 가상 머신에서 어떤 프로브 응답이 발생하더라도 어플라이언스 자체는 중단 상태로 표시됩니다. 이 구성을 통해 전체 응용 프로그램 시나리오에 대 한 단일 백엔드 끝점의 결과로 전체 응용 프로그램 시나리오의 연계 오류가 발생할 수 있습니다.  간헐적 프로브 실패는 Load Balancer가 원래 대상(어플라이언스 인스턴스)을 작동 중단으로 표시하도록 하고, 전체 애플리케이션 시나리오를 비활성화하도록 하는 트리거로 작용할 수 있습니다. 대신 어플라이언스 자체의 상태를 프로브합니다. 상태 신호를 판별하기 위한 프로브는 NVA(네트워크 가상 어플라이언스) 시나리오에서 중요한 고려 사항이며, 이러한 시나리오에 적합한 상태 신호는 애플리케이션 공급업체에 문의해야 합니다.

방화벽 정책에서 프로브의 [원본 IP](#probesource)를 허용하지 않으면 인스턴스에 연결할 수 없으므로 상태 프로브가 실패하게 됩니다.  차례로 상태 프로브 실패로 인해 Load Balancer에서 인스턴스를 표시합니다.  이 잘못된 구성으로 인해 부하 분산된 애플리케이션 시나리오가 실패할 수 있습니다.

Load Balancer의 상태 프로브에서 인스턴스를 표시하려면 모든 Azure [네트워크 보안 그룹](../virtual-network/security-overview.md) 및 로컬 방화벽 정책에서 이 IP 주소를 **허용해야 합니다**.  기본적으로, 모든 네트워크 보안 그룹은 상태 프로브 트래픽을 허용하기 위해 [서비스 태그](../virtual-network/security-overview.md#service-tags) AzureLoadBalancer를 포함합니다.

상태 프로브 실패를 테스트하거나 개별 인스턴스를 표시하려는 경우 [네트워크 보안 그룹](../virtual-network/security-overview.md)을 사용하여 상태 프로브(대상 포트 또는 [원본 IP](#probesource))를 명시적으로 차단하고 프로브 실패를 시뮬레이트할 수 있습니다.

168.63.129.16이 포함된 Microsoft 소유의 IP 주소 범위를 사용하여 VNet을 구성하지 않도록 합니다.  이러한 구성은 상태 프로브의 IP 주소와 충돌하여 시나리오 실패를 야기할 수 있습니다.

VM에 여러 인터페이스가 있는 경우 받은 인터페이스의 프로브에 응답하도록 보장해야 합니다.  인터페이스당 VM에서 이 주소를 변환하려면 네트워크 주소를 소싱해야 할 수 있습니다.

[TCP 타임스탬프](https://tools.ietf.org/html/rfc1323)를 사용하지 않도록 설정합니다.  TCP 타임 스탬프를 사용 하도록 설정 하면 VM의 게스트 OS TCP 스택에 의해 삭제 되는 TCP 패킷으로 인해 상태 프로브가 실패할 수 있습니다. 그러면 해당 끝점에 대 한 Load Balancer 표시 됩니다.  TCP 타임스탬프는 기본적으로 보안이 강화된 VM 이미지에서 주기적으로 사용하도록 설정되며 사용하지 않도록 설정해야 합니다.

## <a name="monitoring"></a>모니터링

공용 및 내부 [표준 Load Balancer](load-balancer-standard-overview.md) 은 끝점 당 끝점 및 백 엔드 끝점 상태 프로브 상태를 Azure Monitor를 통해 다중 차원 메트릭으로 노출 합니다. 이러한 메트릭은 다른 Azure 서비스 또는 파트너 응용 프로그램에서 사용 될 수 있습니다. 

기본 공용 Load Balancer는 Azure Monitor 로그를 통해 백 엔드 풀에 요약 된 상태 프로브 상태를 노출 합니다.  Azure Monitor 로그는 내부 기본 부하 분산 장치에 사용할 수 없습니다.  [Azure Monitor 로그](load-balancer-monitor-log.md) 를 사용 하 여 공용 부하 분산 장치 프로브 상태 및 프로브 수를 확인할 수 있습니다. Power BI 또는 Azure Operational Insights에서 로깅을 사용하여 부하 분산 장치 상태에 대한 통계를 제공할 수 있습니다.

## <a name="limitations"></a>제한 사항

- HTTPS 프로브는 클라이언트 인증서를 사용한 상호 인증을 지원하지 않습니다.
- TCP 타임 스탬프를 사용 하도록 설정 하면 assumehHealth 프로브에 실패 합니다.

## <a name="next-steps"></a>다음 단계

- [표준 Load Balancer](load-balancer-standard-overview.md)에 대해 자세히 알아봅니다.
- [PowerShell을 사용하여 Resource Manager에서 공용 부하 분산 장치 만들기 시작](load-balancer-get-started-internet-arm-ps.md)
- [상태 프로브용 REST API](https://docs.microsoft.com/rest/api/load-balancer/loadbalancerprobes/)
- [Load Balancer의 Uservoice](https://aka.ms/lbuservoice)를 사용하여 새 상태 프로브 기능 요청
