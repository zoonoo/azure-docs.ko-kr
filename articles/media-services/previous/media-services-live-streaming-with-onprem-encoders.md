---
title: 다중 비트 전송률 스트림을 만드는 온-프레미스 인코더를 통한 스트림 라이브 - Azure | Microsoft Docs
description: 이 항목에서는 온-프레미스 인코더에서 다중 비트 전송률 라이브 스트림을 받는 채널을 설정하는 방법에 대해 설명합니다. 다음 적응 스트리밍 프로토콜 중 하나를 사용하여 하나 이상의 스트리밍 엔드포인트를 통해 클라이언트 재생 애플리케이션에 스트림을 전송할 수 있습니다. HLS, 부드러운 스트리밍, DASH.
services: media-services
documentationcenter: ''
author: Juliako
manager: femila
editor: ''
ms.assetid: d9f0912d-39ec-4c9c-817b-e5d9fcf1f7ea
ms.service: media-services
ms.workload: media
ms.tgt_pltfrm: na
ms.devlang: ne
ms.topic: article
ms.date: 03/18/2019
ms.author: cenkd;juliako
ms.openlocfilehash: da20e4601b75bcb22546d21f6ad218ac9ba2728b
ms.sourcegitcommit: 3102f886aa962842303c8753fe8fa5324a52834a
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/23/2019
ms.locfileid: "61463808"
---
# <a name="working-with-channels-that-receive-multi-bitrate-live-stream-from-on-premises-encoders"></a>온-프레미스 인코더에서 다중 비트 전송률 라이브 스트림을 받는 채널 작업

> [!NOTE]
> 2018년 5월 12일부터 라이브 채널은 RTP/MPEG-2 전송 스트림 수집 프로토콜을 더 이상 지원하지 않습니다. RTP/MPEG-2에서 RTMP 또는 조각난 MP4(부드러운 스트리밍) 수집 프로토콜로 마이그레이션하세요.

## <a name="overview"></a>개요
Azure Media Services에서 *채널*은 라이브 스트리밍 콘텐츠를 처리하기 위한 파이프라인을 나타냅니다. 채널은 다음 두 가지 방법 중 하나로 라이브 입력 스트림을 받습니다.

* 온-프레미스 라이브 인코더가 다중 비트 전송률 RTMP 또는 부드러운 스트리밍(조각화된 MP4) 스트림을 Media Services에서 라이브 인코딩을 수행하도록 설정되지 않은 채널로 보냅니다. 수집된 스트림은 어떠한 추가적인 처리 없이 채널을 통과합니다. 이 방법을 *통과*라고 합니다. 또한 라이브 인코더는 라이브 인코딩이 사용되지 않는 채널에 단일 비트 전송률 스트림을 전송할 수 있지만 이 방법은 권장되지 않습니다. Media Services는 요청한 고객에게 스트림을 배달합니다.

  > [!NOTE]
  > 통과 방법은 라이브 스트리밍을 수행하는 가장 경제적인 방법입니다.


* 온-프레미스 라이브 인코더는 단일 비트 전송률 스트림을 RTMP 또는 부드러운 스트리밍(조각난 MP4) 형식의 하나로 Media Services를 통해 라이브 인코딩을 수행할 수 있는 LiveEvent에 전송합니다. 그러면 채널은 들어오는 단일 비트 전송률 스트림을 다중 비트 전송률(적응) 비디오 스트림으로 라이브 인코딩합니다. Media Services는 요청한 고객에게 스트림을 배달합니다.

채널을 만들 때 Media Services 2.10 릴리스부터 채널에서 입력 스트림을 수신하는 방법을 지정할 수 있습니다. 채널이 스트림의 라이브 인코딩을 수행할지 여부를 지정할 수 있습니다. 다음 두 가지 옵션을 사용할 수 있습니다.

* **통과**: 다중 비트 전송률 스트림(통과 스트림)을 출력할 온-프레미스 라이브 인코더를 사용할 계획인 경우 이 값을 지정합니다. 이 경우 들어오는 스트림이 인코딩 없이 출력으로 전달됩니다. 이것이 2.10 릴리스 이전의 채널 동작입니다. 이 문서에서는 이 형식의 채널을 사용하는 방법에 대한 세부 정보를 제공합니다.
* **라이브 인코딩**: Media Services를 사용하여 단일 비트 전송률 라이브 스트림을 다중 비트 전송률 스트림으로 인코딩할 계획인 경우 이 값을 선택합니다. 라이브 인코딩 채널을 **실행** 상태로 놔두면 청구 요금이 발생합니다. 시간당 추가 요금 청구를 방지하려면 라이브 스트리밍 이벤트가 완료된 직후 실행 중인 채널을 중지하는 것이 좋습니다. Media Services는 요청한 고객에게 스트림을 배달합니다.

> [!NOTE]
> 이 문서에서는 라이브 인코딩을 수행할 수 있는 채널의 특성에 대해 설명합니다. 라이브 인코딩을 수행할 수 있는 채널 작업에 대한 자세한 내용은 [Azure Media Services를 사용하여 다중 비트 전송률 스트림을 만드는 라이브 스트리밍](media-services-manage-live-encoder-enabled-channels.md)을 참조하세요.
>
>에 대 한 자세한 내용은 프레미스 인코더에서 권장 [프레미스 인코더에서 권장](media-services-recommended-encoders.md)합니다.

다음 다이어그램은 다중 비트 전송률 RTMP 또는 조각화된 MP4(부드러운 스트리밍) 스트림을 출력하기 위해 온-프레미스 라이브 인코더를 사용하는 라이브 스트리밍 워크플로를 나타냅니다.

![라이브 워크플로][live-overview]

## <a id="scenario"></a>일반적인 라이브 스트리밍 시나리오
다음 단계에서는 일반적인 라이브 스트리밍 애플리케이션을 만드는 데 포함되는 작업을 설명합니다.

1. 비디오 카메라를 컴퓨터에 연결합니다. 다중 비트 전송률 RTMP 또는 조각화된 MP4(부드러운 스트리밍) 스트림을 출력하는 온-프레미스 라이브 인코더를 실행 및 구성합니다. 자세한 내용은 [Azure Media Services RTMP 지원 및 라이브 인코더](https://go.microsoft.com/fwlink/?LinkId=532824)를 참조하세요.

    채널을 만든 후에도 이 단계를 수행할 수 있습니다.
2. 채널을 만들고 시작합니다.

3. 채널 수집 URL을 검색합니다.

    라이브 인코더는 수집 URL을 사용하여 스트림을 채널로 보냅니다.
4. 채널 미리 보기 URL을 검색합니다.

    이 URL을 사용하여 채널이 라이브 스트림을 제대로 받고 있는지 확인합니다.
5. 프로그램을 만듭니다.

    Azure Portal을 사용하는 경우 프로그램을 만들면 자산도 만들어집니다.

    .NET SDK 또는 REST를 사용하는 경우 자산을 만들고 프로그램을 만들 때 이 자산을 사용하도록 지정해야 합니다.
6. 프로그램과 연결된 자산을 게시합니다.   

    >[!NOTE]
    >Azure Media Services 계정이 만들어질 때 **기본** 스트리밍 엔드포인트는 **중지됨** 상태에서 계정에 추가됩니다. 콘텐츠를 스트리밍하려는 스트리밍 엔드포인트가 **실행** 상태에 있어야 합니다.

7. 스트리밍 및 보관을 시작할 준비가 되었으면 프로그램을 시작합니다.

8. 필요에 따라 라이브 인코더는 광고를 시작하라는 신호를 받을 수 있습니다. 광고는 출력 스트림에 삽입됩니다.

9. 이벤트 스트리밍 및 보관을 중지할 때마다 프로그램을 중지 합니다.

10. 프로그램을 삭제하고 필요에 따라 자산을 삭제합니다.     

## <a id="channel"></a>채널 및 관련 구성 요소에 대한 설명
### <a id="channel_input"></a>채널 입력(수집) 구성
#### <a id="ingest_protocols"></a>수집 스트리밍 프로토콜
Media Services는 다중 비트 전송률 조각화된 MP4 및 다중 비트 전송률 RTMP를 스트리밍 프로토콜로 사용하여 라이브 피드를 수집하도록 지원합니다. RTMP 수집 스트리밍 프로토콜이 선택되면 2개의 수집(입력) 엔드포인트가 해당 채널에 만들어집니다.

* **기본 URL**: 채널의 기본 RTMP 수집 엔드포인트의 정규화된 URL을 지정합니다.
* **보조 URL**(선택 사항): 채널의 보조 RTMP 수집 엔드포인트의 정규화된 URL을 지정합니다.

인코더 장애 조치(failover) 및 내결함성뿐 아니라 스트림 수집의 내구성 및 내결함성을 개선하려는 경우, 특히 다음 시나리오에서 보조 URL을 사용합니다.

- 기본 및 보조 URL 모두에 대한 단일 인코더 이중 푸시:

    이 시나리오의 주요 목적은 네트워크 불안정과 Jitter에 대한 더 큰 복원력을 제공하는 것입니다. 일부 RTMP 인코더는 네트워크 연결 끊기를 잘 처리하지 않습니다. 네트워크 연결 끊기가 발생할 때 인코더가 인코딩을 중지할 수 있고 다시 연결될 때 버퍼링된 데이터를 전송하지 않습니다. 이로 인해 불연속 및 데이터 손실 문제가 발생합니다. 네트워크 연결 끊기는 Azure 쪽의 유지 관리나 불안정한 네트워크로 인해 발생할 수 있습니다. 기본/보조 URL을 사용하면 네트워크 문제가 감소하고 제어되는 업그레이드 프로세스도 제공됩니다. 예약된 네트워크 연결 끊기가 발생할 때마다 Media Services에서는 기본 및 보조 연결 끊기를 관리하고 두 연결 끊기 사이에 지연된 연결 끊기를 제공합니다. 그러면 인코더가 계속 데이터를 보내고 다시 연결할 시간이 생깁니다. 연결 끊기 순서는 무작위일 수 있지만 항상 기본/보조 또는 보조/기간 URL 사이에 지연이 있습니다. 이 시나리오에서 인코더는 단일 실패 지점입니다.

- 여러 인코더가 있으면 각 인코더는 전용 지점으로 푸시합니다.

    이 시나리오에서는 두 인코더 및 수집 중복성을 모두 제공합니다. 이 시나리오에서 encoder1은 기본 URL로 푸시하고 encoder2는 보조 URL로 푸시합니다. 인코더가 실패하면 다른 인코더가 데이터를 계속 보낼 수 있습니다. Media Services가 기본 및 보조 URL의 연결을 동시에 끊지 않으므로 데이터 중복성을 유지할 수 있습니다. 이 시나리오에서는 인코더가 시간 동기화된다고 가정하고 똑같은 데이터를 제공합니다.  

- 여러 인코더는 기본 및 보조 URL 모두에 대해 이중 푸시합니다.

    이 시나리오에서 두 인코더는 모두 기본 및 보조 URL에 모두 데이터를 푸시합니다. 이를 통해 최고의 안정성 및 내결함성과 데이터 중복성을 제공합니다. 이 시나리오에서는 하나의 인코더가 작동을 중지하는 경우에도 인코더 오류 및 연결 해제를 모두 허용할 수 있습니다. 여기서는 인코더가 시간 동기화된다고 가정하고 똑같은 데이터를 제공합니다.  

RTMP 라이브 인코더에 대한 자세한 내용은 [Azure Media Services RTMP 지원 및 라이브 인코더](https://go.microsoft.com/fwlink/?LinkId=532824)를 참조하세요.

#### <a name="ingest-urls-endpoints"></a>수집 URL(엔드포인트)
채널이 라이브 인코더에서 지정하는 입력 엔드포인트(수집 URL)를 제공하므로 해당 인코더는 채널에 스트림을 푸시할 수 있습니다.   

채널을 만들 때 수집 URL을 가져올 수 있습니다. 사용자가 이러한 URL을 가져오기 위해 채널이 **실행 중** 상태일 필요는 없습니다. 채널에 데이터 푸시를 시작할 준비가 되면 채널이 **실행 중** 상태여야 합니다. 채널이 데이터 수집을 시작한 후에 미리 보기 URL을 통해 스트림을 미리 볼 수 있습니다.

SSL 연결을 통한 조각화된 MP4(부드러운 스트리밍) 라이브 스트림을 수집하는 옵션이 있습니다. SSL을 통해 수집하려면 수집 URL을 HTTPS로 업데이트해야 합니다. 현재 SSL을 통해 RTMP를 수집할 수 없습니다.

#### <a id="keyframe_interval"></a>키 프레임 간격
다중 비트 전송률 스트림을 생성하는 데 온-프레미스 라이브 인코더를 사용하는 경우 키 프레임 간격은 GOP(Group of Pictures) 기간(외부 인코더에서 사용됨)을 지정합니다. 채널이 들어오는 스트림을 수신한 후에 다음 형식으로 클라이언트 재생 애플리케이션에 라이브 스트림을 제공할 수 있습니다. 부드러운 스트리밍, DASH(HTTP 동적 적응 스트리밍) 및 HLS(HTTP 라이브 스트리밍). 라이브 스트리밍을 수행할 경우 HLS는 항상 동적으로 패키지됩니다. Media Services는 기본적으로 라이브 인코더에서 수신되는 키 프레임 간격에 따라 자동으로 HLS 세그먼트 패키징 비율(세그먼트당 조각 수)을 계산합니다.

다음 테이블에서는 세그먼트 기간이 계산되는 방법을 보여 줍니다.

| 키프레임 간격 | HLS 세그먼트 패키징 비율(FragmentsPerSegment) | 예 |
| --- | --- | --- |
| 3초보다 작거나 같음 |3:1 |KeyFrameInterval(또는 GOP)이 2초인 경우 기본 HLS 세그먼트 패키징 비율은 3 대 1입니다. 그러면 6초 HLS 세그먼트를 만듭니다. |
| 3~5초 |2:1 |KeyFrameInterval(또는 GOP)이 4초인 경우 기본 HLS 세그먼트 패키징 비율은 2 대 1입니다. 그러면 8초 HLS 세그먼트를 만듭니다. |
| 5초보다 큼 |1:1 |KeyFrameInterval(또는 GOP)이 6초인 경우 기본 HLS 세그먼트 패키징 비율은 1 대 1입니다. 그러면 6초 HLS 세그먼트를 만듭니다. |

구성 채널의 출력을 구성하고 ChannelOutputHls에서 FragmentsPerSegment를 설정하여 세그먼트당 조각 수 비율을 변경할 수 있습니다.

ChannelInput에서 KeyFrameInterval 속성을 설정하여 키 프레임 간격 값을 변경할 수도 있습니다. KeyFrameInterval을 명시적으로 설정하는 경우 HLS 세그먼트 패키징 비율 FragmentsPerSegment는 이전에 설명된 규칙을 통해 계산됩니다.  

KeyFrameInterval 및 FragmentsPerSegment를 둘 다 명시적으로 설정하는 경우 Media Services는 사용자가 설정한 값을 사용합니다.

#### <a name="allowed-ip-addresses"></a>허용된 IP 주소
이 채널에 비디오를 게시하도록 허용된 IP 주소를 정의할 수 있습니다. 허용된 IP 주소를 다음 중 하나로 지정할 수 있습니다.

* 단일 IP 주소(예: 10.0.0.1)
* IP 주소와 CIDR 서브넷 마스크를 사용하는 IP 범위(예: 10.0.0.1/22)
* IP 주소와 점으로 구분된 10진수 서브넷 마스크를 사용하는 IP 범위(예: 10.0.0.1(255.255.252.0))

지정된 IP 주소가 없고 정의된 규칙이 없는 경우, IP 주소가 허용되지 않습니다. 모든 IP 주소를 허용하려면 규칙을 만들고 0.0.0.0/0으로 설정합니다.

### <a name="channel-preview"></a>채널 미리 보기
#### <a name="preview-urls"></a>미리 보기 URL
채널은 추가 처리 및 배달 전에 스트림을 미리 보고 확인하는 데 사용하는 미리 보기 엔드포인트(미리 보기 URL)를 제공합니다.

채널을 만들 때 미리 보기 URL을 가져올 수 있습니다. 사용자가 URL을 가져오기 위해 채널이 **실행 중** 상태일 필요는 없습니다. 채널이 데이터를 수집하기 시작한 후에 스트림을 미리 볼 수 있습니다.

현재 미리 보기 스트림은 지정된 입력 형식에 관계없이 조각화된 MP4(부드러운 스트리밍) 형식으로만 제공될 수 있습니다. [부드러운 스트리밍 상태 모니터링](https://playready.directtaps.net/smoothstreaming/) 플레이어를 사용하여 부드러운 스트림을 테스트할 수 있습니다. Azure Portal에 호스팅된 플레이어를 사용하여 스트림을 볼 수도 있습니다.

#### <a name="allowed-ip-addresses"></a>허용된 IP 주소
엔드포인트를 미리 보려면 연결이 허용된 IP 주소를 정의할 수 있습니다. 지정된 IP 주소가 없는 경우 모든 IP 주소가 허용됩니다. 허용된 IP 주소를 다음 중 하나로 지정할 수 있습니다.

* 단일 IP 주소(예: 10.0.0.1)
* IP 주소와 CIDR 서브넷 마스크를 사용하는 IP 범위(예: 10.0.0.1/22)
* IP 주소와 점으로 구분된 10진수 서브넷 마스크를 사용하는 IP 범위(예: 10.0.0.1(255.255.252.0))

### <a name="channel-output"></a>채널 출력
채널 출력에 대한 내용은 [키 프레임 간격](#keyframe_interval) 섹션을 참조하세요.

### <a name="channel-managed-programs"></a>채널 관리되는 프로그램
채널은 라이브 스트림에서 세그먼트의 게시 및 저장소를 제어하는데 사용할 수 있는 프로그램과 연결되어 있습니다. 채널은 프로그램을 관리합니다. 채널 및 프로그램 관계는 기존 미디어와 유사하여 채널에는 일정한 콘텐츠 스트림이 있고 프로그램 범위는 해당 채널에 있는 일부 시간 제한 이벤트로 지정됩니다.

**보관 창** 길이를 설정하여 프로그램에 대해 기록된 콘텐츠를 유지할 시간을 지정할 수 있습니다. 이 값은 최소 5분에서 최대 25시간 사이로 설정할 수 있습니다. 또한 보관 창 길이는 클라이언트가 현재 라이브 위치에서 이전 시간을 검색할 수 있는 최대 시간을 나타냅니다. 프로그램은 지정된 시간 동안 실행되지만 기간 길이보다 늦는 콘텐츠는 계속 삭제됩니다. 또한 이 속성의 값은 클라이언트 매니페스트가 증가할 수 있는 길이를 결정합니다.

각 프로그램은 스트리밍된 콘텐츠를 저장하는 자산과 연결됩니다. 자산은 Azure Storage 계정의 블록 Blob 컨테이너에 매핑되고 자산의 파일은 해당 컨테이너에 Blob으로 저장됩니다. 고객이 스트림을 볼 수 있도록 프로그램을 게시하려면 연결된 자산에 대한 주문형 로케이터를 만들어야 합니다. 이 로케이터를 사용하여 클라이언트에 제공할 수 있는 스트리밍 URL을 빌드할 수 있습니다.

채널은 동시 실행 프로그램을 최대 세 개까지 지원하므로 동일한 들어오는 스트림의 보관 파일을 여러 개 만들 수 있습니다. 이벤트의 여러 부분을 필요에 따라 게시하고 보관할 수 있습니다. 예를 들어 비즈니스 요구 사항에 따라 6시간의 프로그램을 보관하고 마지막 10분만 브로드캐스트한다고 가정합니다. 이렇게 하려면 두 개의 동시 실행 프로그램을 만들어야 합니다. 한 프로그램은 6시간의 이벤트를 보관하도록 설정하고 프로그램은 게시하지 않습니다. 다른 프로그램은 10분 동안을 보관하도록 설정하고 프로그램을 게시합니다.

새 이벤트에 기존 프로그램을 다시 사용할 수 없습니다. 대신, 각 이벤트에 대해 새 프로그램을 만듭니다. 스트리밍 및 보관을 시작할 준비가 되었으면 프로그램을 시작합니다. 이벤트 스트리밍 및 보관을 중지할 때마다 프로그램을 중지 합니다.

보관된 콘텐츠를 삭제하려면 프로그램을 중단 및 삭제한 다음 연결된 자산을 삭제합니다. 프로그램을 사용하는 경우 자산을 삭제할 수 없습니다. 프로그램을 먼저 삭제해야 합니다.

프로그램을 중단 및 삭제한 다음에도 자산을 삭제할 때까지 사용자는 주문형 비디오로 보관된 콘텐츠를 스트림할 수 있어야 합니다. 보관된 콘텐츠를 보관하려는데 스트리밍에 사용할 수 있는 콘텐츠가 없는 경우 스트리밍 로케이터를 삭제합니다.

## <a id="states"></a>채널 상태 및 청구
채널의 현재 상태에 대해 가능한 값은 다음과 같습니다.

* **중지됨**: 만들어진 후 채널의 초기 상태입니다. 이 상태에서 채널 속성을 업데이트할 수 있지만 스트리밍은 허용되지 않습니다.
* **시작 중**: 채널이 시작되고 있습니다. 이 상태에서는 업데이트 또는 스트리밍이 허용되지 않습니다. 오류가 발생하는 경우 채널이 **중지됨** 상태를 반환합니다.
* **Running**: 채널이 라이브 스트림을 처리할 수 있습니다.
* **중지 중**: 채널이 중지되고 있습니다. 이 상태에서는 업데이트 또는 스트리밍이 허용되지 않습니다.
* **삭제 중**: 채널이 삭제되고 있습니다. 이 상태에서는 업데이트 또는 스트리밍이 허용되지 않습니다.

다음 테이블에서는 채널 상태가 청구 모드에 매핑되는 방식을 보여 줍니다.

| 채널 상태 | 포털 UI 표시기 | 청구 여부 |
| --- | --- | --- |
| **시작 중** |**시작 중** |없음(일시적인 상태) |
| **실행 중** |**준비**(실행 중인 프로그램이 없음)<p><p>또는<p>**스트리밍**(실행 중인 프로그램이 하나 이상임) |예 |
| **중지 중** |**중지 중** |없음(일시적인 상태) |
| **중지** |**중지** |아닙니다. |

## <a id="cc_and_ads"></a>선택 자막 및 광고 삽입
다음 테이블에서는 선택 자막 및 광고 삽입의 지원되는 표준을 설명합니다.

| Standard | 메모 |
| --- | --- |
| CEA-708 및 EIA-608(708/608) |CEA-708 및 EIA-608은 미국 및 캐나다의 선택 자막 표준입니다.<p><p>현재 인코딩된 입력 스트림에 수반되는 경우에만 자막이 지원됩니다. Media Services에 전송되는 인코딩된 스트림으로 608 또는 708 자막을 삽입할 수 있는 라이브 미디어 인코더를 사용해야 합니다. Media Services는 뷰어에 삽입된 선택 자막이 있는 콘텐츠를 제공합니다. |
| TTML inside ismt(부드러운 스트리밍 텍스트 트랙) |Media Services 동적 패키징을 사용하면 클라이언트가 다음 형식 중 하나로 콘텐츠를 스트림할 수 있습니다. DASH, HLS 또는 부드러운 스트리밍. 하지만 자막 inside .ismt(부드러운 스트리밍 텍스트 트랙)가 포함된 조각화된 MP4(부드러운 스트리밍)를 수집하는 경우 부드러운 스트리밍 클라이언트로만 스트림을 제공할 수 있습니다. |
| SCTE-35 |SCTE-35는 큐 광고 삽입에 사용되는 디지털 신호 시스템입니다. 다운스트림 수신기는 할당된 시간 동안 스트림에 광고를 연결하기 위해 신호를 사용합니다. SCTE-35는 입력 스트림에서 스파스 트랙으로 전송되어야 합니다.<p><p>현재로서는 광고 신호를 수반하는 지원되는 입력 스트림 형식만이 조각화된 MP4(부드러운 스트리밍)입니다. 또한 지원되는 출력 포맷만 부드러운 스트리밍입니다. |

## <a id="considerations"></a>고려 사항
다중 비트 전송률 스트림을 채널로 보내기 위해 온-프레미스 라이브 인코드를 사용할 때 다음 제약 조건을 적용합니다.

* 수집 포인트로 데이터를 보내기에 충분한 여유 인터넷 연결이 있어야 합니다.
* 보조 수집 URL을 사용하려면 추가 대역폭이 필요합니다.
* 들어오는 다중 비트 전송률 스트림에는 최대 10개의 비디오 품질 수준(레이어) 및 최대 5개의 오디오 트랙이 포함될 수 있습니다.
* 비디오 품질 수준에 대한 가장 높은 평균 비트 전송률은 10Mbps 이하여야 합니다.
* 모든 비디오 및 오디오 스트림에 대한 평균 비트 전송률의 집계는 25Mbps 이하여야 합니다.
* 채널 또는 연결된 프로그램이 실행 중인 동안에는 입력 프로토콜을 변경할 수 없습니다. 다른 프로토콜을 요청하는 경우 각각의 입력 프로토콜에 대한 개별 채널을 만들어야 합니다.
* 채널에서 단일 비트 전송률을 수집할 수 있습니다. 하지만 채널이 스트림을 처리하지 않기 때문에 클라이언트 애플리케이션이 단일 비트 전송률 스트림을 받게 됩니다. 이 옵션을 권장하지 않습니다.

채널 사용 및 관련 구성 요소와 관련되는 다른 고려 사항은 다음과 같습니다.

* 라이브 인코더를 다시 구성할 때마다 채널에 대해 **Reset** 메서드를 호출합니다. 채널을 다시 설정하기 전에 프로그램을 중단해야 합니다. 채널을 다시 설정한 후 프로그램을 다시 시작합니다.

  > [!NOTE]
  > 프로그램을 다시 시작할 때 프로그램을 새 자산과 연결하고 새 로케이터를 만들어야 합니다. 
  
* 채널이 **실행 중** 상태일 때만 중지될 수 있으며 채널의 모든 프로그램이 중지됩니다.
* 기본적으로 Media Services 계정에 5개의 채널만을 추가할 수 있습니다. 자세한 내용은 [할당량 및 제한 사항](media-services-quotas-and-limitations.md)을 참조하세요.
* 채널이 **실행 중** 상태일 때만 비용이 청구됩니다. 자세한 내용은 [채널 상태 및 청구](media-services-live-streaming-with-onprem-encoders.md#states) 섹션을 참조하세요.

## <a name="media-services-learning-paths"></a>Media Services 학습 경로
[!INCLUDE [media-services-learning-paths-include](../../../includes/media-services-learning-paths-include.md)]

## <a name="feedback"></a>사용자 의견
[!INCLUDE [media-services-user-voice-include](../../../includes/media-services-user-voice-include.md)]

## <a name="related-topics"></a>관련된 항목
[권장 온-프레미스 인코더](media-services-recommended-encoders.md)

[Azure Media Services 조각화된 MP4 라이브 수집 사양](media-services-fmp4-live-ingest-overview.md)

[Azure Media Services 개요 및 일반적인 시나리오](media-services-overview.md)

[Media Services 개념](media-services-concepts.md)

[live-overview]: ./media/media-services-manage-channels-overview/media-services-live-streaming-current.png
